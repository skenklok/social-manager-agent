This XML file does not appear to have any style information associated with it. The document tree is shown below.
<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:itunes="http://www.itunes.com/dtds/podcast-1.0.dtd" xmlns:googleplay="http://www.google.com/schemas/play-podcasts/1.0" version="2.0">
<channel>
<title>
<![CDATA[ toString() ]]>
</title>
<description>
<![CDATA[ Technology and Books ]]>
</description>
<link>https://www.tostring.ai</link>
<image>
<url>https://substackcdn.com/image/fetch/w_256,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd9026593-bb1d-495c-8712-41f872e37c87_1080x1080.png</url>
<title>toString()</title>
<link>https://www.tostring.ai</link>
</image>
<generator>Substack</generator>
<lastBuildDate>Wed, 29 Jan 2025 14:45:22 GMT</lastBuildDate>
<atom:link href="https://www.tostring.ai/feed" rel="self" type="application/rss+xml"/>
<copyright>
<![CDATA[ Marco Altea ]]>
</copyright>
<language>
<![CDATA[ en ]]>
</language>
<webMaster>
<![CDATA[ tostring@substack.com ]]>
</webMaster>
<itunes:owner>
<itunes:email>
<![CDATA[ tostring@substack.com ]]>
</itunes:email>
<itunes:name>
<![CDATA[ Marco Altea ]]>
</itunes:name>
</itunes:owner>
<itunes:author>
<![CDATA[ Marco Altea ]]>
</itunes:author>
<googleplay:owner>
<![CDATA[ tostring@substack.com ]]>
</googleplay:owner>
<googleplay:email>
<![CDATA[ tostring@substack.com ]]>
</googleplay:email>
<googleplay:author>
<![CDATA[ Marco Altea ]]>
</googleplay:author>
<item>
<title>
<![CDATA[ Neural Networks Observability and Monitoring ]]>
</title>
<description>
<![CDATA[ As software engineers and architects of large systems and software, an important feature that we have to consider all the time is related to observability and ability to monitor how the system behave at different point in time and under different set of circumstances. ]]>
</description>
<link>https://www.tostring.ai/p/neural-networks-observability-and</link>
<guid isPermaLink="true">https://www.tostring.ai/p/neural-networks-observability-and</guid>
<dc:creator>
<![CDATA[ Marco Altea ]]>
</dc:creator>
<pubDate>Mon, 06 Jan 2025 18:01:26 GMT</pubDate>
<enclosure url="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2017c2f8-543a-4f7a-b773-d898ee045a39_952x797.png" length="0" type="image/jpeg"/>
<content:encoded>
<![CDATA[ <div class="native-audio-embed" data-component-name="AudioPlaceholder" data-attrs="{&quot;label&quot;:null,&quot;mediaUploadId&quot;:&quot;961704b3-a264-4e21-853d-b2db4f889fa8&quot;,&quot;duration&quot;:1770.3967,&quot;isEditorNode&quot;:true}"></div><p></p><p>Happy New Year!!!! During the break I spent some time trying to understand the concept of Observability in LLM and ass software engineers and architects of large systems and software, this is an important feature that we have to consider all the time and ability to monitor how the system behave at different point in time and under different set of circumstances. The reason why we do that is to be able to understand if the system that we built is meeting the expectation using</p><ul><li><p>Real-time monitoring of system health</p></li><li><p>Debugging of the system behaviour</p></li><li><p>Performance optimization</p></li><li><p>Anomaly detection</p></li><li><p>Capacity planning</p></li></ul><p>Now the question is, what capabilities we have to monitor AI Model and in specific Neural Network? What are the differences between observe and monitor a deterministic system in comparison to monitor a non-deterministic one? Here we go let me try to provide you my current understanding of the state of the art.</p><p>As architects, we're familiar with the three pillars of observability</p><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbcd47465-3317-4401-9ecd-85574fd37e43_1024x1024.png" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbcd47465-3317-4401-9ecd-85574fd37e43_1024x1024.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbcd47465-3317-4401-9ecd-85574fd37e43_1024x1024.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbcd47465-3317-4401-9ecd-85574fd37e43_1024x1024.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbcd47465-3317-4401-9ecd-85574fd37e43_1024x1024.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbcd47465-3317-4401-9ecd-85574fd37e43_1024x1024.png" width="1024" height="1024" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/bcd47465-3317-4401-9ecd-85574fd37e43_1024x1024.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1024,&quot;width&quot;:1024,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1783443,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbcd47465-3317-4401-9ecd-85574fd37e43_1024x1024.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbcd47465-3317-4401-9ecd-85574fd37e43_1024x1024.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbcd47465-3317-4401-9ecd-85574fd37e43_1024x1024.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbcd47465-3317-4401-9ecd-85574fd37e43_1024x1024.png 1456w" sizes="100vw" fetchpriority="high"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a></figure></div><ul><li><p><strong>Metrics</strong></p><ul><li><p>Quantitative measurements of system behaviour</p></li><li><p>Key focus: Performance indicators like latency, throughput, resource usage</p></li></ul></li><li><p><strong>Logs</strong></p><ul><li><p>Time stamped records of discrete events and state changes</p></li><li><p>Key focus: Debugging, audit trails, compliance</p></li></ul></li><li><p><strong>Traces</strong></p><ul><li><p>End-to-end request flow through system components</p></li><li><p>Key focus: Performance bottlenecks, error propagation</p></li></ul></li></ul><p>Let's see how these concepts map to neural network observability and what new considerations emerge.</p><div class="subscription-widget-wrap-editor" data-attrs="{&quot;url&quot;:&quot;https://www.tostring.ai/subscribe?&quot;,&quot;text&quot;:&quot;Subscribe&quot;,&quot;language&quot;:&quot;en&quot;}" data-component-name="SubscribeWidgetToDOM"><div class="subscription-widget show-subscribe"><div class="preamble"><p class="cta-caption">toString() is a reader-supported publication. To receive new posts and support my work, consider becoming a free or paid subscriber.</p></div><form class="subscription-widget-subscribe"><input type="email" class="email-input" name="email" placeholder="Type your email&#8230;" tabindex="-1"><input type="submit" class="button primary" value="Subscribe"><div class="fake-input-wrapper"><div class="fake-input"></div><div class="fake-button"></div></div></form></div></div><h3>System Architecture Parallel</h3><p>Imagine you're designing a microservices&#8217; architecture. You have:</p><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3b067cb7-103f-4ded-a9ca-797dd12d4357_501x581.png" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3b067cb7-103f-4ded-a9ca-797dd12d4357_501x581.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3b067cb7-103f-4ded-a9ca-797dd12d4357_501x581.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3b067cb7-103f-4ded-a9ca-797dd12d4357_501x581.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3b067cb7-103f-4ded-a9ca-797dd12d4357_501x581.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3b067cb7-103f-4ded-a9ca-797dd12d4357_501x581.png" width="501" height="581" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/3b067cb7-103f-4ded-a9ca-797dd12d4357_501x581.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:581,&quot;width&quot;:501,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:30263,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3b067cb7-103f-4ded-a9ca-797dd12d4357_501x581.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3b067cb7-103f-4ded-a9ca-797dd12d4357_501x581.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3b067cb7-103f-4ded-a9ca-797dd12d4357_501x581.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3b067cb7-103f-4ded-a9ca-797dd12d4357_501x581.png 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a></figure></div><p>You monitor this using:</p><p>1. Metrics (throughput, latency)</p><p>2. Logs (error messages, state changes)</p><p>3. Traces (request flow through services)</p><p>Now, consider a neural network architecture:</p><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F17744ffb-79ea-434b-8e99-c87d8587be6d_1581x1631.png" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F17744ffb-79ea-434b-8e99-c87d8587be6d_1581x1631.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F17744ffb-79ea-434b-8e99-c87d8587be6d_1581x1631.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F17744ffb-79ea-434b-8e99-c87d8587be6d_1581x1631.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F17744ffb-79ea-434b-8e99-c87d8587be6d_1581x1631.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F17744ffb-79ea-434b-8e99-c87d8587be6d_1581x1631.png" width="1456" height="1502" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/17744ffb-79ea-434b-8e99-c87d8587be6d_1581x1631.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1502,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F17744ffb-79ea-434b-8e99-c87d8587be6d_1581x1631.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F17744ffb-79ea-434b-8e99-c87d8587be6d_1581x1631.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F17744ffb-79ea-434b-8e99-c87d8587be6d_1581x1631.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F17744ffb-79ea-434b-8e99-c87d8587be6d_1581x1631.png 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a></figure></div><p>To understand how and what we can monitor let&#8217;s use a very common user journey where a person is chatting with an AI Model, we can split this journey in different stage for clarity </p><p class="button-wrapper" data-attrs="{&quot;url&quot;:&quot;https://www.tostring.ai/?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share toString()&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a class="button primary" href="https://www.tostring.ai/?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share"><span>Share toString()</span></a></p><h3>Stage 1: Prompt Input Processing</h3><div class="captioned-image-container"><figure><a class="image-link image2" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd34a453e-d83b-4a1c-99fa-cccc825d582e_1101x231.png" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd34a453e-d83b-4a1c-99fa-cccc825d582e_1101x231.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd34a453e-d83b-4a1c-99fa-cccc825d582e_1101x231.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd34a453e-d83b-4a1c-99fa-cccc825d582e_1101x231.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd34a453e-d83b-4a1c-99fa-cccc825d582e_1101x231.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd34a453e-d83b-4a1c-99fa-cccc825d582e_1101x231.png" width="1101" height="231" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/d34a453e-d83b-4a1c-99fa-cccc825d582e_1101x231.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:231,&quot;width&quot;:1101,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:223216,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd34a453e-d83b-4a1c-99fa-cccc825d582e_1101x231.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd34a453e-d83b-4a1c-99fa-cccc825d582e_1101x231.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd34a453e-d83b-4a1c-99fa-cccc825d582e_1101x231.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd34a453e-d83b-4a1c-99fa-cccc825d582e_1101x231.png 1456w" sizes="100vw" loading="lazy"></picture><div></div></div></a></figure></div><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2017c2f8-543a-4f7a-b773-d898ee045a39_952x797.png" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2017c2f8-543a-4f7a-b773-d898ee045a39_952x797.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2017c2f8-543a-4f7a-b773-d898ee045a39_952x797.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2017c2f8-543a-4f7a-b773-d898ee045a39_952x797.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2017c2f8-543a-4f7a-b773-d898ee045a39_952x797.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2017c2f8-543a-4f7a-b773-d898ee045a39_952x797.png" width="724" height="606.1218487394958" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/2017c2f8-543a-4f7a-b773-d898ee045a39_952x797.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:797,&quot;width&quot;:952,&quot;resizeWidth&quot;:724,&quot;bytes&quot;:155560,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2017c2f8-543a-4f7a-b773-d898ee045a39_952x797.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2017c2f8-543a-4f7a-b773-d898ee045a39_952x797.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2017c2f8-543a-4f7a-b773-d898ee045a39_952x797.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2017c2f8-543a-4f7a-b773-d898ee045a39_952x797.png 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a></figure></div><h3>Stage 2: Model Processing</h3><div class="captioned-image-container"><figure><a class="image-link image2" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F553617b6-f198-4fda-ae76-eab6e98fa1c1_1101x231.png" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F553617b6-f198-4fda-ae76-eab6e98fa1c1_1101x231.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F553617b6-f198-4fda-ae76-eab6e98fa1c1_1101x231.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F553617b6-f198-4fda-ae76-eab6e98fa1c1_1101x231.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F553617b6-f198-4fda-ae76-eab6e98fa1c1_1101x231.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F553617b6-f198-4fda-ae76-eab6e98fa1c1_1101x231.png" width="1101" height="231" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/553617b6-f198-4fda-ae76-eab6e98fa1c1_1101x231.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:231,&quot;width&quot;:1101,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:267107,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F553617b6-f198-4fda-ae76-eab6e98fa1c1_1101x231.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F553617b6-f198-4fda-ae76-eab6e98fa1c1_1101x231.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F553617b6-f198-4fda-ae76-eab6e98fa1c1_1101x231.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F553617b6-f198-4fda-ae76-eab6e98fa1c1_1101x231.png 1456w" sizes="100vw" loading="lazy"></picture><div></div></div></a></figure></div><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6f4d3468-90b7-4fe7-9f48-648aafd93a85_866x796.png" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6f4d3468-90b7-4fe7-9f48-648aafd93a85_866x796.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6f4d3468-90b7-4fe7-9f48-648aafd93a85_866x796.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6f4d3468-90b7-4fe7-9f48-648aafd93a85_866x796.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6f4d3468-90b7-4fe7-9f48-648aafd93a85_866x796.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6f4d3468-90b7-4fe7-9f48-648aafd93a85_866x796.png" width="866" height="796" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/6f4d3468-90b7-4fe7-9f48-648aafd93a85_866x796.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:796,&quot;width&quot;:866,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:143879,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6f4d3468-90b7-4fe7-9f48-648aafd93a85_866x796.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6f4d3468-90b7-4fe7-9f48-648aafd93a85_866x796.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6f4d3468-90b7-4fe7-9f48-648aafd93a85_866x796.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6f4d3468-90b7-4fe7-9f48-648aafd93a85_866x796.png 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a></figure></div><h3>Stage 3: Output Generation</h3><div class="captioned-image-container"><figure><a class="image-link image2" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F470771f1-d4c1-4c96-a98e-f56f6bd94821_891x231.png" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F470771f1-d4c1-4c96-a98e-f56f6bd94821_891x231.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F470771f1-d4c1-4c96-a98e-f56f6bd94821_891x231.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F470771f1-d4c1-4c96-a98e-f56f6bd94821_891x231.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F470771f1-d4c1-4c96-a98e-f56f6bd94821_891x231.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F470771f1-d4c1-4c96-a98e-f56f6bd94821_891x231.png" width="891" height="231" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/470771f1-d4c1-4c96-a98e-f56f6bd94821_891x231.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:231,&quot;width&quot;:891,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:161541,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F470771f1-d4c1-4c96-a98e-f56f6bd94821_891x231.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F470771f1-d4c1-4c96-a98e-f56f6bd94821_891x231.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F470771f1-d4c1-4c96-a98e-f56f6bd94821_891x231.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F470771f1-d4c1-4c96-a98e-f56f6bd94821_891x231.png 1456w" sizes="100vw" loading="lazy"></picture><div></div></div></a></figure></div><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8f34c00d-9652-4aab-b832-08578210e988_817x804.png" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8f34c00d-9652-4aab-b832-08578210e988_817x804.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8f34c00d-9652-4aab-b832-08578210e988_817x804.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8f34c00d-9652-4aab-b832-08578210e988_817x804.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8f34c00d-9652-4aab-b832-08578210e988_817x804.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8f34c00d-9652-4aab-b832-08578210e988_817x804.png" width="817" height="804" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/8f34c00d-9652-4aab-b832-08578210e988_817x804.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:804,&quot;width&quot;:817,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:132602,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8f34c00d-9652-4aab-b832-08578210e988_817x804.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8f34c00d-9652-4aab-b832-08578210e988_817x804.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8f34c00d-9652-4aab-b832-08578210e988_817x804.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8f34c00d-9652-4aab-b832-08578210e988_817x804.png 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a></figure></div><div><hr></div><div class="subscription-widget-wrap-editor" data-attrs="{&quot;url&quot;:&quot;https://www.tostring.ai/subscribe?&quot;,&quot;text&quot;:&quot;Subscribe&quot;,&quot;language&quot;:&quot;en&quot;}" data-component-name="SubscribeWidgetToDOM"><div class="subscription-widget show-subscribe"><div class="preamble"><p class="cta-caption">toString() is a reader-supported publication. To receive new posts and support my work, consider becoming a free or paid subscriber.</p></div><form class="subscription-widget-subscribe"><input type="email" class="email-input" name="email" placeholder="Type your email&#8230;" tabindex="-1"><input type="submit" class="button primary" value="Subscribe"><div class="fake-input-wrapper"><div class="fake-input"></div><div class="fake-button"></div></div></form></div></div><h3>The "Black Box" Nature of Neural Networks</h3><p>Neural networks fundamentally operate as complex distributed systems where "intelligence" emerges from the collective interaction of millions of interconnected nodes, rather than from explicit, programmed logic. Unlike traditional software systems where we can trace decision trees or follow logical pathways, a neural network's "thinking" is spread across its entire architecture, with no single neuron or layer containing complete concepts or decision points. This distributed nature means that when a network processes information &#8211; whether recognizing a face, interpreting text, or making predictions &#8211; it does so through countless parallel computations that occur simultaneously across its entire structure. The decision-making process cannot be traced because it doesn't follow sequential steps; instead, decisions emerge from the interaction of all components, similar to how human intuition works. We can observe the input (like an image) and the output (like "this is a cat"), but the actual process of reaching that conclusion exists as patterns of activation across the network's distributed architecture. This creates a fundamental challenge for system architects and developers: while we can monitor performance metrics, resource usage, and input-output relationships, we cannot inspect the actual reasoning process or understand why specific decisions were made. This limitation isn't a flaw in our monitoring capabilities, but rather a fundamental characteristic of how neural networks operate. Just as we cannot isolate the exact neurons in a human brain that contribute to recognizing a friend's face or understanding a complex concept, we cannot trace the specific pathways in a neural network that lead to its conclusions. This understanding is crucial for architects, as it influences how we approach system design, monitoring, validation, and risk management &#8211; forcing us to focus on observable behaviours and outcomes rather than internal logic, and to implement robust testing frameworks and validation strategies that don't rely on understanding the internal decision-making process.</p><p>From an engineering point of view, it&#8217;s important to understand how to &#8220;wrap&#8221; the different AI Model with software application and how to monitor it</p><h3>Deep Dive into Observability for Generative AI Applications</h3><p>As artificial intelligence continues to evolve, we find ourselves working with an entirely new class of software systems - Generative AI applications. Unlike traditional software that follows predetermined paths, these applications can generate novel content, engage in natural conversations, and even write code. This fundamental shift in how software operates requires us to rethink our approach to observability.</p><p>Generative AI applications represent a significant departure from traditional software systems. Think of them as creative collaborators rather than just tools that follow instructions. When you interact with a GenAI application, you're engaging with a system that can generate new and unique outputs each time, much like having a conversation with a knowledgeable colleague. This generative nature introduces unique challenges for monitoring and understanding system behavior.</p><h3>Core Monitoring Dimensions: A Practical Guide</h3><p>Let's break down the essential aspects of GenAI observability into understandable components that anyone building or managing these systems can grasp and implement.</p><h4>Prompt Engineering Metrics: Understanding Your AI Conversations</h4><p>Think of prompt engineering metrics as a quality control system for conversations with your AI. Just as we might analyse customer service interactions to improve service quality, we need to understand which ways of communicating with AI systems produce the best results.</p><p>In practical terms, we monitor:</p><ul><li><p>Prompt length and complexity (Is shorter or longer better?)</p></li><li><p>Question structure (Do examples help? Should we break questions into parts?)</p></li><li><p>Pattern effectiveness (Which approaches consistently get better responses?)</p><p>Measure how well the prompt worked</p></li></ul><p>Think of prompt engineering metrics as a quality control system for conversations with your AI. Just as we might analyse customer service interactions to improve service quality, we need to understand which ways of communicating with AI systems produce the best results.</p><p>In practical terms, we monitor:</p><ul><li><p>Prompt length and complexity (Is shorter or longer better?)</p></li><li><p>Question structure (Do examples help? Should we break questions into parts?)</p></li><li><p>Pattern effectiveness (Which approaches consistently get better responses?)</p></li></ul><p>Here's how we implement this monitoring:</p><h4>Token Usage and Economics: Managing Your AI Budget</h4><p>Just as you would monitor your phone bill or cloud computing costs, token usage monitoring helps you understand and control the costs of your AI interactions. Each word or piece of a word processed by the AI counts as a token, and these add up quickly in production systems.</p><p>This monitoring helps you:</p><ul><li><p>Track costs per conversation</p></li><li><p>Identify expensive interaction patterns</p></li><li><p>Optimize prompts for efficiency without sacrificing quality</p></li></ul><h4>Response Quality Assessment: Ensuring Reliable AI Outputs</h4><p>Just as traditional software needs quality assurance, GenAI applications need systematic ways to evaluate their outputs. This is particularly important because AI responses can vary significantly and might sometimes include incorrect or inappropriate content.</p><p>Our quality monitoring system checks for:</p><p>- Response coherence (Does it make logical sense?)</p><p>- Answer relevance (Does it address the actual question?)</p><p>- Factual accuracy (Is it making up information?)</p><p>- Content safety (Is it appropriate and aligned with policies?)</p><h4>Model Performance Correlation and System Integration</h4><p>Just as a car's performance depends on multiple factors like road conditions, fuel quality, and driver behavior, AI model performance is influenced by various interrelated factors. Model Performance Correlation helps us understand these relationships in practical terms.</p><p>Think of it as having a sophisticated diagnostic system that helps you understand:</p><ul><li><p>How different types of inputs affect your AI's response quality</p></li><li><p>How busy periods impact response times</p></li><li><p>Whether users are actually getting value from the AI's outputs</p></li></ul><h4>Multi-layered Data Collection</h4><p>Imagine your GenAI application as a multi-story building - you need to monitor conditions on each floor while also understanding how they affect the building as a whole. This is why we need a multi-layered approach to data collection.</p><p>At the ground level (Application Layer), we track:</p><ul><li><p>Basic health metrics (response times, error rates)</p></li><li><p>System resource usage</p></li><li><p>API call patterns</p></li></ul><p>At the upper levels (Model Layer), we monitor:</p><ul><li><p>Model inference times</p></li><li><p>Token consumption patterns</p></li><li><p>Quality metrics for model outputs</p></li></ul><h3>Putting It All Together</h3><p>These monitoring systems work together to give you a complete picture of your GenAI application's health and performance. By implementing all three aspects, you create a comprehensive observability solution that helps you:</p><ul><li><p>Optimize your AI interactions</p></li><li><p>Control costs while maintaining quality</p></li><li><p>Ensure reliable and safe AI responses</p></li></ul><p>I hope this post gives you a clearer understanding of what we can and can&#8217;t observe about AI. Here are some resources that can help you dive deeper into related topics.</p><p><a href="https://gyliu513.github.io/jekyll/update/2024/02/28/deep-dive-into-instana-ai-observability.html#key-features-of-ai-observability">Instana AI Observability</a> by my colleague Guangya Liu</p><p><a href="https://langfuse.com/faq/all/llm-observability">What is LLM Observability and LLM Monitoring?</a> By <a href="https://langfuse.com">Langfuse</a></p><p><a href="https://arxiv.org/pdf/1910.06401">Physics-Informed Deep Neural Network Method for Limited Observability State Estimation</a> By Jonatan Ostrometzky, Konstantin Berestizshevsk, Andrey Bernstein , Gil Zussman</p><p></p><p>See you next month!!</p><p class="button-wrapper" data-attrs="{&quot;url&quot;:&quot;https://www.tostring.ai/subscribe?&quot;,&quot;text&quot;:&quot;Subscribe now&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a class="button primary" href="https://www.tostring.ai/subscribe?"><span>Subscribe now</span></a></p><p></p><p></p><p></p> ]]>
</content:encoded>
</item>
<item>
<title>
<![CDATA[ The Hiring Paradox: When Bots Talk to Bots ]]>
</title>
<description>
<![CDATA[ This episode is going to be less technical but I want to help myself relect about the use of AI tolls in recruitment. ]]>
</description>
<link>https://www.tostring.ai/p/the-hiring-paradox-when-bots-talk</link>
<guid isPermaLink="true">https://www.tostring.ai/p/the-hiring-paradox-when-bots-talk</guid>
<dc:creator>
<![CDATA[ Marco Altea ]]>
</dc:creator>
<pubDate>Mon, 25 Nov 2024 16:08:20 GMT</pubDate>
<enclosure url="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3402618e-c9e4-4b1c-bfb4-9f7d7f9f453c_1024x1024.jpeg" length="0" type="image/jpeg"/>
<content:encoded>
<![CDATA[ <p>This episode is going to be less technical but I want to help myself relect about the use of AI tolls in recruitment. </p><div><hr></div><p><strong>Quick Note:</strong> If you prefer listening over reading, I've created an audio version of this article using <a href="https://notebooklm.google/">NotebookLM</a>. You can find it below.</p><div class="native-audio-embed" data-component-name="AudioPlaceholder" data-attrs="{&quot;label&quot;:null,&quot;mediaUploadId&quot;:&quot;ef767e99-dde2-4cc7-a135-474d964badf7&quot;,&quot;duration&quot;:1370.0441,&quot;isEditorNode&quot;:true}"></div><p>For those who prefer reading, let's dive in...</p><div><hr></div><p>As the AI race intensifies, we're all bombarded with new AI products and features daily. One particular case caught my attention recently while browsing Reddit. A user shared their experience of <a href="https://www.reddit.com/r/GetEmployed/comments/1eo8uyp/i_used_ai_to_automatically_apply_for_1000_jobs/">automating job applications</a>, describing how he built a program that takes a user's CV and desired job type as input, then scours LinkedIn for positions with the "Easy Apply" option. The program uses AI to match job requirements with the applicant's profile and automatically tailors the CV to highlight relevant skills and experience.</p><p></p><p class="button-wrapper" data-attrs="{&quot;url&quot;:&quot;https://www.tostring.ai/subscribe?&quot;,&quot;text&quot;:&quot;Subscribe now&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a class="button primary" href="https://www.tostring.ai/subscribe?"><span>Subscribe now</span></a></p><p>My initial reaction was excitement. As a technologist, any form of automation triggers that familiar dopamine rush, and examining the shared open-source code revealed how a relatively simple solution could create something genuinely useful.</p><p>However, once the initial enthusiasm subsided, I started thinking beyond the technological aspects and considered the broader implications of this development. Most companies today employ Applicant Tracking Systems (ATS) to manage their recruitment process. These systems typically offer:</p><ul><li><p><strong>Comprehensive Candidate Management</strong>: From initial registration to progress tracking through various recruitment stages, integrating with talent assessment systems to automate evaluations and status updates.</p></li><li><p><strong>Advanced Job Posting and Sourcing</strong>: Automating job postings across multiple platforms while optimizing descriptions to attract suitable candidates.<em> These systems leverage AI to parse resumes and match candidates based on qualifications and keywords.</em></p></li><li><p><strong>Streamlined Communication and Scheduling</strong>: Integrating with calendar systems like Google Calendar for interview scheduling and automated notifications, while providing various communication channels between recruiters and candidates.</p></li></ul><p>The controversy surrounding the AI features in ATS systems has been brewing for years. Candidates frequently complain about receiving no feedback and suspecting their applications are rejected by AI bots based on simple keyword matching or potentially biased training data. A notable example was Amazon's decision to abandon their <a href="https://www.reuters.com/article/world/insight-amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK0AG/#:~:text=In%20effect%2C%20Amazon's%20system%20taught,the%20names%20of%20the%20schools.">AI recruiting tool</a> after discovering it discriminated against women.</p><p>At first glance, creating tools to automate job searches and application creation seems like a fair countermeasure. However, deeper analysis suggests these are symptoms of a larger problem rather than the core issue itself. Let's examine the constraints and challenges faced by both sides, then consider potential future developments.</p><p>For companies hiring in 2024, the candidate pool has expanded far beyond national borders, particularly in regions like the EU and USA, where cross-border employment is commonplace. The sheer volume of potential candidates creates several challenges. A mid-sized company posting a remote software developer position might receive hundreds, if not thousands, of applications within days. This scale makes traditional human-first review processes increasingly impractical, leading companies to rely more heavily on automated screening tools.</p><p>Let's break down the current dynamics:</p><p><em>From the Company's Perspective:</em></p><ul><li><p>The global talent pool offers unprecedented access to skilled candidates</p></li><li><p>However, processing thousands of applications manually is resource-intensive and time-consuming</p></li><li><p>ATS systems seem to offer a solution by providing initial screening and filtering</p></li><li><p>But these systems might miss excellent candidates who don't perfectly match keyword criteria</p></li><li><p>Companies risk losing competitive advantage by potentially overlooking innovative thinkers who don't fit standard patterns</p></li><li><p>Tools like LinkedIn's "Easy Apply" have created an unintended consequence: candidates mass-applying to positions without careful consideration of fit or requirements</p></li><li><p>This "one-click" application culture leads to a flood of unsuitable applications, making it even harder to identify truly interested and qualified candidates</p></li><li><p>The ease of applying means companies must now filter through applications from candidates who are merely "testing the waters" rather than genuinely interested in the role and company</p></li><li><p>This further strains the recruitment process and potentially increases the time-to-hire metric</p></li></ul><p><em>From the Candidate's Perspective:</em></p><ul><li><p>The global job market offers more opportunities than ever before</p></li><li><p>But competition has intensified proportionally</p></li><li><p>Getting past ATS systems feels like solving a puzzle rather than showcasing real capabilities</p></li><li><p>The lack of meaningful feedback creates frustration and wastes time</p></li><li><p>This leads to a "spray and pray" approach, where candidates mass-apply to increase their chances</p></li></ul><p>So what happens when we introduce AI-powered application automation into this mix? We're essentially creating bots war: ATS systems become more sophisticated to filter out automated applications, while application automation tools evolve to better mimic "genuine" applications. </p><div class="subscription-widget-wrap-editor" data-attrs="{&quot;url&quot;:&quot;https://www.tostring.ai/subscribe?&quot;,&quot;text&quot;:&quot;Subscribe&quot;,&quot;language&quot;:&quot;en&quot;}" data-component-name="SubscribeWidgetToDOM"><div class="subscription-widget show-subscribe"><div class="preamble"><p class="cta-caption">toString() is a reader-supported publication. To receive new posts and support my work, consider becoming a free or paid subscriber.</p></div><form class="subscription-widget-subscribe"><input type="email" class="email-input" name="email" placeholder="Type your email&#8230;" tabindex="-1"><input type="submit" class="button primary" value="Subscribe"><div class="fake-input-wrapper"><div class="fake-input"></div><div class="fake-button"></div></div></form></div></div><p></p><h3><strong>What Could the Future Hold?</strong></h3><h4>The AI Avatar Ecosystem </h4><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3402618e-c9e4-4b1c-bfb4-9f7d7f9f453c_1024x1024.jpeg" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3402618e-c9e4-4b1c-bfb4-9f7d7f9f453c_1024x1024.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3402618e-c9e4-4b1c-bfb4-9f7d7f9f453c_1024x1024.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3402618e-c9e4-4b1c-bfb4-9f7d7f9f453c_1024x1024.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3402618e-c9e4-4b1c-bfb4-9f7d7f9f453c_1024x1024.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3402618e-c9e4-4b1c-bfb4-9f7d7f9f453c_1024x1024.jpeg" width="1024" height="1024" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/3402618e-c9e4-4b1c-bfb4-9f7d7f9f453c_1024x1024.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1024,&quot;width&quot;:1024,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:331772,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3402618e-c9e4-4b1c-bfb4-9f7d7f9f453c_1024x1024.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3402618e-c9e4-4b1c-bfb4-9f7d7f9f453c_1024x1024.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3402618e-c9e4-4b1c-bfb4-9f7d7f9f453c_1024x1024.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3402618e-c9e4-4b1c-bfb4-9f7d7f9f453c_1024x1024.jpeg 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a></figure></div><p></p><p>Imagine a future where each professional has their own AI agent - a digital avatar that represents them in the job market. These avatars would act as sophisticated digital representatives:</p><ul><li><p>They would understand their "owner's" skills, preferences, and career aspirations in depth</p></li><li><p>Could engage in preliminary discussions with company AI agents to assess mutual fit</p></li><li><p>Would negotiate initial terms and conditions based on predefined parameters</p></li><li><p>Could provide real-time feedback to their users about market demands and skill gaps</p></li><li><p>Might even suggest personalized learning paths to increase employability</p></li></ul><p>This scenario could evolve into a complex digital ecosystem where:</p><ul><li><p>Company avatars broadcast detailed job requirements and company culture markers</p></li><li><p>Candidate avatars continuously scan for opportunities and engage in initial screening</p></li><li><p>AI-to-AI negotiations filter out obvious mismatches before human involvement</p></li><li><p>The system could dramatically reduce the time both parties spend on unsuitable matches</p></li></ul><p><strong>Pros:</strong></p><p><em>For Candidates:</em></p><ul><li><p>24/7 job search without active involvement</p></li><li><p>Personalized opportunity discovery based on deep understanding of preferences</p></li><li><p>Real-time market intelligence about skill demands and salary ranges</p></li><li><p>Reduced emotional burden of rejection as initial screening happens at AI level</p></li><li><p>Continuous learning recommendations based on market trends</p></li><li><p>More efficient use of time, focusing only on highly matched opportunities</p></li><li><p>Potential for more objective initial screening, reducing human bias</p></li></ul><p><em>For Companies:</em></p><ul><li><p>Significant reduction in initial screening time and costs</p></li><li><p>Access to a more accurately filtered candidate pool</p></li><li><p>Ability to adjust requirements in real-time based on available talent</p></li><li><p>Reduced risk of miscommunication about basic requirements</p></li><li><p>More efficient resource allocation in the hiring process</p></li><li><p>Potential for better retention through more accurate initial matching</p></li><li><p>Ability to maintain continuous talent pool awareness</p></li></ul><p><strong>Cons:</strong></p><p><em>For Candidates:</em></p><ul><li><p>Risk of over-automation leading to missed "diamond in the rough" opportunities</p></li><li><p>Potential cost barriers for accessing advanced avatar features</p></li><li><p>Privacy concerns about sharing detailed personal and professional data</p></li><li><p>Risk of being excluded from opportunities due to avatar optimization failures</p></li><li><p>Difficulty in expressing unique or non-standard qualifications</p></li><li><p>Possible loss of serendipitous career opportunities</p></li><li><p>Risk of becoming too dependent on AI for career decisions</p></li></ul><p><em>For Companies:</em></p><ul><li><p>High initial investment in AI avatar systems and integration</p></li><li><p>Risk of missing innovative candidates who don't fit standard patterns</p></li><li><p>Potential for avatar system gaming or manipulation</p></li><li><p>Loss of human intuition in initial candidate assessment</p></li><li><p>Difficulty in assessing soft skills and cultural fit through AI alone</p></li><li><p>Risk of creating an arms race in avatar sophistication</p></li><li><p>Possible standardization of talent leading to less diverse workforces</p></li></ul><p><em>System-Level Challenges:</em></p><ul><li><p>Need for standardization across different avatar platforms</p></li><li><p>Risk of creating new forms of digital inequality</p></li><li><p>Potential for market manipulation through coordinated avatar behaviour</p></li><li><p>Complexity in handling cross-cultural nuances and communication styles</p></li><li><p>Legal and ethical implications of AI-based decision-making in hiring</p></li><li><p>Data security and privacy concerns at scale</p></li><li><p>Risk of reinforcing existing biases through AI training data</p></li></ul><p>Thinking about this model, there's an elephant in the room that we need to address: the <strong>human factor</strong>. This element has consistently proven difficult to quantify, program, or replicate in any automated system.</p><p>What do we mean by the "human factor"? It's that intangible quality that emerges during face-to-face interactions:</p><ul><li><p>The spark of enthusiasm when someone talks about their past projects</p></li><li><p>The subtle signs of emotional intelligence in handling a challenging question</p></li><li><p>The authentic cultural fit that becomes evident in casual conversation</p></li><li><p>The natural problem-solving approach that surfaces during technical discussions</p></li><li><p>The unspoken communication and body language that inform gut feelings</p></li><li><p>The genuine passion that can't be conveyed through carefully crafted bullet points</p></li><li><p>The ability to think on one's feet and adapt to unexpected conversational turns</p></li></ul><p>Current Limitations:</p><ul><li><p>No AI system at the moment, no matter how sophisticated, can fully capture these human elements</p></li><li><p>Even advanced language models struggle to replicate authentic human interaction</p></li><li><p>Automated systems can't accurately assess qualities like resilience, adaptability, and emotional intelligence</p></li><li><p>Cultural fit often relies on subtle cues that are lost in digital translation</p></li><li><p>Team dynamics and personality matches remain largely intuitive assessments</p></li></ul><h4>The Referral-Only World: A Return to Human Networks</h4><p>In contrast to the AI-driven future, we might witness a counter-movement: a return to purely human-based hiring through trusted referral networks. This scenario could emerge as a reaction to AI saturation and the growing distrust in automated systems.</p><p><strong>How It Might Work:</strong></p><ul><li><p>Companies would only accept applications through existing employee referrals</p></li><li><p>Professional networks would become the primary currency in the job market</p></li><li><p>LinkedIn and similar platforms might evolve into verified referral networks rather than job boards</p></li><li><p>Career growth would depend heavily on building and maintaining genuine professional relationships</p></li><li><p>Companies would invest more in referral bonus programs and network building events</p></li><li><p>Industry meetups and conferences would gain renewed importance as network-building opportunities</p></li></ul><p><strong>Pros:</strong></p><p><em>For Companies:</em></p><ul><li><p>Higher quality candidates through pre-vetted connections</p></li><li><p>Reduced recruitment costs and time-to-hire</p></li><li><p>Better cultural fit through existing employee recommendations</p></li><li><p>Increased accountability (employees putting their reputation on the line)</p></li><li><p>Lower turnover rates due to stronger social ties</p></li><li><p>Reduced risk of hiring mismatches</p></li><li><p>Natural team cohesion through existing relationships</p></li></ul><p><em>For Candidates:</em></p><ul><li><p>More meaningful job opportunities through personal connections</p></li><li><p>Higher success rate in applications</p></li><li><p>Better insight into company culture through referrers</p></li><li><p>Stronger support system when joining new companies</p></li><li><p>More transparent salary negotiations</p></li><li><p>Access to hidden job markets</p></li><li><p>More authentic hiring experiences</p></li></ul><p><strong>Cons:</strong></p><p><em>For Companies:</em></p><ul><li><p>Limited talent pool based on existing networks</p></li><li><p>Risk of creating homogeneous workforces</p></li><li><p>Difficulty scaling quickly when needed</p></li><li><p>Potential for nepotism and bias</p></li><li><p>Missing out on diverse perspectives and experiences</p></li><li><p>Challenging for new or smaller companies without established networks</p></li><li><p>Risk of creating "cliques" within the organization</p></li></ul><p><em>For Candidates:</em></p><ul><li><p>High barriers to entry for newcomers to an industry</p></li><li><p>Disadvantages for introverts or those with smaller networks</p></li><li><p>Increased inequality based on social capital</p></li><li><p>Difficulty changing industries or locations</p></li><li><p>Over-reliance on networking skills versus technical abilities</p></li><li><p>Pressure to maintain relationships for career purposes</p></li><li><p>Limited geographic mobility</p></li></ul><h5>Social Implications</h5><p>The shift towards a referral-based hiring system would create profound ripple effects across our economy and society. From an economic perspective, we'd likely see slower job market mobility as positions become more dependent on existing connections rather than open applications. The importance of networking education would surge, leading to new business opportunities focused on facilitating professional connections. Economic clusters would likely form around strong networks, fundamentally changing how we approach career preparation and development.</p><p>The social fabric of professional life would undergo significant transformation. Professional communities would strengthen, with reputation management becoming increasingly crucial for career advancement. The emphasis on long-term relationship building would reshape how people approach their careers, though this could potentially deepen existing social inequalities. We'd see a greater focus on soft skills development, and professional events would evolve to better serve their new role as critical networking hubs.</p><p>Educational institutions would need to adapt their curricula to this new reality. Traditional academic programs would likely incorporate more networking skills and professional relationship building into their core offerings. Internships and industry connections would become even more crucial than they are today, with alumni networks playing a more central role in career advancement. Enhanced mentorship programs would become a standard feature of education, preparing students for a world where professional relationships are the primary currency.</p><p>However, this system would inevitably develop a "shadow side." We might see the emergence of black markets for referrals and paid referral services, as people seek to bypass traditional networking barriers. Professional network gaming would become more sophisticated, leading to potential discrimination and exclusion. There's a real risk of industry gatekeeping, where established networks create closed professional circles that become increasingly difficult to penetrate. These challenges would require careful consideration and potentially new regulatory frameworks to ensure fair access to professional opportunities.</p><div class="subscription-widget-wrap-editor" data-attrs="{&quot;url&quot;:&quot;https://www.tostring.ai/subscribe?&quot;,&quot;text&quot;:&quot;Subscribe&quot;,&quot;language&quot;:&quot;en&quot;}" data-component-name="SubscribeWidgetToDOM"><div class="subscription-widget show-subscribe"><div class="preamble"><p class="cta-caption">toString() is a reader-supported publication. To receive new posts and support my work, consider becoming a free or paid subscriber.</p></div><form class="subscription-widget-subscribe"><input type="email" class="email-input" name="email" placeholder="Type your email&#8230;" tabindex="-1"><input type="submit" class="button primary" value="Subscribe"><div class="fake-input-wrapper"><div class="fake-input"></div><div class="fake-button"></div></div></form></div></div><p></p><h4>The Middle Ground: A Hybrid Future</h4><p>The two scenarios we've explored - the AI Avatar Ecosystem and the Referral-Only World - represent opposite ends of the spectrum in future hiring possibilities. One fully embraces technological automation, while the other swings back to purely human connections. Both scenarios offer compelling benefits while surfacing significant concerns. The reality is that the future probably lies somewhere in between, taking the best elements from both approaches.</p><p><strong>What Could This Hybrid Future Look Like?</strong></p><p>Imagine a system where AI and human networks complement each other rather than compete:</p><ul><li><p>AI avatars could serve as initial networkers, identifying potential connections based on genuine shared interests and complementary skills</p></li><li><p>Referral networks could be enhanced by AI tools that help people maintain and nurture their professional relationships more effectively</p></li><li><p>Initial screening could use AI to assess technical skills while relying on human networks for cultural fit and soft skills evaluation</p></li><li><p>Professional relationships could be enriched by AI-powered insights while maintaining their fundamental human nature</p></li><li><p>Companies could use AI to identify potential candidates within their employees' networks, creating a more structured and fair referral system</p></li></ul><p><strong>Addressing the Cons of Both Worlds:</strong></p><p><em>From the AI Avatar world, we need to preserve:</em></p><ul><li><p>Efficiency in handling large volumes of applications</p></li><li><p>Objective assessment of technical skills</p></li><li><p>Broad access to opportunities</p></li><li><p>Real-time market intelligence</p></li><li><p>Continuous learning recommendations</p></li></ul><p><em>From the Referral-Only world, we need to maintain:</em></p><ul><li><p>The human element in hiring decisions</p></li><li><p>Authentic professional relationships</p></li><li><p>Cultural fit assessment</p></li><li><p>Trust and accountability</p></li><li><p>Community building</p></li></ul><p><strong>The Key Principles for This Hybrid Approach:</strong></p><p><strong>Technology as an Enabler, Not a Replacement</strong></p><ul><li><p>AI tools should enhance human capabilities rather than replace human judgment</p></li><li><p>Automation should focus on reducing administrative burden, not making final decisions</p></li><li><p>Technology should facilitate more meaningful human interactions, not eliminate them</p></li></ul><p><strong>Balanced Access to Opportunities</strong></p><ul><li><p>Combine the breadth of AI-driven job matching with the depth of personal recommendations</p></li><li><p>Create systems that help build and expand professional networks fairly</p></li><li><p>Ensure both technical merit and social capital are appropriately valued</p></li></ul><p><strong>Transparent and Fair Processes</strong></p><ul><li><p>Clear communication about how AI tools and human networks influence decisions</p></li><li><p>Equal opportunity for candidates regardless of their initial network size</p></li><li><p>Mechanisms to prevent both algorithmic bias and network-based discrimination</p></li></ul><p><strong>Continuous Learning and Adaptation</strong></p><ul><li><p>Systems that learn from successful and unsuccessful hiring outcomes</p></li><li><p>Regular evaluation of the balance between automated and human-driven processes</p></li><li><p>Flexibility to adjust based on industry, role, and company culture needs</p></li></ul><h4>Looking Ahead</h4><p>The future of hiring will likely be neither a purely AI-driven marketplace nor a closed network of referrals, but rather an intelligent blend of both approaches. The challenge lies not in choosing between human and artificial intelligence, but in finding ways to combine them effectively. This hybrid approach could create a job market that is both efficient and human-centric, leveraging technology to enhance rather than replace human connections.</p><p>The key to success will be maintaining focus on the ultimate goal: connecting the right people with the right opportunities in a way that's both efficient and meaningful. As we move forward, we should strive to build systems that amplify human potential rather than trying to replicate or replace it.</p><p>What are your thoughts on this balance? How do you see the integration of AI and human networks evolving in your industry? Share your experiences and perspectives in the comments below.</p><p class="button-wrapper" data-attrs="{&quot;url&quot;:&quot;https://www.tostring.ai/p/the-hiring-paradox-when-bots-talk/comments&quot;,&quot;text&quot;:&quot;Leave a comment&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a class="button primary" href="https://www.tostring.ai/p/the-hiring-paradox-when-bots-talk/comments"><span>Leave a comment</span></a></p><p></p> ]]>
</content:encoded>
</item>
<item>
<title>
<![CDATA[ Apple PCC Explained: How Apple Redefines Cloud Security ]]>
</title>
<description>
<![CDATA[ How the World's Most Valuable Company Designed Its Most Secure Cloud ]]>
</description>
<link>https://www.tostring.ai/p/apple-pcc-explained-how-apple-redefines</link>
<guid isPermaLink="true">https://www.tostring.ai/p/apple-pcc-explained-how-apple-redefines</guid>
<dc:creator>
<![CDATA[ Marco Altea ]]>
</dc:creator>
<pubDate>Fri, 13 Sep 2024 12:23:16 GMT</pubDate>
<enclosure url="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc2584673-d20d-4334-8dd6-a56f382833fa_1351x971.png" length="0" type="image/jpeg"/>
<content:encoded>
<![CDATA[ <p>Hey folks welcome back, a few months before their annual event <a href="https://www.apple.com/uk/apple-events/">WWDC 2024</a> where they present new products, Apple released a detailed <a href="https://security.apple.com/blog/private-cloud-compute/">blog</a> post explaining how they approach security and privacy in this AI-driven, personal data-consuming age. I have to admit that I&#8217;m really impressed with Apple&#8217;s effort. Though I&#8217;m not an Apple fanboy, as my friends know, the work they did here is impressive. It covers all layers of the OSI model and more, ensuring that the supply chain is involved in security control processes. Let&#8217;s analyse together.</p><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F53341594-931d-45eb-a060-38164cd6939a_768x1024.png" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F53341594-931d-45eb-a060-38164cd6939a_768x1024.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F53341594-931d-45eb-a060-38164cd6939a_768x1024.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F53341594-931d-45eb-a060-38164cd6939a_768x1024.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F53341594-931d-45eb-a060-38164cd6939a_768x1024.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F53341594-931d-45eb-a060-38164cd6939a_768x1024.png" width="386" height="514.6666666666666" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/53341594-931d-45eb-a060-38164cd6939a_768x1024.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1024,&quot;width&quot;:768,&quot;resizeWidth&quot;:386,&quot;bytes&quot;:1103094,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F53341594-931d-45eb-a060-38164cd6939a_768x1024.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F53341594-931d-45eb-a060-38164cd6939a_768x1024.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F53341594-931d-45eb-a060-38164cd6939a_768x1024.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F53341594-931d-45eb-a060-38164cd6939a_768x1024.png 1456w" sizes="100vw" fetchpriority="high"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a></figure></div><div class="subscription-widget-wrap-editor" data-attrs="{&quot;url&quot;:&quot;https://www.tostring.ai/subscribe?&quot;,&quot;text&quot;:&quot;Subscribe&quot;,&quot;language&quot;:&quot;en&quot;}" data-component-name="SubscribeWidgetToDOM"><div class="subscription-widget show-subscribe"><div class="preamble"><p class="cta-caption">toString() is a reader-supported publication. To receive new posts and support my work, consider becoming a free or paid subscriber.</p></div><form class="subscription-widget-subscribe"><input type="email" class="email-input" name="email" placeholder="Type your email&#8230;" tabindex="-1"><input type="submit" class="button primary" value="Subscribe"><div class="fake-input-wrapper"><div class="fake-input"></div><div class="fake-button"></div></div></form></div></div><p></p><h3>Private Cloud Compute (PCC) Objectives</h3><p>Apple&#8217;s effort to design and build a Secure Private Cloud Computing environment has been driven by the desire to:</p><ul><li><p>Provide personal intelligence system that brings powerful generative models to iPhone, iPad, and Mac in a secure and private way</p></li><li><p>Guarantees data is processed without being stored.</p></li><li><p>Ensures personal data security in AI and cloud services. </p></li></ul><h3><strong>What Does &#8220;Secure&#8221; Mean?</strong></h3><p>Before to proceed, we should ask ourselves how we define the concept of security and privacy in this context? </p><p>As the famous quote says</p><div class="pullquote"><p>The only truly secure computer is one buried in concrete, with the power turned off and the network cable cut</p></div><p>Security is always a compromise between safety and usability, and like everything in computer science and in life, there is a trade-off to make between cost and benefit of a new capability. </p><p>Let&#8217;s explore how Apple defines "secure" in the context of their Private Cloud Compute (PCC) design, focusing on generative AI features:</p><ul><li><p><strong>Stateless computation</strong>: When using features like personalized Siri or on-device machine learning, Apple wants to <em><strong>process your data without storing it</strong></em>. </p></li><li><p><strong>Enforceable guarantee</strong>s: This essentially means Apple is reducing the use of external components that are not part of their dedicated infrastructure to maintain control over security and privacy. By doing so, they avoid potential risks that arise from relying on third-party systems. They are also reducing the functionality of each component to the bare minimum needed, like in the example of the monitor and logs, where Apple ensures that necessary functions like server metrics and error logs are collected in ways that do not compromise privacy. This means they are carefully selecting both internal and external components while maintaining essential functionality without weakening privacy guarantees.</p></li><li><p><strong>No privileged access</strong>: Whether you&#8217;re interacting with an AI assistant or using recommendations, Apple staff have no access to your data&#8212;even in emergencies.</p></li><li><p><strong>Non-targetability</strong>: Apple&#8217;s approach to non-targetability in PCC means they ensure that users cannot be uniquely singled out or targeted based on their data. This reduces the risk of attacks or data leaks focusing on specific individuals. By designing systems that do not retain identifiable user data or expose unique information, Apple makes it significantly harder for attackers to isolate or trace individual users. Essentially, the system processes user data in a way that prevents malicious actors from identifying or exploiting specific user profiles for targeted attacks.</p></li><li><p><strong>Verifiable transparency</strong>: Apple ensures that users and independent auditors can verify the privacy and security measures within PCC. By providing system logs, publishing software, and implementing open processes, Apple allows third parties to independently confirm that the privacy claims they make are accurate. This transparency builds trust by letting users and auditors see exactly how their data is being handled, ensuring that the system operates as Apple promises without hidden risks or privacy compromises.</p></li></ul><p>Now that we have a clearer understanding of the <strong>WHAT</strong> (Apple's security and privacy goals) and <strong>HOW</strong> (the technical mechanisms like stateless computation, non-targetability, and verifiable transparency) let's explore the cloud architecture designed by our friends in Cupertino. </p><h3>Context Diagram</h3><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc2584673-d20d-4334-8dd6-a56f382833fa_1351x971.png" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc2584673-d20d-4334-8dd6-a56f382833fa_1351x971.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc2584673-d20d-4334-8dd6-a56f382833fa_1351x971.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc2584673-d20d-4334-8dd6-a56f382833fa_1351x971.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc2584673-d20d-4334-8dd6-a56f382833fa_1351x971.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc2584673-d20d-4334-8dd6-a56f382833fa_1351x971.png" width="1351" height="971" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/c2584673-d20d-4334-8dd6-a56f382833fa_1351x971.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:971,&quot;width&quot;:1351,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:105576,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc2584673-d20d-4334-8dd6-a56f382833fa_1351x971.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc2584673-d20d-4334-8dd6-a56f382833fa_1351x971.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc2584673-d20d-4334-8dd6-a56f382833fa_1351x971.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc2584673-d20d-4334-8dd6-a56f382833fa_1351x971.png 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a></figure></div><p><strong>Apple's Private Cloud Computing (PCC)</strong> architecture represents a paradigm shift in secure, privacy-preserving cloud AI processing. Let's analyze each component:</p><p><strong>User Device:</strong></p><ul><li><p><em><strong>Apple Intelligence System:</strong></em> Serves as the frontend for advanced AI features, interfacing between user interactions and the PCC backend.</p></li><li><p><em><strong>PCC Client:</strong></em> Crucial for secure communication with PCC infrastructure. Implements end-to-end encryption and certificate verification against the Transparency Log.</p></li><li><p><em><strong>Cryptographic Component:</strong></em> Manages key generation, encryption, and signature verification. Critical for maintaining the security boundary between device and cloud.</p><p></p></li></ul><p><strong><a href="https://www.rfc-editor.org/rfc/rfc9458">OHTTP Relay:</a></strong></p><ul><li><p> Implements IP address anonymization, a key element of the Target Diffusion strategy.</p></li><li><p> Decouples user identity from requests, enhancing privacy at the network level.</p></li></ul><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb4e95000-304e-4324-995a-6bce85f54721_1338x518.png" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb4e95000-304e-4324-995a-6bce85f54721_1338x518.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb4e95000-304e-4324-995a-6bce85f54721_1338x518.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb4e95000-304e-4324-995a-6bce85f54721_1338x518.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb4e95000-304e-4324-995a-6bce85f54721_1338x518.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb4e95000-304e-4324-995a-6bce85f54721_1338x518.png" width="1338" height="518" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/b4e95000-304e-4324-995a-6bce85f54721_1338x518.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:518,&quot;width&quot;:1338,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" class="sizing-normal" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb4e95000-304e-4324-995a-6bce85f54721_1338x518.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb4e95000-304e-4324-995a-6bce85f54721_1338x518.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb4e95000-304e-4324-995a-6bce85f54721_1338x518.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb4e95000-304e-4324-995a-6bce85f54721_1338x518.png 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a><figcaption class="image-caption">All rights reserved to Cloudflare</figcaption></figure></div><p>Expand on this <a href="https://blog.cloudflare.com/stronger-than-a-promise-proving-oblivious-http-privacy-properties/">HERE</a></p><p><strong>Load Balancer:</strong></p><ul><li><p>Distributes requests across PCC Nodes without bias, supporting the non-targetability requirement.</p></li><li><p>Implements part of the Target Diffusion strategy by selecting nodes without user-specific information.</p></li></ul><p><strong>PCC Node:</strong></p><ul><li><p><em><strong>Secure Enclave Processor:</strong></em> The cornerstone of PCC's security model. Manages secure boot, code signing, and cryptographic operations. Its hardware-based root of trust is pivotal for the system's integrity.</p></li><li><p><em><strong>ML Stack</strong></em>: Handles inference processing. The separation from the Secure Enclave represents a clear delineation of concerns between security and processing tasks.</p></li><li><p><em><strong>Swift on Server:</strong></em> Enables custom cloud extensions, providing a balance between performance and memory safety.</p></li><li><p><em><strong>Dedicated Hardened OS:</strong></em> Incorporates advanced security features like sandboxing and pointer authentication codes. This bespoke OS is crucial for maintaining a minimal attack surface.</p></li><li><p><em><strong>Data Volume</strong></em>: Managed by the Secure Enclave, ensuring data remains encrypted at rest and is ephemeral between requests.</p></li><li><p><em><strong>Observability:</strong></em> Limited to predetermined, privacy-preserving metrics and logs, balancing operational needs with privacy requirements.</p></li></ul><p><strong>Transparency Log:</strong></p><ul><li><p>A public, append-only log that enables verifiable transparency.</p></li><li><p>Interacts with both user devices and PCC Nodes, facilitating trust without centralized authority. Critical for the system's auditability and for enabling third-party verification of PCC's security claims.</p></li></ul><h4>Architectural Principles:</h4><p>1.<strong> Stateless Computation:</strong> The architecture ensures that user data is processed transiently, leaving no persistent trace on PCC Nodes.</p><p>2. <strong>Enforceable Guarantees</strong>: Hardware-based security measures and the hardened OS create multiple layers of enforceable security boundaries.</p><p>3. <strong>Non-Privileged Access</strong>: The absence of traditional admin interfaces like SSH significantly reduces the attack surface.</p><p>4. <strong>Non-Targetability</strong>: Implemented through various mechanisms including the OHTTP Relay, Load Balancer behavior, and Target Diffusion strategy.</p><p>5.<strong> Verifiable Transparency</strong>: The Transparency Log enables unprecedented levels of auditability for a cloud AI system.</p><div class="captioned-button-wrap" data-attrs="{&quot;url&quot;:&quot;https://www.tostring.ai/p/apple-pcc-explained-how-apple-redefines?utm_source=substack&utm_medium=email&utm_content=share&action=share&token=eyJ1c2VyX2lkIjoyMTE1MDMzMywicG9zdF9pZCI6MTQ4ODQwNDU0LCJpYXQiOjE3MzgxNjE5MjIsImV4cCI6MTc0MDc1MzkyMiwiaXNzIjoicHViLTgzMTY2NiIsInN1YiI6InBvc3QtcmVhY3Rpb24ifQ.fXwlk9yQ864y1Phe48p-nVj_yfysT8r0LhPhOzUURM0&quot;,&quot;text&quot;:&quot;Share&quot;}" data-component-name="CaptionedButtonToDOM"><div class="preamble"><p class="cta-caption">Thanks for reading toString()! This post is public so feel free to share it.</p></div><p class="button-wrapper" data-attrs="{&quot;url&quot;:&quot;https://www.tostring.ai/p/apple-pcc-explained-how-apple-redefines?utm_source=substack&utm_medium=email&utm_content=share&action=share&token=eyJ1c2VyX2lkIjoyMTE1MDMzMywicG9zdF9pZCI6MTQ4ODQwNDU0LCJpYXQiOjE3MzgxNjE5MjIsImV4cCI6MTc0MDc1MzkyMiwiaXNzIjoicHViLTgzMTY2NiIsInN1YiI6InBvc3QtcmVhY3Rpb24ifQ.fXwlk9yQ864y1Phe48p-nVj_yfysT8r0LhPhOzUURM0&quot;,&quot;text&quot;:&quot;Share&quot;}" data-component-name="ButtonCreateButton"><a class="button primary" href="https://www.tostring.ai/p/apple-pcc-explained-how-apple-redefines?utm_source=substack&utm_medium=email&utm_content=share&action=share&token=eyJ1c2VyX2lkIjoyMTE1MDMzMywicG9zdF9pZCI6MTQ4ODQwNDU0LCJpYXQiOjE3MzgxNjE5MjIsImV4cCI6MTc0MDc1MzkyMiwiaXNzIjoicHViLTgzMTY2NiIsInN1YiI6InBvc3QtcmVhY3Rpb24ifQ.fXwlk9yQ864y1Phe48p-nVj_yfysT8r0LhPhOzUURM0"><span>Share</span></a></p></div><h2>How the information flow?</h2><p>Now, I believe that to understand Apple's perspective on security it's important to see how the information travel around the different actors. Let's examine how information flows from a device to the cloud and back. For this purpose, I've created three different sequence diagrams that represent three critical parts of the process:</p><h3>High-level view of the information sequence flow:</h3><p>This diagram provides an overview of the entire process, showing the main components and their interactions at a glance. It illustrates the journey of data from the user's device to Apple's Private Cloud Compute (PCC) and back, highlighting the key steps without delving into technical details.</p><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F26dd09a3-1556-496b-a234-9364fdd05ba7_1150x802.png" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F26dd09a3-1556-496b-a234-9364fdd05ba7_1150x802.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F26dd09a3-1556-496b-a234-9364fdd05ba7_1150x802.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F26dd09a3-1556-496b-a234-9364fdd05ba7_1150x802.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F26dd09a3-1556-496b-a234-9364fdd05ba7_1150x802.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F26dd09a3-1556-496b-a234-9364fdd05ba7_1150x802.png" width="1150" height="802" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/26dd09a3-1556-496b-a234-9364fdd05ba7_1150x802.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:802,&quot;width&quot;:1150,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:65626,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F26dd09a3-1556-496b-a234-9364fdd05ba7_1150x802.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F26dd09a3-1556-496b-a234-9364fdd05ba7_1150x802.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F26dd09a3-1556-496b-a234-9364fdd05ba7_1150x802.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F26dd09a3-1556-496b-a234-9364fdd05ba7_1150x802.png 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a></figure></div><ol><li><p>User initiates the request on their device.</p></li><li><p>The device (which includes Apple Intelligence and PCC Client) constructs and encrypts the request.</p></li><li><p>The encrypted request is sent to the cloud (which includes Supporting Services and PCC Nodes).</p></li><li><p>A note indicates end-to-end encryption between the device and cloud.</p></li><li><p>The cloud processes the request.</p></li><li><p>The cloud sends an encrypted response back to the device.</p></li><li><p>The device decrypts the response.</p></li><li><p>The result is presented to the user.</p></li><li><p>The cloud deletes the user data after processing.</p></li></ol><p class="button-wrapper" data-attrs="{&quot;url&quot;:&quot;https://www.tostring.ai/subscribe?&quot;,&quot;text&quot;:&quot;Subscribe now&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a class="button primary" href="https://www.tostring.ai/subscribe?"><span>Subscribe now</span></a></p><h3>Detailed view of the information sequence between the device and the PCC:</h3><p>This diagram zooms in on the interactions between the user's device and the PCC system. It showcases the specific steps involved in securing and transmitting data, including encryption processes, the role of intermediary services like OHTTP and load balancers, and how end-to-end encryption is maintained throughout the communication.</p><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9ac2f6fe-a212-41b6-aa51-d063d7c6b726_1155x1009.png" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9ac2f6fe-a212-41b6-aa51-d063d7c6b726_1155x1009.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9ac2f6fe-a212-41b6-aa51-d063d7c6b726_1155x1009.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9ac2f6fe-a212-41b6-aa51-d063d7c6b726_1155x1009.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9ac2f6fe-a212-41b6-aa51-d063d7c6b726_1155x1009.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9ac2f6fe-a212-41b6-aa51-d063d7c6b726_1155x1009.png" width="1155" height="1009" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/9ac2f6fe-a212-41b6-aa51-d063d7c6b726_1155x1009.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1009,&quot;width&quot;:1155,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:109997,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9ac2f6fe-a212-41b6-aa51-d063d7c6b726_1155x1009.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9ac2f6fe-a212-41b6-aa51-d063d7c6b726_1155x1009.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9ac2f6fe-a212-41b6-aa51-d063d7c6b726_1155x1009.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9ac2f6fe-a212-41b6-aa51-d063d7c6b726_1155x1009.png 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a></figure></div><ol><li><p>Initial Request Handling:</p><ul><li><p>Apple Intelligence passes the constructed request to the PCC Client.</p></li><li><p>PCC Client encrypts the request for OHTTP transmission.</p></li></ul></li><li><p>OHTTP Gateway:</p><ul><li><p>The encrypted request is sent to the OHTTP Gateway.</p></li><li><p>OHTTP Gateway processes the request, providing an additional layer of privacy.</p></li></ul></li><li><p>Load Balancer:</p><ul><li><p>OHTTP Gateway forwards the request to the Load Balancer.</p></li><li><p>Load Balancer distributes the request among PCC Nodes.</p></li></ul></li><li><p>PCC Nodes:</p><ul><li><p>PCC Nodes decrypt and process the request.</p></li><li><p>They generate and encrypt the response.</p></li></ul></li><li><p>Response Path:</p><ul><li><p>The encrypted response is sent back through the Load Balancer and OHTTP Gateway.</p></li><li><p>PCC Client decrypts the OHTTP response.</p></li><li><p>The decrypted response is delivered to Apple Intelligence.</p></li></ul></li><li><p>Data Deletion:</p><ul><li><p>PCC Nodes delete the user data after processing.</p></li></ul></li><li><p>Security Notes:</p><ul><li><p>End-to-end encryption is maintained throughout the process.</p></li></ul></li></ol><h3>Information flow inside the PCC:</h3><p>The final diagram focuses on the internal workings of a PCC node. It illustrates how data is processed within the secure environment, including steps like decryption, validation, model inference, response generation, and the crucial process of data deletion after use. This diagram emphasizes the security measures and ephemeral nature of data handling within the PCC.</p><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F78bdb02d-94eb-4aaa-a546-57d7d0e2d351_1868x1070.png" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F78bdb02d-94eb-4aaa-a546-57d7d0e2d351_1868x1070.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F78bdb02d-94eb-4aaa-a546-57d7d0e2d351_1868x1070.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F78bdb02d-94eb-4aaa-a546-57d7d0e2d351_1868x1070.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F78bdb02d-94eb-4aaa-a546-57d7d0e2d351_1868x1070.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F78bdb02d-94eb-4aaa-a546-57d7d0e2d351_1868x1070.png" width="1456" height="834" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/78bdb02d-94eb-4aaa-a546-57d7d0e2d351_1868x1070.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:834,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:137211,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F78bdb02d-94eb-4aaa-a546-57d7d0e2d351_1868x1070.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F78bdb02d-94eb-4aaa-a546-57d7d0e2d351_1868x1070.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F78bdb02d-94eb-4aaa-a546-57d7d0e2d351_1868x1070.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F78bdb02d-94eb-4aaa-a546-57d7d0e2d351_1868x1070.png 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a></figure></div><ol><li><p>Input Reception:</p><ul><li><p>The Input Receiver gets the encrypted request from the network.</p></li></ul></li><li><p>Decryption:</p><ul><li><p>The Decryptor decrypts the received request.</p></li></ul></li><li><p>Validation and Parsing:</p><ul><li><p>The Validator &amp; Parser checks the request format and parses the parameters.</p></li></ul></li><li><p>Model Management:</p><ul><li><p>The Model Manager is asked to provide the appropriate model for the request.</p></li></ul></li><li><p>Inference:</p><ul><li><p>The Inference Engine loads the model and performs the inference based on the request.</p></li></ul></li><li><p>Response Generation:</p><ul><li><p>The Response Generator creates a response based on the inference results.</p></li></ul></li><li><p>Encryption:</p><ul><li><p>The Encryptor encrypts the generated response.</p></li></ul></li><li><p>Output:</p><ul><li><p>The encrypted response is sent back to the client through the Input Receiver.</p></li></ul></li><li><p>Data Deletion:</p><ul><li><p>After completion, the Data Deleter removes all user data and temporary files.</p></li></ul></li><li><p>Security Note:</p><ul><li><p>A note emphasizes that secure memory management is maintained throughout the process.</p></li></ul></li></ol><p>These three diagrams, when viewed together, provide a good understanding of Apple's approach to securing user data in cloud-based AI processing. They highlight the multiple layers of security and privacy measures implemented at every stage of the data's journey, from the user's device through the cloud infrastructure and back.</p><h3>Beyond Software and Network Security</h3><p>Apple's commitment to security in their Private Cloud Compute (PCC) system extends far beyond software measures, reaching deep into the hardware supply chain. Their approach to hardware security is exemplary and comprehensive, beginning at the manufacturing stage and continuing through to deployment in data centers.</p><p>The process starts with meticulous inventory and high-resolution imaging of each PCC node component. This detailed documentation occurs before the server is sealed and its tamper-evident switch is activated, creating a verifiable record of the original state of each unit.</p><p>Upon arrival at the data center, these servers undergo an extensive revalidation process. This crucial step involves multiple Apple teams working independently to cross-check data from various sources, ensuring the integrity of each unit. To further enhance transparency and trust, this process is monitored by an independent third-party observer with no affiliation to Apple.</p><p>The culmination of this rigorous process is the issuance of a unique certificate for each PCC node. These certificates are cryptographically rooted in the Secure Enclave's Unique Identifier (UID), providing an unbreakable link between the physical hardware and its digital identity.</p><p>Apple's security model extends this trust to the user's device. The system is designed so that a user's device will refuse to transmit data to any PCC node whose certificate it cannot validate. This creates an end-to-end chain of trust from the manufacturing process all the way to the user's interaction with the PCC system.</p><p>These measures demonstrate Apple's holistic approach to security, protecting the hardware from potential compromises at every stage of its lifecycle. By implementing such thorough and transparent processes, Apple has set a new standard in hardware security for cloud computing infrastructure.</p><p></p><p class="button-wrapper" data-attrs="{&quot;url&quot;:&quot;https://www.tostring.ai/p/apple-pcc-explained-how-apple-redefines/comments&quot;,&quot;text&quot;:&quot;Leave a comment&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a class="button primary" href="https://www.tostring.ai/p/apple-pcc-explained-how-apple-redefines/comments"><span>Leave a comment</span></a></p><p></p> ]]>
</content:encoded>
</item>
<item>
<title>
<![CDATA[ RAG, Vector Database and RBAC ]]>
</title>
<description>
<![CDATA[ Recently, I talked to a coworker who is working with a client adopting a RAG Architecture. She told me about a technical question that she had. She was creating an AI chat assistant on AWS using a RAG architecture, she was wondering what was the best approach to ensure that the strict permissions from their documentation wiki were kept when the data was moved to a vector database for use by the AI. ]]>
</description>
<link>https://www.tostring.ai/p/rag-vector-database-and-rbac</link>
<guid isPermaLink="true">https://www.tostring.ai/p/rag-vector-database-and-rbac</guid>
<dc:creator>
<![CDATA[ Marco Altea ]]>
</dc:creator>
<pubDate>Thu, 06 Jun 2024 13:49:35 GMT</pubDate>
<enclosure url="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F72ed663c-5924-44fc-9631-2c93d07050dd_1114x641.png" length="0" type="image/jpeg"/>
<content:encoded>
<![CDATA[ <p>Recently, I talked to a coworker who is working with a client adopting a RAG Architecture. She told me about a technical question that she had. She was creating an AI chat assistant on AWS using a RAG architecture, she was wondering what was the best approach to ensure that the strict permissions from their documentation wiki were kept when the data was moved to a vector database for use by the AI.</p><p>I find it an interesting topic to explore. I want to understand the best approaches available and their trade-offs.</p><p>I decided to look into this issue more and share my findings. This blog will explain how RBAC (Role-Based Access Control) can work well with RAG architecture in AWS.</p><p>Let&#8217;s start from the basic</p><h3><strong>What is a Vector Database?</strong></h3><p>Vector databases are specialized databases designed to store and query vector embeddings generated by machine learning models. </p><p>Vector embeddings are a way of converting non-numeric data, like words or images, into a numeric form so that they can be processed by machine learning algorithms. The resulting numeric forms are vectors in a high-dimensional space, where each dimension captures some features or aspects of the input data. These embeddings help to preserve the contextual relationships between data points in their original forms.</p><div id="youtube2-t9IDoenf-lo" class="youtube-wrap" data-attrs="{&quot;videoId&quot;:&quot;t9IDoenf-lo&quot;,&quot;startTime&quot;:null,&quot;endTime&quot;:null}" data-component-name="Youtube2ToDOM"><div class="youtube-inner"><iframe src="https://www.youtube-nocookie.com/embed/t9IDoenf-lo?rel=0&amp;autoplay=0&amp;showinfo=0&amp;enablejsapi=0" frameborder="0" loading="lazy" gesture="media" allow="autoplay; fullscreen" allowautoplay="true" allowfullscreen="true" width="728" height="409"></iframe></div></div><p><strong>How Vector Embeddings Work</strong></p><p>Vector embeddings work by mapping the original data to points in a geometric space. Similar items are placed closer together, whereas dissimilar items are farther apart. This mapping is often learned from large amounts of data using machine learning techniques. For text data, these embeddings can capture semantic meanings, syntactic roles, and even relationships between words.</p><p><strong>Example: Word Embeddings</strong></p><p>Let&#8217;s consider an example using word embeddings, which are a common type of vector embedding in natural language processing (NLP). One popular model for creating word embeddings is <strong>Word2Vec</strong>.</p><p>Imagine we have three words: &#8220;king,&#8221; &#8220;queen,&#8221; and &#8220;man.&#8221; The Word2Vec model can be trained on a large amount of text so that it learns to represent these words as vectors in a way that captures their relationships. For instance, it might capture gender relationships and royalty concepts. This can be visualized as vectors where &#8220;king&#8221; and &#8220;queen&#8221; are close to each other because both are royalty, and the vector from &#8220;king&#8221; to &#8220;queen&#8221; might be similar to the vector from &#8220;man&#8221; to &#8220;woman,&#8221; capturing the concept of gender.</p><p>Here is a simplified numerical example:</p><ul><li><p><strong>king</strong> &#8594; (0.5, 0.2, 0.9)</p></li><li><p><strong>queen</strong> &#8594; (0.45, 0.25, 0.88)</p></li><li><p><strong>man</strong> &#8594; (0.6, 0.1, 0.5)</p></li></ul><p>These vectors might indicate that &#8220;king&#8221; and &#8220;queen&#8221; are more similar to each other (closer in vector space) than either is to &#8220;man,&#8221; reflecting a shared concept of royalty that &#8220;man&#8221; does not have.</p><p>If you are a basketball fan, let me give you an example that helped me understand better how this works</p><p>Imagine you&#8217;re trying to organize an extensive collection of basketball player trading cards based on different attributes: </p><p>scoring ability, defensive skills, and teamwork. Each card contains a lot of qualitative data (like player performance descriptions) that isn&#8217;t immediately comparable in a numerical way.</p><p>Vector embeddings are like a tool that converts all those qualitative traits into scores on a scale, creating a &#8220;profile&#8221; for each player as a vector (or a list of numbers). For example, a player&#8217;s ability to score might be on a scale from 0 to 1, their defensive skills might also be scaled similarly, and so on.</p><p>Here&#8217;s how it relates to basketball:</p><ol><li><p><strong>Similarity in Space</strong>: Just as you might group players who have similar playing styles or strengths, vector embeddings place similar items (like words, or in our case, players) close together in a vector space. For instance, LeBron James and Kevin Durant might be closer in this space because their playing styles and roles are similar, while a specialist like Stephen Curry might be slightly further because of his exceptional shooting skills.</p></li><li><p><strong>Understanding Relationships</strong>: Just like understanding that a point guard like Chris Paul plays differently from a center like Joel Embiid, word embeddings help capture relationships and differences between words. In our basketball analogy, vector embeddings might help a machine understand and quantify how different roles or skills relate to each other in the context of player evaluations.</p></li></ol><p><strong>Example with Player Profiles:</strong></p><ul><li><p><strong>LeBron James</strong> might be embedded as (0.9, 0.8, 0.9) where these numbers represent his scoring ability, defensive skills, and teamwork, respectively.</p></li><li><p><strong>Stephen Curry</strong> might be (0.95, 0.7, 0.85) reflecting his outstanding scoring, good defense, and great teamwork.</p></li><li><p><strong>Joel Embiid</strong> might be (0.85, 0.9, 0.75), indicating strong scoring, excellent defense, and good teamwork.</p></li></ul><div class="captioned-button-wrap" data-attrs="{&quot;url&quot;:&quot;https://www.tostring.ai/p/rag-vector-database-and-rbac?utm_source=substack&utm_medium=email&utm_content=share&action=share&token=eyJ1c2VyX2lkIjoyMTE1MDMzMywicG9zdF9pZCI6MTQ0MjM0Njg3LCJpYXQiOjE3MzgxNjE5MjIsImV4cCI6MTc0MDc1MzkyMiwiaXNzIjoicHViLTgzMTY2NiIsInN1YiI6InBvc3QtcmVhY3Rpb24ifQ.gR_VKhINrawjSBwnJQpV8VJah8hZ-Zy_rOwir7ZmLg8&quot;,&quot;text&quot;:&quot;Share&quot;}" data-component-name="CaptionedButtonToDOM"><div class="preamble"><p class="cta-caption">Thank you for reading toString(). This post is public so feel free to share it.</p></div><p class="button-wrapper" data-attrs="{&quot;url&quot;:&quot;https://www.tostring.ai/p/rag-vector-database-and-rbac?utm_source=substack&utm_medium=email&utm_content=share&action=share&token=eyJ1c2VyX2lkIjoyMTE1MDMzMywicG9zdF9pZCI6MTQ0MjM0Njg3LCJpYXQiOjE3MzgxNjE5MjIsImV4cCI6MTc0MDc1MzkyMiwiaXNzIjoicHViLTgzMTY2NiIsInN1YiI6InBvc3QtcmVhY3Rpb24ifQ.gR_VKhINrawjSBwnJQpV8VJah8hZ-Zy_rOwir7ZmLg8&quot;,&quot;text&quot;:&quot;Share&quot;}" data-component-name="ButtonCreateButton"><a class="button primary" href="https://www.tostring.ai/p/rag-vector-database-and-rbac?utm_source=substack&utm_medium=email&utm_content=share&action=share&token=eyJ1c2VyX2lkIjoyMTE1MDMzMywicG9zdF9pZCI6MTQ0MjM0Njg3LCJpYXQiOjE3MzgxNjE5MjIsImV4cCI6MTc0MDc1MzkyMiwiaXNzIjoicHViLTgzMTY2NiIsInN1YiI6InBvc3QtcmVhY3Rpb24ifQ.gR_VKhINrawjSBwnJQpV8VJah8hZ-Zy_rOwir7ZmLg8"><span>Share</span></a></p></div><p>These vectors help in quickly comparing players, understanding player types, or even predicting game outcomes based on player attributes. Just like in advanced stats or fantasy basketball, where players are often reduced to a set of numbers to predict performance, vector embeddings provide a way to mathematically and visually analyze and predict based on learned relationships and attributes.</p><p>These databases enable efficient similarity searches, making them ideal for applications like recommendation systems, image and text retrieval, and more. Popular vector databases include Amazon OpenSearch Service, Amazon Aurora PostgreSQL-Compatible Edition, Amazon Neptune ML, Amazon MemoryDB for Redis, and Amazon DocumentDB</p><h3><strong>RBAC (Role-Based Access Control)</strong></h3><p>RBAC is a method of regulating access to computer or network resources based on the roles of individual users within an organization. It involves assigning permissions to roles rather than to individual users, simplifying the management of user permissions. Key components of RBAC include roles, permissions, and users. Implementing RBAC enhances security, ensures compliance, and simplifies the management of access control.</p><h3>Using AWS Technologies to Integrate RBAC and FGAC in AI Applications<br></h3><p>Controlling data access is important in the field of AI and machine learning since it not only solves security issues but also makes sure that the system complies with organisational and privacy laws. With improved security features like Role-Based Access Control (RBAC) and Fine-Grained Access Control (FGAC), AWS provides a stable foundation for implementing AI applications. </p><h4>Architecture Overview </h4><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F72ed663c-5924-44fc-9631-2c93d07050dd_1114x641.png" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F72ed663c-5924-44fc-9631-2c93d07050dd_1114x641.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F72ed663c-5924-44fc-9631-2c93d07050dd_1114x641.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F72ed663c-5924-44fc-9631-2c93d07050dd_1114x641.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F72ed663c-5924-44fc-9631-2c93d07050dd_1114x641.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F72ed663c-5924-44fc-9631-2c93d07050dd_1114x641.png" width="1114" height="641" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/72ed663c-5924-44fc-9631-2c93d07050dd_1114x641.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:641,&quot;width&quot;:1114,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:87471,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F72ed663c-5924-44fc-9631-2c93d07050dd_1114x641.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F72ed663c-5924-44fc-9631-2c93d07050dd_1114x641.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F72ed663c-5924-44fc-9631-2c93d07050dd_1114x641.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F72ed663c-5924-44fc-9631-2c93d07050dd_1114x641.png 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a></figure></div><p>The core of our RAG application is a vector database that respects user roles and access privileges while processing, storing, and retrieving data. Data intake starts the process, which ends with safe data retrieval based on the permissions assigned to each user role.</p><p>1. <strong>Data Processing and Vector Generation:</strong></p><ul><li><p><strong>AWS S3</strong> stores raw data, which is ingested by AWS SageMaker for processing.</p></li><li><p><strong>AWS SageMaker</strong> processes the data into vectors. Each vector generated from the raw data is tagged with metadata that includes user role information, dictating who can access this data. This is where embedding of data with security permissions begins.</p></li></ul><p>2. <strong>Secure Data Storage and Access Control:</strong></p><ul><li><p><strong>AWS OpenSearch</strong> is used for storing the generated vectors and facilitating efficient querying. It implements RBAC and FGAC to enforce security measures based on the metadata tags.</p></li></ul><p><strong>Role-Based and Fine-Grained Access Control Mechanisms</strong></p><ul><li><p><strong>RBAC</strong> ensures that only users with appropriate roles can access specific operations within the AWS environment. For example, only data engineers might have the permission to upload new data and trigger processing workflows.</p></li><li><p><strong>FGAC</strong> operates at a more granular level. In OpenSearch, FGAC uses the metadata associated with each vector to determine access rights. For instance, if a vector is tagged with the role &#8216;Researcher&#8217;, only users assigned the &#8216;Researcher&#8217; role can query or view this data.</p></li></ul><p></p><p><strong>Vector Data Structure</strong></p><p>Suppose we have a machine learning application that processes research articles to generate semantic vectors representing their content for a recommendation system. Here&#8217;s an example of how a vector and its associated metadata might be stored in AWS OpenSearch:</p><pre><code>{ "document_id": "doc123", "vector": [0.12, 0.23, 0.31, ..., 0.29], // Example of a 128-dimensional vector "metadata": { "created_by": "researcher01", "role": ["Researcher", "Data Scientist"], "department": "Machine Learning", "access_level": "confidential" } }</code></pre><ul><li><p><strong>document_id</strong>: A unique identifier for the document.</p></li><li><p><strong>vector</strong>: The numerical vector generated by AWS SageMaker from the document&#8217;s content.</p></li><li><p><strong>metadata</strong>: Contains additional data about the document, crucial for access control:</p></li><li><p><strong>created_by</strong>: The user or process that generated this vector.</p></li><li><p><strong>role</strong>: An array that lists all the roles that are authorized to access this vector.</p></li><li><p><strong>department</strong>: The department within the organization that owns or is associated with this data.</p></li><li><p><strong>access_level</strong>: Defines the sensitivity of the data, influencing who can access it.</p></li></ul><h4><strong>Role-Based and Fine-Grained Access Control Mechanisms</strong></h4><p>Here&#8217;s how RBAC and FGAC would work with this vector data:</p><ul><li><p><strong>RBAC (Role-Based Access Control)</strong>:</p><ul><li><p>In RBAC, roles are predefined with certain permissions. For example, users assigned the &#8220;Data Scientist&#8221; role may have permissions to access vectors across multiple projects, whereas &#8220;Researchers&#8221; may only access vectors they or their team created.</p></li></ul></li><li><p><strong>FGAC (Fine-Grained Access Control)</strong>:</p><ul><li><p>FGAC is applied at the document level in OpenSearch. When a query is made, OpenSearch evaluates the role and <em><strong>access_level</strong></em> fields in the metadata against the querying user&#8217;s role and their clearance.</p></li><li><p>For example, if a user with the role &#8220;Intern&#8221; queries for vectors, the system checks the role field of each vector&#8217;s metadata. Since &#8220;Intern&#8221; is not listed, vectors with &#8220;Researcher&#8221; and &#8220;Data Scientist&#8221; roles in their metadata would not be returned to this user.</p></li></ul></li></ul><h5><strong>Querying with Access Controls</strong></h5><p>When a user submits a query, the process might look like this:</p><ol><li><p><strong>User Query</strong>: A &#8220;Data Scientist&#8221; queries for vectors related to a specific machine learning topic.</p></li><li><p><strong>Authentication and Authorization</strong>: The user&#8217;s role is authenticated using their security credentials (e.g., via Cognito).</p></li><li><p><strong>Query Processing</strong>: OpenSearch processes the query. It first filters vectors by checking if the user&#8217;s role matches any of the roles listed in the metadata.role field of each document.</p></li><li><p><strong>Data Retrieval</strong>: Only vectors whose metadata matches the user&#8217;s role and meets other criteria (like access_level) are retrieved and returned to the user.</p></li></ol><p></p><p class="button-wrapper" data-attrs="{&quot;url&quot;:&quot;https://www.tostring.ai/subscribe?&quot;,&quot;text&quot;:&quot;Subscribe now&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a class="button primary" href="https://www.tostring.ai/subscribe?"><span>Subscribe now</span></a></p><p></p><p>Below I rapresented with a sequence diagram the flow of this User Journey</p><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F78baaf48-e327-4d72-befa-57090530db61_1819x719.png" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F78baaf48-e327-4d72-befa-57090530db61_1819x719.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F78baaf48-e327-4d72-befa-57090530db61_1819x719.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F78baaf48-e327-4d72-befa-57090530db61_1819x719.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F78baaf48-e327-4d72-befa-57090530db61_1819x719.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F78baaf48-e327-4d72-befa-57090530db61_1819x719.png" width="1456" height="576" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/78baaf48-e327-4d72-befa-57090530db61_1819x719.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:576,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:91255,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F78baaf48-e327-4d72-befa-57090530db61_1819x719.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F78baaf48-e327-4d72-befa-57090530db61_1819x719.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F78baaf48-e327-4d72-befa-57090530db61_1819x719.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F78baaf48-e327-4d72-befa-57090530db61_1819x719.png 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a></figure></div><ol><li><p><strong>Data Engineer Uploads Documents</strong>:</p><ol><li><p>Documents are uploaded to AWS S3 by the Data Engineer, initiating the data processing sequence.</p></li></ol></li><li><p><strong>Trigger Data Processing in SageMaker</strong>:</p><ol><li><p>The new documents in S3 automatically trigger AWS SageMaker, which begins the vector generation process.</p></li></ol></li><li><p><strong>Apply ML Models in SageMaker</strong>:</p><ol><li><p>AWS SageMaker applies machine learning algorithms to convert raw data into vectors, encapsulating complex data attributes into a numerically accessible format.</p></li></ol></li><li><p><strong>Store Generated Vectors with Metadata in OpenSearch</strong>:</p><ol><li><p>Once vectors are generated, they are stored in AWS OpenSearch along with metadata. This metadata includes role-based permissions, specifying which roles can access or interact with the vectors.</p></li></ol></li><li><p><strong>Apply RBAC &amp; FGAC in OpenSearch</strong>:</p><ol><li><p>As vectors are stored, AWS OpenSearch applies Role-Based Access Control (RBAC) and Fine-Grained Access Control (FGAC). These controls use the embedded metadata to manage access based on the roles specified within the metadata.</p></li></ol></li><li><p><strong>User Sends Query via REST API</strong>:</p><ol><li><p>The user sends a query through the REST API, including an authentication token that helps verify their identity and associated role.</p></li></ol></li><li><p><strong>Authenticate &amp; Process Query in OpenSearch</strong>:</p><ol><li><p>The REST API authenticates the user&#8217;s token, retrieves role information, and passes the query to AWS OpenSearch, where the user&#8217;s role is checked against the roles allowed in the vector metadata.</p></li></ol></li><li><p><strong>Return Query Results</strong>:</p><ol><li><p>OpenSearch filters the query results based on the FGAC settings, ensuring that the user only receives data they are authorized to access based on their role.</p></li></ol></li><li><p><strong>Display Results to User</strong>:</p><ol><li><p>Finally, the filtered results are sent back to the user through the REST API, completing the user&#8217;s request.</p></li></ol></li></ol><p><strong>Note on Metadata and Role Matching:</strong></p><ul><li><p><strong>Embedding Roles in Metadata</strong>: When vectors are stored in OpenSearch, they are tagged with metadata that includes specific role-based permissions. This metadata is crucial for controlling access to the data.</p></li><li><p><strong>Matching Roles During Query Processing</strong>: During the query process, OpenSearch checks the metadata against the authenticated user&#8217;s role. This ensures that each user only accesses vectors they are authorized to see, aligning with security and compliance requirements.</p></li></ul><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc698c51a-12b5-4492-8a18-d0035e3c1a51_4240x2412.png" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc698c51a-12b5-4492-8a18-d0035e3c1a51_4240x2412.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc698c51a-12b5-4492-8a18-d0035e3c1a51_4240x2412.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc698c51a-12b5-4492-8a18-d0035e3c1a51_4240x2412.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc698c51a-12b5-4492-8a18-d0035e3c1a51_4240x2412.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc698c51a-12b5-4492-8a18-d0035e3c1a51_4240x2412.png" width="1456" height="828" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/c698c51a-12b5-4492-8a18-d0035e3c1a51_4240x2412.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:828,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc698c51a-12b5-4492-8a18-d0035e3c1a51_4240x2412.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc698c51a-12b5-4492-8a18-d0035e3c1a51_4240x2412.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc698c51a-12b5-4492-8a18-d0035e3c1a51_4240x2412.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc698c51a-12b5-4492-8a18-d0035e3c1a51_4240x2412.png 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a><figcaption class="image-caption">Credits to <a href="https://aws.amazon.com/blogs/big-data/data-governance-in-the-age-of-generative-ai/">https://aws.amazon.com/blogs/big-data/data-governance-in-the-age-of-generative-ai/</a></figcaption></figure></div><p>In order to protect user privacy, assure compliance, and preserve data security, AI applications must be equipped with strong Role-Based and Fine-Grained Access Control methods. By combining AWS services like S3 for data management, OpenSearch for safe data storage and querying, and SageMaker for vector generation, enterprises can build complex RAG systems that strike a compromise between strict access rules and sophisticated data retrieval capabilities. This methodology not only enables people to effectively engage with AI-driven insights and data, but it also protects sensitive data by implementing stringent access controls. Through the integration of security throughout the whole data lifecycle, from retrieval to ingestion, organisations may optimise AI technologies while upholding optimal standards for data governance and security. This elaborate arrangement serves as an example of how AI can be both powerful and secure.</p><div class="subscription-widget-wrap-editor" data-attrs="{&quot;url&quot;:&quot;https://www.tostring.ai/subscribe?&quot;,&quot;text&quot;:&quot;Subscribe&quot;,&quot;language&quot;:&quot;en&quot;}" data-component-name="SubscribeWidgetToDOM"><div class="subscription-widget show-subscribe"><div class="preamble"><p class="cta-caption">toString() is a reader-supported publication. To receive new posts and support my work, consider becoming a free or paid subscriber.</p></div><form class="subscription-widget-subscribe"><input type="email" class="email-input" name="email" placeholder="Type your email&#8230;" tabindex="-1"><input type="submit" class="button primary" value="Subscribe"><div class="fake-input-wrapper"><div class="fake-input"></div><div class="fake-button"></div></div></form></div></div><p></p> ]]>
</content:encoded>
</item>
<item>
<title>
<![CDATA[ AI Agents in Software ]]>
</title>
<description>
<![CDATA[ Adding reasoning capability to software ]]>
</description>
<link>https://www.tostring.ai/p/ai-agents-in-software</link>
<guid isPermaLink="true">https://www.tostring.ai/p/ai-agents-in-software</guid>
<dc:creator>
<![CDATA[ Marco Altea ]]>
</dc:creator>
<pubDate>Mon, 29 Apr 2024 12:44:48 GMT</pubDate>
<enclosure url="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc3e56011-6657-491b-874e-da79ebeb4526_841x792.png" length="0" type="image/jpeg"/>
<content:encoded>
<![CDATA[ <p>Hey, hey, I've been away for a bit, focusing on training and racing the London Marathon, yet I haven't stopped writing. In fact, I launched a new blog about my running journey. You can check it out </p><div class="embedded-publication-wrap" data-attrs="{&quot;id&quot;:2516894,&quot;name&quot;:&quot;Marco can't run!&quot;,&quot;logo_url&quot;:&quot;https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2752f5a1-f0dd-49b3-967a-5a08faa49c2f_1280x1280.png&quot;,&quot;base_url&quot;:&quot;https://marcocantrun.substack.com&quot;,&quot;hero_text&quot;:&quot;Keeping track of my running&quot;,&quot;author_name&quot;:&quot;Marco Altea&quot;,&quot;show_subscribe&quot;:true,&quot;logo_bg_color&quot;:&quot;#ffffff&quot;,&quot;language&quot;:&quot;en&quot;}" data-component-name="EmbeddedPublicationToDOMWithSubscribe"><div class="embedded-publication show-subscribe"><a class="embedded-publication-link-part" native="true" href="https://marcocantrun.substack.com?utm_source=substack&amp;utm_campaign=publication_embed&amp;utm_medium=web"><img class="embedded-publication-logo" src="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2752f5a1-f0dd-49b3-967a-5a08faa49c2f_1280x1280.png" width="56" height="56" style="background-color: #ffffff"><span class="embedded-publication-name">Marco can't run!</span><div class="embedded-publication-hero-text">Keeping track of my running</div><div class="embedded-publication-author-name">By Marco Altea</div></a><form class="embedded-publication-subscribe" method="GET" action="https://marcocantrun.substack.com/subscribe?"><input type="hidden" name="source" value="publication-embed"><input type="hidden" name="autoSubmit" value="true"><input type="email" class="email-input" name="email" placeholder="Type your email..."><input type="submit" class="button primary" value="Subscribe"></form></div></div><p>Now, back to our shared passion for software engineering. Recently, both professionally and personally, I've been exploring AI Agents. Let me explain what these are.</p><blockquote><p><em>AI Agents are software programs equipped with data access, algorithms, reasoning, and conversational abilities. They dynamically interact with their environment and its inputs to autonomously perform tasks and achieve specific goals.</em></p></blockquote><p>AI Agents can be classified based on their functionality, the complexity of tasks they handle, and the environment in which they operate. Here&#8217;s a list of common types of AI Agents:</p><h5>Reactive Agents</h5><p><em>Description</em>: Reactive agents operate based on the current status, ignoring any previous history. They directly link their current state to actions and are designed to respond to specific situations.</p><p><em>Example</em>: A simple home thermostat that adjusts heating based on temperature changes.</p><h5>Model-Based Agents</h5><p><em>Description</em>: These agents have an internal model of the world and use it to make decisions based on how the world changes in response to their actions. They maintain a state over time to track the environment.</p><p><em>Example</em>: A navigation system in a car that updates its route based on traffic conditions.</p><h5>Goal-Based Agents</h5><p><em>Description</em>: Goal-based agents act to achieve specific goals and can consider various actions to choose the most appropriate path. They use a form of predictive modeling to foresee the outcome of actions.</p><p><em>Example</em>: An investment AI that manages a portfolio with the goal of maximizing returns based on market predictions.</p><h5>Utility-Based Agents</h5><p><em>Description</em>: These agents not only strive to achieve a goal but also do so by maximizing a utility function, which is a measure of their happiness or satisfaction. They evaluate the potential outcomes based on a preference hierarchy.</p><p><em>Example</em>: A smart home system that adjusts lighting, heating, and security settings not just to satisfy predefined conditions but to optimize comfort and energy efficiency.</p><h5>Learning Agents</h5><p><em>Description</em>: Learning agents improve their performance and adapt to changing environments over time. They have the capability to learn from past actions and improve their strategies dynamically.</p><p><em>Example</em>: A recommendation system for streaming services like Netflix or Spotify that adapts to user preferences over time to improve recommendation accuracy.</p><h5>Hybrid Agents</h5><p><em>Description</em>: These agents combine characteristics of different types, often integrating reactive and deliberative capabilities, to perform complex functions that require a variety of skills.</p><p><em>Example</em>: Advanced robotics used in manufacturing that can perform pre-programmed tasks while adapting to new efficiencies or unexpected obstacles.</p><p>Now that we have a better understanding of AI Agents, their types, and capabilities, let&#8217;s go into a real example that I implemented the first weekend after the London Marathon (yes, I&#8217;m taking a moment to brag about that :) ).</p><p>Leveraging my ecommerce experience I develop a simple agent called</p><h3>Intelligent Product Description Enhancement Agent</h3><p><strong>DescriboBot</strong>, sorry for the name, GPT suggested it and as you know as a SWE I could lose weeks naming a variable or a project :), is an AI Agent designed to streamline and enhance the quality of product descriptions within an e-commerce platform. It stands as an intermediary between the user that could be a typical ecommerce manager and multiple data sources, utilizing a feedback loop to refine the generated content.</p><h6></h6><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc3e56011-6657-491b-874e-da79ebeb4526_841x792.png" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc3e56011-6657-491b-874e-da79ebeb4526_841x792.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc3e56011-6657-491b-874e-da79ebeb4526_841x792.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc3e56011-6657-491b-874e-da79ebeb4526_841x792.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc3e56011-6657-491b-874e-da79ebeb4526_841x792.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc3e56011-6657-491b-874e-da79ebeb4526_841x792.png" width="841" height="792" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/c3e56011-6657-491b-874e-da79ebeb4526_841x792.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:792,&quot;width&quot;:841,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:205768,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc3e56011-6657-491b-874e-da79ebeb4526_841x792.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc3e56011-6657-491b-874e-da79ebeb4526_841x792.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc3e56011-6657-491b-874e-da79ebeb4526_841x792.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc3e56011-6657-491b-874e-da79ebeb4526_841x792.png 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a></figure></div><p>Looking at this diagram, let me try to explain the flow of the information:<br></p><p>The ecommerce manager interacts with DescriboBot (1), asking the agent to review the product descriptions that exist in the ecommerce engine. The agent then communicates with an e-commerce API (2), fetching product information and descriptions which are stored in the ecommerce PIM (Product Information Management) system.</p><p>The DescriboBot leverage a Language Model (LLM) (3) to analyse and process the product descriptions, utilizing advanced algorithms and natural language processing techniques to generate a specific feedback and a score related to each product description and an improved Product description content based on the LLM feedback.</p><p>Each feedback, score and proposed content are then stored in a data storage (4)</p><p>Once the AI Agent has crafted an enhanced product description, it interfaces with the Feedback Loop API (5). This API drives the ongoing enhancement of descriptions through a dynamic, iterative process. It enables e-commerce managers to review generated feedback, assess and suggest content, and provide human feedback. If the feedback indicates the need for improvement, it triggers the generation of a new product description.</p><p>Finally, the updated product description is pushed back to the e-commerce platform (6), completing the cycle. This process ensures that product descriptions are not only crafted to a high standard but also evolve to meet user preferences and behaviours, contributing to a more engaging shopping experience.</p><h3><strong>Inside the Code: A File-by-File Breakdown</strong></h3><p>I uploaded here the code <a href="https://github.com/skenklok/DescriboBot">DescriboBot repository</a> let&#8217;s analyse the code </p><p><strong>app.py</strong>: This is the heart of <strong>DescriboBot</strong>, where the Flask web server is defined. It serves as the interface for user interactions, managing both the input and output of product descriptions. Through this script, DescriboBot receives user feedback, communicates with the feedback storage, and invokes the <strong>Langchain-enhanced </strong>regeneration process of product descriptions.</p><p><strong>description_eval.py</strong>: Key to DescriboBot's intelligent operation, this script is where Langchain shines. Langchain is an advanced library that bridges the gap between language models like OpenAI's GPT and application-specific logic. In DescriboBot, it is tasked with the function of evaluating and regenerating product descriptions, applying natural language understanding and generation techniques to refine content.</p><p>By integrating with Langchain, DescriboBot is able to leverage large language models in a plug-and-play fashion, simplifying the integration of complex AI functionalities into everyday applications. Langchain is a framework that allows developers to build sequences of operations&#8212;chains&#8212;that can include transformations, extractions, and reasoning based on language inputs. This makes DescriboBot not only reactive to feedback but also proactively improving in a way that mirrors human learning and reasoning.</p><h3>Test</h3><p>when I run <code>python3 app.py</code></p><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F26c36511-fa9c-4271-9348-d0b6f6ea1626_1888x904.png" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F26c36511-fa9c-4271-9348-d0b6f6ea1626_1888x904.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F26c36511-fa9c-4271-9348-d0b6f6ea1626_1888x904.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F26c36511-fa9c-4271-9348-d0b6f6ea1626_1888x904.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F26c36511-fa9c-4271-9348-d0b6f6ea1626_1888x904.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F26c36511-fa9c-4271-9348-d0b6f6ea1626_1888x904.png" width="1456" height="697" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/26c36511-fa9c-4271-9348-d0b6f6ea1626_1888x904.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:697,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:258547,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F26c36511-fa9c-4271-9348-d0b6f6ea1626_1888x904.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F26c36511-fa9c-4271-9348-d0b6f6ea1626_1888x904.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F26c36511-fa9c-4271-9348-d0b6f6ea1626_1888x904.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F26c36511-fa9c-4271-9348-d0b6f6ea1626_1888x904.png 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a></figure></div><p>The agent is able to fetch the products from the PIM, print the <strong>Original description</strong>, provide feedback as <strong>Suggested Improvement</strong> then providing a new generated content for that specific product description.</p><p>This data is all stored, in this example in an in memory storage, in a hypothetical user journey the ecommerce manager can review each feedback and proposal and provide feedback, for example a negative one that we can provide using a REST API</p><p><code>curl -X POST http://localhost:5000/submit_feedback \</code></p><p><code>-H "Content-Type: application/json" \</code></p><p><code>-d '{"product_id": "PRD_1", "rating": 2, "user_feedback": "Poor description. Needs improvement."}'</code></p><p><code>{"message":"Feedback received and processing","status":"success"}</code></p><p>Once this request is received by the server, you can see <strong>Regenerated Description for Product PRD_1 </strong>- completely the feedback loop and setting the product description ready to be pushed back to the PIM.</p><div class="subscription-widget-wrap-editor" data-attrs="{&quot;url&quot;:&quot;https://www.tostring.ai/subscribe?&quot;,&quot;text&quot;:&quot;Subscribe&quot;,&quot;language&quot;:&quot;en&quot;}" data-component-name="SubscribeWidgetToDOM"><div class="subscription-widget show-subscribe"><div class="preamble"><p class="cta-caption">toString() is a reader-supported publication. To receive new posts and support my work, consider becoming a free or paid subscriber.</p></div><form class="subscription-widget-subscribe"><input type="email" class="email-input" name="email" placeholder="Type your email&#8230;" tabindex="-1"><input type="submit" class="button primary" value="Subscribe"><div class="fake-input-wrapper"><div class="fake-input"></div><div class="fake-button"></div></div></form></div></div><p></p><h4><strong>AI Agent Type: Utility and Learning Combined</strong></h4><p>DescriBot could be best classified as a <strong>Utility-Based Agent with Learning capabilities. As a Utility-Based Agent</strong>, it is designed to optimize the quality of product descriptions, aiming to maximize a specific utility function&#8212;here, the effectiveness of e-commerce content for engaging customers and potentially improving SEO. Its goal is not merely to perform a task but to perform it in the best way possible, as evidenced by the generation of detailed, informative product descriptions.</p><p>Additionally, the agent exhibits learning capabilities. It iteratively improves its performance by incorporating human feedback into subsequent iterations of content generation. This feedback loop enables the agent to refine its understanding of what constitutes a 'better' description, demonstrating a capacity for adaptation and growth over time&#8212;key traits of a Learning Agent.</p><p class="button-wrapper" data-attrs="{&quot;url&quot;:&quot;https://www.tostring.ai/p/ai-agents-in-software/comments&quot;,&quot;text&quot;:&quot;Leave a comment&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a class="button primary" href="https://www.tostring.ai/p/ai-agents-in-software/comments"><span>Leave a comment</span></a></p><p>In summary, AI Agents like the one I've examined represent a very powerful way to build software utility that can perform complex task without a human supervision. By leveraging these agents, we can automate complex tasks with a level of precision that was once out of reach. The "DescriBot" stands as an example of practical AI application in software engineering&#8212;a tool that not only performs its given task but learns and evolves to do it better over time.</p><p>As we continue to develop and refine these agents, the potential for improved efficiency and effectiveness in our software is substantial. For developers, the implications are clear: integrating AI Agents into our solutions can significantly elevate the quality of our work and the satisfaction of our users.</p><p></p><p></p> ]]>
</content:encoded>
</item>
<item>
<title>
<![CDATA[ Data Debt > Tech Debt ]]>
</title>
<description>
<![CDATA[ Tech Debt is Just the Tip of the Iceberg &#8211; Welcome to the Deep Waters of Data Debt ]]>
</description>
<link>https://www.tostring.ai/p/data-debt-tech-debt</link>
<guid isPermaLink="true">https://www.tostring.ai/p/data-debt-tech-debt</guid>
<dc:creator>
<![CDATA[ Marco Altea ]]>
</dc:creator>
<pubDate>Tue, 23 Jan 2024 10:41:31 GMT</pubDate>
<enclosure url="https://substack-post-media.s3.amazonaws.com/public/images/2d3342f1-1a6a-416e-b560-fca36150c657_1024x1024.png" length="0" type="image/jpeg"/>
<content:encoded>
<![CDATA[ <p>In recent years, I've collaborated with numerous companies embarking on a journey to harness the vast amounts of data generated every second. What I've found is a landscape rife with terror and panic, further exacerbated in the last year by the hype surrounding Generative AI, especially the ChatGPT phenomenon. </p><p>The classic question has been</p><div class="pullquote"><p>How can we leverage Generative AI in our business?</p></div><p>The response tends to be less exhilarating than anticipated, primarily because the effective utilization of AI hinges on a critical element: <strong>DATA</strong>.</p><p>Understanding an organization's data maturity is essential in this context. Data maturity refers to an organization's capability to effectively</p><ul><li><p>Manage Data</p></li><li><p>Process Data</p></li><li><p>Use Data</p></li></ul><p>It includes various elements such as data quality, systems for data management, the extent of data integration throughout the organization, and the capability to utilize data for strategic insights and decision-making.</p><p>When an organization exhibits low data maturity, it typically faces several challenges. Firstly, there's often a lack of clarity regarding the data they possess, leading to underutilization of valuable assets. Secondly, the absence of robust data governance mechanisms results in unchecked data inflows and outflows, compromising data integrity and security. Inconsistencies in data further complicate analysis and decision-making processes. Additionally, such organizations usually incur significant costs in data consumption and sharing between systems, as inefficiencies and redundancies hamper smooth data integration.</p><div class="subscription-widget-wrap-editor" data-attrs="{&quot;url&quot;:&quot;https://www.tostring.ai/subscribe?&quot;,&quot;text&quot;:&quot;Subscribe&quot;,&quot;language&quot;:&quot;en&quot;}" data-component-name="SubscribeWidgetToDOM"><div class="subscription-widget show-subscribe"><div class="preamble"><p class="cta-caption">toString() is a reader-supported publication. To receive new posts and support my work, consider becoming a free or paid subscriber.</p></div><form class="subscription-widget-subscribe"><input type="email" class="email-input" name="email" placeholder="Type your email&#8230;" tabindex="-1"><input type="submit" class="button primary" value="Subscribe"><div class="fake-input-wrapper"><div class="fake-input"></div><div class="fake-button"></div></div></form></div></div><p>I usually call this scenario a <em><strong>Data Debt</strong></em> scenario.</p><p>We are all familiar with the term tech debt and its meaning in Software Engineering</p><div class="pullquote"><p>In software development, is the implied cost of future reworking required when choosing an easy but limited solution instead of a better approach that could take more time<a class="footnote-anchor" data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-1" href="#footnote-1" target="_self">1</a></p></div><p>In my role as a Software Engineer, I've both accumulated and addressed technical debt. It's a universal truth in software development: all software has some degree of technical debt. This is an inherent aspect of software as a dynamic entity, constantly evolving to meet changing needs and requirements. In certain projects, I've observed technical debt reach such critical levels that a thorough trade-off analysis recommended either a complete rebuild of the platform (an amazing story is described <a href="https://blog.pragmaticengineer.com/uber-app-rewrite-yolo/">HERE</a> by <span class="mention-wrap" data-attrs="{&quot;name&quot;:&quot;Gergely Orosz&quot;,&quot;id&quot;:30107029,&quot;type&quot;:&quot;user&quot;,&quot;url&quot;:null,&quot;photo_url&quot;:&quot;https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F802a32bb-2048-428b-bdb5-d6acd1e2b2d5_48x48.png&quot;,&quot;uuid&quot;:&quot;468b2c63-f2e5-4d57-bd93-e8c275c31a72&quot;}" data-component-name="MentionToDOM"></span> in his <span class="mention-wrap" data-attrs="{&quot;name&quot;:&quot;The Pragmatic Engineer&quot;,&quot;id&quot;:458709,&quot;type&quot;:&quot;pub&quot;,&quot;url&quot;:&quot;https://open.substack.com/pub/pragmaticengineer&quot;,&quot;photo_url&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/5ecbf7ac-260b-423b-8493-26783bf01f06_600x600.png&quot;,&quot;uuid&quot;:&quot;7d3cef8a-0f97-4cf9-aa0d-f526bf4e99ea&quot;}" data-component-name="MentionToDOM"></span>) or replacement with an off-the-shelf solution. While such measures might appear extreme or perceived as a disregard for previous investments, drastic and sudden shifts in circumstances can sometimes leave no alternative.</p><p>As an Architect working in large, data-intensive systems, I've observed a crucial distinction in handling technical and data-related debts. In software systems, addressing technical debt often involves rebuilding or replacing the underlying architecture or code &#8211; essentially, the tools facilitating value exchange. However, when it comes to data debt, this approach is not feasible. Data itself embodies the value, and unlike tools, it cannot simply be replaced. </p><div class="pullquote"><p>Data is the new oil<a class="footnote-anchor" data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-2" href="#footnote-2" target="_self">2</a></p></div><p>For instance, consider an organization grappling with substantial data debt. The data, being the core asset, holds intrinsic value and insights crucial for the organization's operations and strategic decisions. If this data is plagued with inconsistencies, redundancies, or accessibility issues, it directly impacts the organization's ability to operate efficiently and make informed decisions. Unlike software components, data cannot be discarded and rewritten from scratch without losing valuable insights and historical context. </p><p>Therefore, the strategy to mitigate data debt requires a nuanced approach. It involves rigorous data governance, quality control, and the implementation of robust data management practices. These measures ensure that the data remains accurate, consistent, and accessible, thereby sustaining the organization's ability to leverage it for strategic advantage.</p><p>Let me try to draw you an example scenario of how this work in the real world </p><h4>Scenario:</h4><p>GreenTech, a mid-sized eco-friendly products company, has been operating a successful e-commerce platform for the past five years. The platform, built on a legacy e-commerce engine, has served its purpose but is now struggling to keep up with the evolving market demands and technological advancements. GreenTech's leadership decides to replace the outdated e-commerce engine with a more modern, scalable solution. </p><p>However, a significant challenge emerges as they go deeper into the migration process. GreenTech's data landscape is a complex web of storage systems spread across the organization. Over the years, data duplication, lack of integration, and insufficient documentation have led to a convoluted and inefficient data environment. This scenario presents two distinct types of technical debt:</p><h4>1. E-commerce Engine Debt:</h4><p> - <strong>Nature</strong>: This debt is primarily technology-focused, centred around the outdated e-commerce engine.</p><p> - <strong>Solution</strong>: Replacing the old engine with a new, modern system is straightforward. The new system, offers improved scalability, flexibility, and better integration capabilities with contemporary tools and platforms.</p><p> - <strong>Challenge</strong>: While the technical aspect of this debt is addressable through replacement, ensuring seamless migration of existing data and integration with other company systems requires meticulous planning.</p><h4>2. <strong>Data Landscape Debt</strong>:</h4><p> - <strong>Nature</strong>: This debt is more intricate, stemming from years of ad-hoc data storage practices, resulting in duplicated, scattered, and poorly integrated data.</p><p> - <strong>Solution</strong>: Unlike the e-commerce engine, this debt cannot be resolved through a simple replacement. It requires a comprehensive audit of the existing data landscape, identification of data duplication, and development of a unified data management strategy.</p><p> - <strong>Approach</strong>: Implementing a central data warehouse or data lake can consolidate data storage. Additionally, employing data governance practices and documentation will ensure future data integrity and accessibility. This process involves not just technological changes, but also organizational and process adjustments.</p><h4>Leasson Learned:</h4><p>In GreenTech's scenario, while the e-commerce engine debt is resolved by a technology upgrade, the data landscape debt demands a more holistic approach. It requires a blend of technological solutions, process re-engineering, and cultural change within the organization to foster better data management practices. In conclusion, when comparing technical debt and data debt in the context of the GreenTech example scenario, it's crucial to understand their distinct cost implications.<em><strong> Technical debt</strong></em>, often stemming from expedient but suboptimal design or coding choices, carries a cost primarily in terms of future code maintenance and potential refactoring. It's a debt of development shortcuts and compromises, which, while costly, is often contained within the realm of software development processes.</p><p><em><strong>Data debt</strong></em>, on the other hand, is typically more onerous in terms of cost - monetary, time, effort, and human resources. This is because data debt include not only the technological aspects but also the broader implications on business operations, decision-making, and strategic planning. Data debt can arise from issues such as poor data quality, lack of data governance, outdated data models, or inadequate data integration. Its resolution requires a multi-faceted approach involving not just technological fixes but also changes in organizational processes, data governance policies, and potentially, a cultural shift in how data is perceived and managed across the organization.</p><p>In the GreenTech scenario, addressing data debt could involve extensive data cleaning, implementing new data governance protocols, retraining staff, and perhaps even overhauling entire systems to ensure data integrity and relevance. The costs here are not just financial, but also involve significant time and effort in reorienting the organization&#8217;s data practices. The human resource investment is also substantial, as it may require specialized skills in data management, governance, and analysis, which are often in high demand.</p><blockquote><p>Therefore, while both types of debt incur costs, data debt often proves more challenging and expensive to resolve, given its pervasive impact on the broader organizational ecosystem. It underscores the importance of proactive data management strategies to mitigate these costs and align data practices with the organization's evolving needs and goals.</p></blockquote><p>Now imagine a company like GreenTech eager to implement Generative AI functionalities. As Architects, our duty extends beyond mere implementation. It is imperative to first conduct a thorough evaluation of the company&#8217;s existing data infrastructure and maturity. This involves assessing the quality, integration, and governance of their current data systems. Our role is to guide GreenTech in understanding that the successful deployment of Generative AI technologies relies heavily on the robustness of their data architecture. We need to advise them on the necessary steps to enhance their data management capabilities, ensuring that their data ecosystem is primed for the complexities and demands of advanced AI applications. This strategic approach not only aligns with technological advancements but also positions the company to harness the full potential of Generative AI, thereby driving meaningful and sustainable business outcomes. </p><p>In such a scenario, the initial focus should not be on selecting the AI model or determining the most suitable MLOps architecture. Instead, the starting point must be a fundamental reshaping of how data is collected, stored, managed, and consumed across the organization. This approach represents a significant shift in focus for executives, who must prioritize <em><strong>foundational data management strategies</strong></em> over being swayed by the prevailing hype around technologies like ChatGPT.</p><p>In my experience, this challenge is often overlooked in the rush to adopt new technologies. Yet, it is crucial to understand that the successful implementation of any advanced AI or machine learning solution, including generative AI, is deeply rooted in the organization's data infrastructure. Without a robust, efficient, and coherent data management framework, even the most advanced AI technologies will struggle to deliver their full potential.</p><p>Therefore, before going into the implementation of AI capabilities, it is essential for organizations to critically assess and, if necessary, overhaul their data practices. This involves ensuring data integrity, eliminating redundancies, integrating disparate data sources, and establishing clear governance and management protocols. Only with these foundational elements in place can organizations truly leverage the power of advanced AI technologies in a meaningful and sustainable way.</p><p>In conclusion, while the allure of rapidly implementing genAI functionalities like ChatGPT is undeniable, it's crucial to anchor our approach and expectation in the reality of data management and organizational readiness. I invite you to reflect on how your organization manages its data ecosystem and consider whether it's truly primed to leverage advanced AI technologies effectively. Share your thoughts, experiences, or any challenges you've faced in aligning your data strategies with emerging AI trends</p><p class="button-wrapper" data-attrs="{&quot;url&quot;:&quot;https://www.tostring.ai/p/data-debt-tech-debt/comments&quot;,&quot;text&quot;:&quot;Leave a comment&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a class="button primary" href="https://www.tostring.ai/p/data-debt-tech-debt/comments"><span>Leave a comment</span></a></p><div class="footnote" data-component-name="FootnoteToDOM"><a id="footnote-1" href="#footnote-anchor-1" class="footnote-number" contenteditable="false" target="_self">1</a><div class="footnote-content"><p>https://en.wikipedia.org/wiki/Technical_debt</p></div></div><div class="footnote" data-component-name="FootnoteToDOM"><a id="footnote-2" href="#footnote-anchor-2" class="footnote-number" contenteditable="false" target="_self">2</a><div class="footnote-content"><p>Clive Humby - British mathematician - 2006</p><p></p></div></div> ]]>
</content:encoded>
</item>
<item>
<title>
<![CDATA[ Orchestrating the ML Lifecycle: An Engineering Blueprint ]]>
</title>
<description>
<![CDATA[ Constructing Scalable ML Architectures: A Step-by-Step overview ]]>
</description>
<link>https://www.tostring.ai/p/orchestrating-the-ml-lifecycle-an</link>
<guid isPermaLink="true">https://www.tostring.ai/p/orchestrating-the-ml-lifecycle-an</guid>
<dc:creator>
<![CDATA[ Marco Altea ]]>
</dc:creator>
<pubDate>Thu, 07 Dec 2023 13:14:15 GMT</pubDate>
<enclosure url="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe576373b-9190-4b54-b745-e47b7275b710_821x581.png" length="0" type="image/jpeg"/>
<content:encoded>
<![CDATA[ <p>2023 hit, and there I was, as an architect traditionally dealing with predictable systems, yet I found myself intrigued by the ever-evolving beast that is Machine Learning (ML). Welcoming OpenAI ChatGPT, I started to deepen my knowledge by reading books like "<a href="https://d2l.ai/index.html">Dive into Deep Learning</a>", using IBM resources about <a href="https://dataplatform.cloud.ibm.com/docs/content/wsj/wmls/wmls-deploy-overview.html?context=cpdaas">Deploying and managing models</a> and delving into AWS and NVIDIA's documentation, it struck me &#8211; ML is a whole different game.</p><p>The more I read about advanced deep learning architectures, the more I realized my architecture background wasn&#8217;t just ready for this &#8220;game&#8221;. These resources weren't just informative; they were a wake-up call. ML isn't just about algorithms and data; it's about the interplay of components, challenges, and the tough calls you need to make as an architect.</p><p>So here's my angle: How does an ML architecture actually work? What are its moving parts? And most importantly, what are the trade-offs and decisions that keep an ML architect awake at night? This blog post is my dive into these questions, driven by a blend of professional curiosity and a desire to understand the mechanics behind these powerful systems.</p><div class="subscription-widget-wrap-editor" data-attrs="{&quot;url&quot;:&quot;https://www.tostring.ai/subscribe?&quot;,&quot;text&quot;:&quot;Subscribe&quot;,&quot;language&quot;:&quot;en&quot;}" data-component-name="SubscribeWidgetToDOM"><div class="subscription-widget show-subscribe"><div class="preamble"><p class="cta-caption">toString() is a reader-supported publication. To receive new posts and support my work, consider becoming a free or paid subscriber.</p></div><form class="subscription-widget-subscribe"><input type="email" class="email-input" name="email" placeholder="Type your email&#8230;" tabindex="-1"><input type="submit" class="button primary" value="Subscribe"><div class="fake-input-wrapper"><div class="fake-input"></div><div class="fake-button"></div></div></form></div></div><h3>The Machine Learning Lifecycle</h3><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3e8c6e88-9c51-45ab-90e8-8113118c5b11_2881x922.png" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3e8c6e88-9c51-45ab-90e8-8113118c5b11_2881x922.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3e8c6e88-9c51-45ab-90e8-8113118c5b11_2881x922.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3e8c6e88-9c51-45ab-90e8-8113118c5b11_2881x922.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3e8c6e88-9c51-45ab-90e8-8113118c5b11_2881x922.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3e8c6e88-9c51-45ab-90e8-8113118c5b11_2881x922.png" width="1456" height="466" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/3e8c6e88-9c51-45ab-90e8-8113118c5b11_2881x922.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:466,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:238743,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3e8c6e88-9c51-45ab-90e8-8113118c5b11_2881x922.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3e8c6e88-9c51-45ab-90e8-8113118c5b11_2881x922.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3e8c6e88-9c51-45ab-90e8-8113118c5b11_2881x922.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3e8c6e88-9c51-45ab-90e8-8113118c5b11_2881x922.png 1456w" sizes="100vw" fetchpriority="high"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a><figcaption class="image-caption">Machine Learning lifecycle - (image created by the author)</figcaption></figure></div><p>In the image I've drawn (see Machine Learning Lifecycle diagram), the journey of an ML project begins with a clearly defined problem statement, rooted in a thorough business analysis. This is where we, as architects, lay down the groundwork by translating a business problem into an ML problem. The initial phase is all about understanding the data landscape &#8211; pinpointing the required data and dissecting the available raw data &#8211; which sets the stage for the feature engineering process.</p><p><strong>Feature engineering</strong>, a critical and creative phase, involves defining rules that transform raw data into a format palatable for ML models. This process flows into a structured ETL pipeline where data is extracted, transformed, and subsequently loaded, ready for the model development phase.</p><p>As we transition to <strong>Experimentation</strong>, models undergo rigorous training, tuning, and evaluation. This iterative process is a balancing act between model complexity and performance, often influenced by the quality of the engineered features. The feature store system comes into play here, acting as a repository that provides both low and normal latency access to feature sets for real-time inference and batch processing</p><p>The <strong>Orchestration</strong> of these processes is crucial, which is where the scheduler steps in, ensuring that new data triggers model re-training and validation. Embracing MLOps principles, we automate the flow from data extraction to preparation and model training, encapsulating these within CI/CD practices for seamless integration and development.</p><p>At the heart of this lifecycle lies the <strong>Model Registry</strong>, a vault that not only stores model artefacts but also tracks their lineage &#8211; a vital component for version control and compliance. It is here that models are prepped for their final destination &#8211; deployment into production. This phase includes a staging environment to validate models for security and robustness before they&#8217;re served via a robust model serving infrastructure.</p><p>The endgame of this lifecycle is a continuous<strong> Feedback Loop</strong>, a mechanism that doesn't just propel iterative improvement but also guards against model drift in the production environment. Monitoring tools keep a vigilant eye on model performance, ensuring that any deviations are promptly flagged and rectified.</p><p></p><h3>Machine Learning Architecture</h3><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8cd550ef-acd3-47e6-af06-051fc92c5ee8_2096x671.jpeg" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8cd550ef-acd3-47e6-af06-051fc92c5ee8_2096x671.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8cd550ef-acd3-47e6-af06-051fc92c5ee8_2096x671.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8cd550ef-acd3-47e6-af06-051fc92c5ee8_2096x671.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8cd550ef-acd3-47e6-af06-051fc92c5ee8_2096x671.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8cd550ef-acd3-47e6-af06-051fc92c5ee8_2096x671.jpeg" width="1456" height="466" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/8cd550ef-acd3-47e6-af06-051fc92c5ee8_2096x671.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:466,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:89394,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8cd550ef-acd3-47e6-af06-051fc92c5ee8_2096x671.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8cd550ef-acd3-47e6-af06-051fc92c5ee8_2096x671.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8cd550ef-acd3-47e6-af06-051fc92c5ee8_2096x671.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8cd550ef-acd3-47e6-af06-051fc92c5ee8_2096x671.jpeg 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a><figcaption class="image-caption">Machine Learning Architecture Blueprint (Image created by the author)</figcaption></figure></div><p>Let&#8217;s analyse a typical ML Architecture piece by piece </p><h4>Data Sources</h4><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F78928ac1-13c0-422d-8d14-a15ed7c15b37_351x481.jpeg" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F78928ac1-13c0-422d-8d14-a15ed7c15b37_351x481.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F78928ac1-13c0-422d-8d14-a15ed7c15b37_351x481.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F78928ac1-13c0-422d-8d14-a15ed7c15b37_351x481.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F78928ac1-13c0-422d-8d14-a15ed7c15b37_351x481.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F78928ac1-13c0-422d-8d14-a15ed7c15b37_351x481.jpeg" width="351" height="481" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/78928ac1-13c0-422d-8d14-a15ed7c15b37_351x481.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:481,&quot;width&quot;:351,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:10450,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F78928ac1-13c0-422d-8d14-a15ed7c15b37_351x481.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F78928ac1-13c0-422d-8d14-a15ed7c15b37_351x481.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F78928ac1-13c0-422d-8d14-a15ed7c15b37_351x481.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F78928ac1-13c0-422d-8d14-a15ed7c15b37_351x481.jpeg 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a></figure></div><p>In the 'Data Source' phase of the ML Lifecycle, we're in the domain of data analysis and extraction&#8212; a fundamental step where data from streaming inputs, batch processing, and cloud storage converge. The intent here is to lay a solid foundation by amassing a broad spectrum of data that underpins the machine learning models we aim to construct. It's about scouting the landscape for data that can be harnessed to predict outcomes with precision, forming the raw material for the feature engineering to come. Technologies at play include data lakes and warehouses that serve as repositories for this eclectic mix of data, with tools like Apache Hadoop for batch data and cloud services such as AWS S3 for storing vast labeled datasets. Market offerings range from cloud-based platforms that offer integrated data sourcing solutions to open-source frameworks geared towards data ingestion and preliminary analysis. For instance, organizations like financial institutions may tap into this phase by pooling transactional data, customer interactions, and market trends, laying the groundwork for predictive analytics in fraud detection or customer behavior modeling. The challenge lies in sifting through this expanse to identify data that truly informs the ML problem at hand&#8212;where relevance is king, and the chaff must be separated from the wheat.</p><p>Navigating the 'Data Source' phase comes with its own set of limitations and trade-offs that need astute consideration. When focusing on streaming data, you're faced with the high-stakes balance of capturing real-time insights against the backdrop of potential latency and significant infrastructure investments. On the flip side, batch data processing, while more forgiving on timing, can result in a lag in the freshness of insights, which might be a deal-breaker in fast-paced industries.</p><p>Choosing the right cloud storage often becomes a game of balancing cost against scalability and integration with existing systems. Here's the rub: the more comprehensive your data sources, the more complex and resource-intensive the data management becomes. It's about striking that balance between breadth and depth of data without sinking into the quicksand of information overload.</p><p>Take the likes of large e-commerce platforms, for instance. They grapple with these trade-offs daily, deciding how to store and process customer data to provide personalized experiences without inflating costs or sacrificing performance. This is the tightrope walk of the data source stage, where every step forward is measured against potential pitfalls lurking just a misstep away</p><p>In a production scenario example, consider how Twitter manages its data sources. The platform utilizes streaming data to monitor and analyze billions of tweets in real time, employing technologies like Apache Kafka for swift data ingestion. This allows for immediate trend analysis and user engagement metrics. For historical data analysis, Twitter relies on batch processing, where data is stored in massive data lakes, enabling them to perform complex queries and analyses that inform long-term strategies. These approaches showcase a real-world application where both real-time and batch data are pivotal, and the trade-offs between immediacy and depth of insight are constantly balanced to drive user engagement and business decisions.</p><h4>Feature Engineering</h4><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb99ce9f9-d53c-453d-952d-42816545bb14_666x481.png" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb99ce9f9-d53c-453d-952d-42816545bb14_666x481.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb99ce9f9-d53c-453d-952d-42816545bb14_666x481.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb99ce9f9-d53c-453d-952d-42816545bb14_666x481.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb99ce9f9-d53c-453d-952d-42816545bb14_666x481.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb99ce9f9-d53c-453d-952d-42816545bb14_666x481.png" width="666" height="481" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/b99ce9f9-d53c-453d-952d-42816545bb14_666x481.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:481,&quot;width&quot;:666,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:43015,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb99ce9f9-d53c-453d-952d-42816545bb14_666x481.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb99ce9f9-d53c-453d-952d-42816545bb14_666x481.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb99ce9f9-d53c-453d-952d-42816545bb14_666x481.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb99ce9f9-d53c-453d-952d-42816545bb14_666x481.png 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a></figure></div><p>The Feature Engineering represented above, is where raw data is transformed into a goldmine for machine learning models. This is the stage where transformation and feature engineering rules are meticulously crafted and applied, ensuring that the resulting features are primed for effective model training.</p><p>This complex task takes place within the Feature Engineering Pipeline, an orchestrated series of steps encompassing data extraction, transformation, and finally, data loading. Tools like Apache Nifi for data routing and transformation, along with more comprehensive platforms like IBM CP4D, AWS and Databricks, are leveraged for their robust ETL capabilities.</p><p>Then there's the Feature Store System &#8211; a repository with dual facets. It serves up features with normal latency for batch processing needs, while also catering to the demands of real-time prediction with its low-latency offerings. Tecton and Feast are examples of feature store systems that are gaining traction, providing teams the ability to reuse and share features across models, thereby streamlining the feature engineering process.</p><p>However, this phase is not without its challenges. The design and maintenance of feature stores demand a delicate balance between accessibility and performance, ensuring that the right features are available at the right time, without resource wastage. Moreover, the granularity and quality of features can significantly sway model performance, placing a premium on the precision of engineering rules.</p><p>In the trenches of production, companies like Uber with its <a href="https://www.uber.com/en-GB/blog/michelangelo-machine-learning-platform/">Michelangelo platform</a>, harness feature engineering to fuel their real-time decision engines, ensuring that features like ETA predictions and pricing models are as accurate as they are swift. It's a testament to the critical role feature engineering plays in delivering ML solutions that not only function but excel in real-world applications.</p><h3>Training Model</h3><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe576373b-9190-4b54-b745-e47b7275b710_821x581.png" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe576373b-9190-4b54-b745-e47b7275b710_821x581.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe576373b-9190-4b54-b745-e47b7275b710_821x581.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe576373b-9190-4b54-b745-e47b7275b710_821x581.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe576373b-9190-4b54-b745-e47b7275b710_821x581.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe576373b-9190-4b54-b745-e47b7275b710_821x581.png" width="821" height="581" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/e576373b-9190-4b54-b745-e47b7275b710_821x581.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:581,&quot;width&quot;:821,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:65500,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe576373b-9190-4b54-b745-e47b7275b710_821x581.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe576373b-9190-4b54-b745-e47b7275b710_821x581.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe576373b-9190-4b54-b745-e47b7275b710_821x581.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe576373b-9190-4b54-b745-e47b7275b710_821x581.png 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a></figure></div><p>The <strong>'Training Model'</strong> segment of my ML architecture diagram captures a network of computational nodes&#8212;machines dedicated to the arduous task of model training. Each machine, possibly a high-performance GPU or CPU server, runs instances of training algorithms, which iteratively adjust a model's parameters to minimize error against a set of training data. This process demands robust hardware capable of high-speed matrix computations and data processing&#8212;a reason why GPUs, with their parallel processing prowess, are often the hardware of choice.</p><p>Central to this orchestrated training effort is the <strong>Parameter Server</strong>, a system designed to synchronize parameter updates across all training nodes. It's the heart of distributed learning, managing the state of the model by aggregating gradients&#8212;a technique known as gradient descent&#8212;ensuring that each node's updates contribute to a singular, evolving model. This server must be both high-capacity and low-latency to handle the frequent, voluminous exchanges of parameter updates.</p><p>This phase leverages software like TensorFlow or PyTorch, frameworks that support distributed model training across multiple hardware nodes, often abstracting the complexities of direct hardware manipulation. They come with built-in support for leveraging Parameter Servers or employing alternative strategies like all-reduce for parameter synchronization.</p><p>The technical trade-offs in this stage are significant. More powerful hardware accelerates training but increases costs. The Parameter Server model scales well but can become a bottleneck in extremely large-scale systems, where alternatives like decentralized parameter updating might be considered.</p><p>In live production environments, tech companies might deploy these training models on cloud platforms like AWS or Azure, which provide scalable GPU resources on-demand. For example, an autonomous vehicle company might use such a setup to train driving models on petabytes of sensor data, requiring immense computational resources and sophisticated parameter synchronization to simulate and learn from countless driving scenarios.</p><p>In production environments, companies often require substantial computational power to train complex ML models. For example, a financial analytics firm might use distributed clusters of machines, each equipped with GPUs for parallel processing, to train models on market data and predict stock trends. They could leverage a setup involving Kubernetes to orchestrate containerized machine learning workloads across a cloud environment, optimizing resource use and scaling training operations on demand.</p><p>For parameter synchronization, they might implement an elastic Parameter Server framework or utilize decentralized strategies like ring-allreduce, which can offer better scalability and fault tolerance. Such choices depend on the size of the model, the frequency of parameter updates, and the overall network topology.</p><p>Additionally, leading cloud providers offer Machine Learning as a Service (MLaaS) platforms, which abstract away much of the underlying infrastructure complexity. These platforms provide integrated tools for model training, parameter tuning, version control, and deployment, streamlining the entire lifecycle of ML model development.</p><p>In the context of real-world applications, consider a healthcare organization using MLaaS to train models for predicting patient outcomes. They would utilize the vast computational resources offered by cloud services, paired with sophisticated model management systems, to ensure that their predictive models are as accurate and up-to-date as possible, ultimately aiming to provide better care and save lives.</p><p>A well-known example in the context of financial analytics could be JPMorgan Chase &amp; Co. They have leveraged distributed computing for risk modeling and fraud detection. <a href="https://pages.awscloud.com/rs/112-TZM-766/images/IN02-JPMC.pdf">Their platform, Athena, </a>is known for processing vast amounts of financial data, and for such data-intensive tasks, they use scalable cloud computing resources that can handle the computational load.</p><p>In healthcare, Philips is known for its <a href="https://www.philips.com/c-dam/b2bhc/master/hts/healthsuite/brochure-philips-ealthsuite.pdf">HealthSuite platform</a>, which uses advanced analytics to improve patient care. They train complex models on large datasets of patient information, using scalable cloud infrastructure to manage and process this sensitive data securely and efficiently. Philips' use of MLaaS enables them to continuously refine their predictive models, which can lead to more personalized patient care plans and better health outcomes.</p><h3>Inference Server</h3><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F536d8c17-b03a-48aa-ac9a-68de29d49b7f_521x611.png" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F536d8c17-b03a-48aa-ac9a-68de29d49b7f_521x611.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F536d8c17-b03a-48aa-ac9a-68de29d49b7f_521x611.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F536d8c17-b03a-48aa-ac9a-68de29d49b7f_521x611.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F536d8c17-b03a-48aa-ac9a-68de29d49b7f_521x611.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F536d8c17-b03a-48aa-ac9a-68de29d49b7f_521x611.png" width="521" height="611" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/536d8c17-b03a-48aa-ac9a-68de29d49b7f_521x611.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:611,&quot;width&quot;:521,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:33295,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F536d8c17-b03a-48aa-ac9a-68de29d49b7f_521x611.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F536d8c17-b03a-48aa-ac9a-68de29d49b7f_521x611.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F536d8c17-b03a-48aa-ac9a-68de29d49b7f_521x611.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F536d8c17-b03a-48aa-ac9a-68de29d49b7f_521x611.png 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a></figure></div><p>The <strong>'Inference Server' </strong>segment of the ML architecture diagram depicts the critical role of inference servers in deploying and managing machine learning models for real-world applications. These servers act as intermediaries between client applications and trained machine learning models, handling the complex task of interpreting user requests and executing the appropriate model computations to generate meaningful inferences.</p><p>The diagram highlights the interplay between the Inference Server, the Model, and the Client Application. The Client Application submits an Inference Request, which is typically a data payload containing the input features for the target machine learning model. This request is then routed to the Inference Server, which acts as a centralized repository for managing multiple machine learning models.</p><ul><li><p>Software: The client application can be written in any programming language that supports HTTP communication. Popular options include Python, Java, and JavaScript.</p></li><li><p>Hardware: The client application can run on a variety of devices, including desktops, laptops, mobile phones, and servers. The specific hardware requirements will depend on the complexity of the inference request and the desired performance.</p></li></ul><p>Within the Inference Server, the Scheduler component receives the incoming Inference Request and determines which Model is the most appropriate for handling the request based on the type of input data and the specific task at hand. The selected Model is then activated and loaded into memory, ready to process the input data.</p><ul><li><p>Software: The inference server typically runs on a dedicated server machine. The server should have a powerful CPU or GPU to handle the computational demands of the machine learning models. Common inference server software frameworks include TensorFlow Serving, PyTorch Serving, and Apache MXNet.</p></li><li><p>Hardware: The inference server hardware will depend on the specific inference requirements. For basic inference tasks, a standard server with a CPU or a low-end GPU may be sufficient. For more demanding tasks, a high-end GPU server may be necessary.</p></li></ul><p>Once the Model is loaded, the Request/Response Handling mechanism takes over, orchestrating the communication between the Model and the Client Application. The Inference Server communicates with the Model using the HTTP protocol, sending the input data and receiving the Inference Response, which contains the generated predictions or insights from the model.</p><ul><li><p>Software: The model is the trained machine learning model that is deployed on the inference server. The model can be represented in a variety of formats, such as TensorFlow SavedModel, Keras HDF5, or ONNX.</p></li><li><p>Hardware: The model hardware requirements will depend on the size and complexity of the model. For smaller models, a standard server may be sufficient. For larger models, a dedicated hardware accelerator may be necessary.</p></li></ul><p><strong>Scheduler</strong></p><ul><li><p>Software: The scheduler is responsible for managing the execution of inference requests. It receives incoming requests, determines which model to use, and loads the model into memory. Popular scheduler software frameworks include TensorFlow Serving, Model Serving, and Apache Flink.</p></li><li><p>Hardware: The scheduler can run on the same server as the inference server or on a separate server. The hardware requirements will depend on the number of concurrent inference requests.</p></li></ul><p><strong>Request/Response Handling</strong></p><ul><li><p>Software: The request/response handling mechanism is responsible for communicating between the inference server and the client application. It sends the input data to the model, receives the inference result, and sends the result back to the client application. Popular request/response handling libraries include HTTP, gRPC, and Apache Kafka.</p></li><li><p>Hardware: The request/response handling mechanism can run on the same server as the scheduler or on a separate server. The hardware requirements will depend on the number of concurrent inference requests and the network bandwidth.</p></li></ul><p>This process encapsulates the fundamental role of inference servers in translating user requests into meaningful inferences through machine learning models. They act as the bridge between the application layer and the underlying machine learning expertise, enabling the seamless integration of AI into various domains.</p><p></p><div class="captioned-button-wrap" data-attrs="{&quot;url&quot;:&quot;https://www.tostring.ai/p/orchestrating-the-ml-lifecycle-an?utm_source=substack&utm_medium=email&utm_content=share&action=share&token=eyJ1c2VyX2lkIjoyMTE1MDMzMywicG9zdF9pZCI6MTM5NTgwMjg0LCJpYXQiOjE3MzgxNjE5MjIsImV4cCI6MTc0MDc1MzkyMiwiaXNzIjoicHViLTgzMTY2NiIsInN1YiI6InBvc3QtcmVhY3Rpb24ifQ.QDzZORWyilaosLi4M9u7uLr2ALlhKhzDrlzWZo4ClUU&quot;,&quot;text&quot;:&quot;Share&quot;}" data-component-name="CaptionedButtonToDOM"><div class="preamble"><p class="cta-caption">Thank you for reading toString(). This post is public so feel free to share it.</p></div><p class="button-wrapper" data-attrs="{&quot;url&quot;:&quot;https://www.tostring.ai/p/orchestrating-the-ml-lifecycle-an?utm_source=substack&utm_medium=email&utm_content=share&action=share&token=eyJ1c2VyX2lkIjoyMTE1MDMzMywicG9zdF9pZCI6MTM5NTgwMjg0LCJpYXQiOjE3MzgxNjE5MjIsImV4cCI6MTc0MDc1MzkyMiwiaXNzIjoicHViLTgzMTY2NiIsInN1YiI6InBvc3QtcmVhY3Rpb24ifQ.QDzZORWyilaosLi4M9u7uLr2ALlhKhzDrlzWZo4ClUU&quot;,&quot;text&quot;:&quot;Share&quot;}" data-component-name="ButtonCreateButton"><a class="button primary" href="https://www.tostring.ai/p/orchestrating-the-ml-lifecycle-an?utm_source=substack&utm_medium=email&utm_content=share&action=share&token=eyJ1c2VyX2lkIjoyMTE1MDMzMywicG9zdF9pZCI6MTM5NTgwMjg0LCJpYXQiOjE3MzgxNjE5MjIsImV4cCI6MTc0MDc1MzkyMiwiaXNzIjoicHViLTgzMTY2NiIsInN1YiI6InBvc3QtcmVhY3Rpb24ifQ.QDzZORWyilaosLi4M9u7uLr2ALlhKhzDrlzWZo4ClUU"><span>Share</span></a></p></div><h3><strong>Conclusion</strong></h3><p>As you can see, machine learning architecture is a complex and ever-evolving field. There are many different components that need to be considered, and the trade-offs between them can be significant. However, by understanding the different phases of the ML lifecycle and the role of each component, we can make informed decisions about how to architect your machine learning solutions.</p><p>Here are some key takeaways from this blog post:</p><ul><li><p><strong>The ML lifecycle is a series of steps that begins with problem definition and ends with deployment and monitoring.</strong></p></li><li><p><strong>Each phase of the ML lifecycle has its own set of challenges and trade-offs.</strong></p></li><li><p><strong>Machine learning architecture is about choosing the right tools and frameworks to support the ML lifecycle.</strong></p></li><li><p><strong>The specific architecture you choose will depend on your specific needs and constraints.</strong></p></li></ul><p>I hope this blog post has given you a better understanding of machine learning architecture. If you have any questions, please feel free to leave a comment below.</p><p></p><p class="button-wrapper" data-attrs="{&quot;url&quot;:&quot;https://www.tostring.ai/p/orchestrating-the-ml-lifecycle-an/comments&quot;,&quot;text&quot;:&quot;Leave a comment&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a class="button primary" href="https://www.tostring.ai/p/orchestrating-the-ml-lifecycle-an/comments"><span>Leave a comment</span></a></p> ]]>
</content:encoded>
</item>
<item>
<title>
<![CDATA[ E4: The Linguistics of Machines: LLM and NLP ]]>
</title>
<description>
<![CDATA[ Human and Machine Communication through Deep Learning Techniques ]]>
</description>
<link>https://www.tostring.ai/p/e4-the-linguistics-of-machines-llm</link>
<guid isPermaLink="true">https://www.tostring.ai/p/e4-the-linguistics-of-machines-llm</guid>
<dc:creator>
<![CDATA[ Marco Altea ]]>
</dc:creator>
<pubDate>Fri, 03 Nov 2023 08:36:09 GMT</pubDate>
<enclosure url="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F63dfe2b8-b5d4-479b-b9f7-f5fe19656a7a_409x595.webp" length="0" type="image/jpeg"/>
<content:encoded>
<![CDATA[ <h2>Introduction</h2><p>As the technology continually evolves, as you can probably have noticed </p><div class="pullquote"><p>WE CAN NOW TALK WITH MACHINE!!!! </p></div><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2d96708c-6b50-4edc-b745-5e58b37c7c0f_1024x1024.png" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2d96708c-6b50-4edc-b745-5e58b37c7c0f_1024x1024.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2d96708c-6b50-4edc-b745-5e58b37c7c0f_1024x1024.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2d96708c-6b50-4edc-b745-5e58b37c7c0f_1024x1024.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2d96708c-6b50-4edc-b745-5e58b37c7c0f_1024x1024.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2d96708c-6b50-4edc-b745-5e58b37c7c0f_1024x1024.png" width="1024" height="1024" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/2d96708c-6b50-4edc-b745-5e58b37c7c0f_1024x1024.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1024,&quot;width&quot;:1024,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1712158,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2d96708c-6b50-4edc-b745-5e58b37c7c0f_1024x1024.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2d96708c-6b50-4edc-b745-5e58b37c7c0f_1024x1024.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2d96708c-6b50-4edc-b745-5e58b37c7c0f_1024x1024.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2d96708c-6b50-4edc-b745-5e58b37c7c0f_1024x1024.png 1456w" sizes="100vw" fetchpriority="high"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a></figure></div><p></p><div class="subscription-widget-wrap-editor" data-attrs="{&quot;url&quot;:&quot;https://www.tostring.ai/subscribe?&quot;,&quot;text&quot;:&quot;Subscribe&quot;,&quot;language&quot;:&quot;en&quot;}" data-component-name="SubscribeWidgetToDOM"><div class="subscription-widget show-subscribe"><div class="preamble"><p class="cta-caption">toString() is a reader-supported publication. To receive new posts and support my work, consider becoming a free or paid subscriber.</p></div><form class="subscription-widget-subscribe"><input type="email" class="email-input" name="email" placeholder="Type your email&#8230;" tabindex="-1"><input type="submit" class="button primary" value="Subscribe"><div class="fake-input-wrapper"><div class="fake-input"></div><div class="fake-button"></div></div></form></div></div><p>The journey so far, through Machine Learning and Deep Learning, has set a good foundation into how machines interpret and generate human language. In this episode, I will try to explain how Large Language Models (LLMs) and Natural Language Processing (NLP) works. This technique allows the fusion of linguistic and machine learning principles to foster a more nuanced interaction between humans and computers.</p><p>This new chapter of AI Odyssey It's about to show how we can teach machines to understand and respond to textual data, mirroring human-like understanding to a significant extent. This exploration is all set to unveil the architectural designs and the underlying mechanisms that help machines process textual data effectively, thereby enhancing our digital solutions.</p><h2><strong>Large Language Models (LLMs)</strong></h2><p>LLMs as discussed in the first chapter </p><div class="digest-post-embed" data-attrs="{&quot;nodeId&quot;:&quot;2315765f-c58a-492a-a89e-55cc43cc3743&quot;,&quot;caption&quot;:&quot;1. Introduction In a world where the term \&quot;Artificial Intelligence\&quot; (AI) has become ubiquitous, it's crucial to ground my understanding in its foundational aspects. John McCarthy, a luminary in the domain from Stanford University, delved deep into the basic questions surrounding AI in his paper&quot;,&quot;size&quot;:&quot;lg&quot;,&quot;isEditorNode&quot;:true,&quot;title&quot;:&quot;E1 - From Code to Cognition: My AI Exploration Begins&quot;,&quot;publishedBylines&quot;:[{&quot;id&quot;:21150333,&quot;name&quot;:&quot;Marco Altea&quot;,&quot;bio&quot;:&quot;Londoner, IBM Technical Architect &amp; wine lover time traveller &quot;,&quot;photo_url&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/90a0c78f-fe64-4a86-8bf2-f89b09696a3e_3000x2002.jpeg&quot;,&quot;is_guest&quot;:false,&quot;bestseller_tier&quot;:null}],&quot;post_date&quot;:&quot;2023-10-13T08:40:55.155Z&quot;,&quot;cover_image&quot;:&quot;https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F751132e6-7ab7-4720-9984-a1a5787a7df3_1024x1024.png&quot;,&quot;cover_image_alt&quot;:null,&quot;canonical_url&quot;:&quot;https://tostring.substack.com/p/e1-from-code-to-cognition-my-ai-exploration&quot;,&quot;section_name&quot;:&quot;AI Odyssey&quot;,&quot;id&quot;:137898406,&quot;type&quot;:&quot;newsletter&quot;,&quot;reaction_count&quot;:4,&quot;comment_count&quot;:4,&quot;publication_name&quot;:&quot;toString()&quot;,&quot;publication_logo_url&quot;:&quot;https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd9026593-bb1d-495c-8712-41f872e37c87_1080x1080.png&quot;,&quot;belowTheFold&quot;:true}"></div><p></p><p>are a class of artificial intelligence models designed to understand and generate human language. They are trained on vast datasets comprising text from diverse sources, which provide them with a broad &#8220;understanding&#8221; of language, context, and even certain aspects of general knowledge.</p><p>One of the hallmarks of LLMs is the ability to handle and generate text in a way that resonates with human understanding. This allows machines to understand not just the words, but the sentiments, nuances, and contexts that come with human communication. LLMs like GPT-3, with its 175 billion parameters, represent the progress that have been made in this direction.</p><p>Now, let's get a bit technical. The underlying architecture that empowers these LLMs is the <a href="https://tostring.substack.com/i/137898406/llm-architecture-a-closer-look">Transformer Architecture</a>. <a class="footnote-anchor" data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-1" href="#footnote-1" target="_self">1</a></p><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F63dfe2b8-b5d4-479b-b9f7-f5fe19656a7a_409x595.webp" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F63dfe2b8-b5d4-479b-b9f7-f5fe19656a7a_409x595.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F63dfe2b8-b5d4-479b-b9f7-f5fe19656a7a_409x595.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F63dfe2b8-b5d4-479b-b9f7-f5fe19656a7a_409x595.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F63dfe2b8-b5d4-479b-b9f7-f5fe19656a7a_409x595.webp 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F63dfe2b8-b5d4-479b-b9f7-f5fe19656a7a_409x595.webp" width="409" height="595" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/63dfe2b8-b5d4-479b-b9f7-f5fe19656a7a_409x595.webp&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:595,&quot;width&quot;:409,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F63dfe2b8-b5d4-479b-b9f7-f5fe19656a7a_409x595.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F63dfe2b8-b5d4-479b-b9f7-f5fe19656a7a_409x595.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F63dfe2b8-b5d4-479b-b9f7-f5fe19656a7a_409x595.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F63dfe2b8-b5d4-479b-b9f7-f5fe19656a7a_409x595.webp 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a></figure></div><p>It's a model that utilizes layers of attention mechanisms to weigh the importance of different parts of the input text (if you want to dig deep on how it technically works you can find a detailed explaination <a href="https://tostring.substack.com/i/137898406/llm-architecture-a-closer-look">HERE</a>). This design enables the model to focus on different parts of the text, much like how we humans pay attention to different parts of a conversation. It's about distinguishing the critical from the trivial, the relevant from the irrelevant. </p><p>The impact of LLMs on the architectural designs is profound. They provide a way to incorporate a sophisticated understanding of language into our digital solutions, enabling a more intuitive interaction between users and systems. For instance, integrating an LLM like GPT-3 into a system can significantly enhance its ability to understand and respond to user queries in a more human-like manner.</p><p>But it's not all sunshine and rainbows. The computational resources required to train and run these behemoths are substantial. Also, the vast amount of data they require raises concerns regarding data privacy and bias. Yet, the potential they hold is immense and hard to overlook.</p><h2><strong>Natural Language Processing (NLP)</strong></h2><p>NLP enables machines to understand, process, and generate human language. It's not just about reading text or hearing speech; it's about deciphering the meanings, the context, and the intent behind the words.</p><p>Let's break it down. At its core, NLP include a variety of techniques and models working to convert our linguistic expressions into a format that machines can understand. </p><p>With the advent of transformative Language Models like <a href="https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf">GPT (Generative Pre-trained Transformer)</a> and <a href="https://github.com/google-research/bert">BERT (Bidirectional Encoder Representations from Transformers)</a>. These models, with their ability to handle vast amounts of text and grasp contextual nuances, are pushing the boundaries of what's possible with NLP.</p><p>For instance, GPT-3, a model by OpenAI<a class="footnote-anchor" data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-2" href="#footnote-2" target="_self">2</a>, can generate human-like text that's almost indistinguishable from something a person would write. It's fascinating and scary at the same time! BERT, from Google, shines in understanding the context of words in a sentence, which is instrumental in search queries and other language understanding tasks.</p><p>Using the below example ofe the <a href="https://openai.com/research/instruction-following">OpenAI Method</a>, we can extract the steps and how the information flow:</p><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcff6f28d-6d99-4212-9037-81edab06c7b8_1140x677.svg" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcff6f28d-6d99-4212-9037-81edab06c7b8_1140x677.svg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcff6f28d-6d99-4212-9037-81edab06c7b8_1140x677.svg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcff6f28d-6d99-4212-9037-81edab06c7b8_1140x677.svg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcff6f28d-6d99-4212-9037-81edab06c7b8_1140x677.svg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcff6f28d-6d99-4212-9037-81edab06c7b8_1140x677.svg" width="1456" height="865" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/cff6f28d-6d99-4212-9037-81edab06c7b8_1140x677.svg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:865,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcff6f28d-6d99-4212-9037-81edab06c7b8_1140x677.svg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcff6f28d-6d99-4212-9037-81edab06c7b8_1140x677.svg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcff6f28d-6d99-4212-9037-81edab06c7b8_1140x677.svg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcff6f28d-6d99-4212-9037-81edab06c7b8_1140x677.svg 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a></figure></div><p></p><p><strong>Step 1: Collecting Demonstration Data</strong> - This is similar to requirement gathering in software design. We're identifying key use cases and setting the stage for how our system should behave. Like determining the core modules of a software system, this step helps us focus on primary functionalities.</p><p><strong>Step 2: Collecting Comparison Data</strong> - Here, it's about quality assurance and validation. Multiple model outputs are generated, much like how we'd have various modules or microservices in an architecture. They're then assessed for efficiency, coherence, and quality, similar to evaluating architectural components based on their performance metrics.</p><p><strong>Step 3: Policy Optimization using Reinforcement Learning</strong> - As you should know from the <a href="https://tostring.substack.com/i/138098744/reinforcement-learning">Episode 2</a> think of this as the iterative process of architectural refinement. Just as we would optimize server loads or streamline database queries in a system, this phase continually hones the NLP model based on feedback, ensuring that it meets the set criteria.</p><p>Now, let's take a moment to appreciate the architectural impact. Embedding NLP within our digital solutions opens doors to a plethora of possibilities. Imagine a system that can not only understand user queries but also sense the urgency or the emotion behind them. It's about creating interfaces that are not just smart, but empathetic.</p><p>Yet, we must tread cautiously. The models are as good as the data they are trained on. Biases in data can lead to biases in understanding and responses, which is a significant concern.</p><div class="subscription-widget-wrap-editor" data-attrs="{&quot;url&quot;:&quot;https://www.tostring.ai/subscribe?&quot;,&quot;text&quot;:&quot;Subscribe&quot;,&quot;language&quot;:&quot;en&quot;}" data-component-name="SubscribeWidgetToDOM"><div class="subscription-widget show-subscribe"><div class="preamble"><p class="cta-caption">toString() is a reader-supported publication. To receive new posts and support my work, consider becoming a free or paid subscriber.</p></div><form class="subscription-widget-subscribe"><input type="email" class="email-input" name="email" placeholder="Type your email&#8230;" tabindex="-1"><input type="submit" class="button primary" value="Subscribe"><div class="fake-input-wrapper"><div class="fake-input"></div><div class="fake-button"></div></div></form></div></div><h2><strong>Generative AI</strong></h2><p>Generative Adversarial Networks, or GANs, are the linchpins of Generative AI. A GAN<a class="footnote-anchor" data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-3" href="#footnote-3" target="_self">3</a> comprises two neural networks &#8211; the Generator and the Discriminator &#8211; that are trained simultaneously through adversarial training. It's like a forger trying to create a masterpiece while an art detective tries to catch the forger. Over time, the forger gets so good that the detective can&#8217;t tell the real from the fake. The Generator creates new data instances, while the Discriminator evaluates them, and with each iteration, the Generator gets better at creating realistic data. This continuous feedback loop is the essence of GANs.</p><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F81c65cef-1333-441c-a926-3f79662a6a46_577x254.svg" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F81c65cef-1333-441c-a926-3f79662a6a46_577x254.svg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F81c65cef-1333-441c-a926-3f79662a6a46_577x254.svg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F81c65cef-1333-441c-a926-3f79662a6a46_577x254.svg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F81c65cef-1333-441c-a926-3f79662a6a46_577x254.svg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F81c65cef-1333-441c-a926-3f79662a6a46_577x254.svg" width="1456" height="641" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/81c65cef-1333-441c-a926-3f79662a6a46_577x254.svg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:641,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;A diagram of a generative adversarial network. At the center of the\n diagram is a box labeled 'discriminator'. Two branches feed into this\n box from the left. The top branch starts at the upper left of the\n diagram with a cylinder labeled 'real world images'. An arrow leads\n from this cylinder to a box labeled 'Sample'. An arrow from the box\n labeled 'Sample' feeds into the 'Discriminator' box. The bottom branch\n feeds into the 'Discriminator' box starting with a box labeled 'Random\n Input'. An arrow leads from the 'Random Input' box to a box labeled\n 'Generator'. An arrow leads from the 'Generator' box to a second\n 'Sample' box. An arrow leads from the 'Sample' box to the\n 'Discriminator box. On the right side of the Discriminator box, an\n arrow leads to a box containing a green circle and a red circle. The\n word 'Real' appears in green text above the box and the word 'False'\n appears in red below the box. Two arrows lead from this box to two\n boxes on the right side of the diagram. One arrow leads to a box\n labeled 'Discriminator loss'. The other arrow leads to a box labeled\n 'Generator loss'.&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" class="sizing-normal" alt="A diagram of a generative adversarial network. At the center of the diagram is a box labeled 'discriminator'. Two branches feed into this box from the left. The top branch starts at the upper left of the diagram with a cylinder labeled 'real world images'. An arrow leads from this cylinder to a box labeled 'Sample'. An arrow from the box labeled 'Sample' feeds into the 'Discriminator' box. The bottom branch feeds into the 'Discriminator' box starting with a box labeled 'Random Input'. An arrow leads from the 'Random Input' box to a box labeled 'Generator'. An arrow leads from the 'Generator' box to a second 'Sample' box. An arrow leads from the 'Sample' box to the 'Discriminator box. On the right side of the Discriminator box, an arrow leads to a box containing a green circle and a red circle. The word 'Real' appears in green text above the box and the word 'False' appears in red below the box. Two arrows lead from this box to two boxes on the right side of the diagram. One arrow leads to a box labeled 'Discriminator loss'. The other arrow leads to a box labeled 'Generator loss'." title="A diagram of a generative adversarial network. At the center of the diagram is a box labeled 'discriminator'. Two branches feed into this box from the left. The top branch starts at the upper left of the diagram with a cylinder labeled 'real world images'. An arrow leads from this cylinder to a box labeled 'Sample'. An arrow from the box labeled 'Sample' feeds into the 'Discriminator' box. The bottom branch feeds into the 'Discriminator' box starting with a box labeled 'Random Input'. An arrow leads from the 'Random Input' box to a box labeled 'Generator'. An arrow leads from the 'Generator' box to a second 'Sample' box. An arrow leads from the 'Sample' box to the 'Discriminator box. On the right side of the Discriminator box, an arrow leads to a box containing a green circle and a red circle. The word 'Real' appears in green text above the box and the word 'False' appears in red below the box. Two arrows lead from this box to two boxes on the right side of the diagram. One arrow leads to a box labeled 'Discriminator loss'. The other arrow leads to a box labeled 'Generator loss'." srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F81c65cef-1333-441c-a926-3f79662a6a46_577x254.svg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F81c65cef-1333-441c-a926-3f79662a6a46_577x254.svg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F81c65cef-1333-441c-a926-3f79662a6a46_577x254.svg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F81c65cef-1333-441c-a926-3f79662a6a46_577x254.svg 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a></figure></div><p>Breaking down the architecture of a GAN using a practical use case the generation of realistic human to understand better how the information flow and change</p><p><strong>Random Input</strong>: Technically known as a latent space vector or noise, this randomly initialized set of data points provides the initial blueprint. For our face generation task, consider this as a basic, undetailed sketch of facial features.</p><p>This code defines a function to generate a random vector of a given size. This random vector will act as the initial seed for the GAN's generator.</p><pre><code><code>import numpy as np def generate_random_input(dimensions): return np.random.randn(dimensions) random_input = generate_random_input(100)</code></code></pre><ul><li><p>The <code>numpy</code> library is imported for numerical operations.</p></li><li><p><code>generate_random_input</code> function takes an integer argument <code>dimensions</code> which specifies the size of the random vector.</p></li><li><p>The <code>np.random.randn</code> function is used to generate a random array of shape <code>dimensions</code> with values sampled from a standard normal distribution.</p></li><li><p>An example random vector of size 100 is generated.</p></li></ul><h4><strong>Generator</strong></h4><p>A deep neural network that takes the random sketch and refines it. Imagine it as an artist who takes the basic sketch and starts adding details - eyes, nose, lips, skin texture, etc., based on its learning from real faces. The deeper the network, the more intricate the details, allowing it to capture subtle facial features and expressions.</p><p>This code defines the architecture of the generator model using the Keras API. The generator model is responsible for generating data (in this case, faces) from random inputs.</p><pre><code>from keras.models import Sequential from keras.layers import Dense, Reshape, Conv2DTranspose def build_generator(): model = Sequential() model.add(Dense(128 * 7 * 7, activation="relu", input_dim=100)) model.add(Reshape((7, 7, 128))) model.add(Conv2DTranspose(128, kernel_size=4, strides=2, padding="same", activation="relu")) model.add(Conv2DTranspose(1, kernel_size=4, strides=2, padding="same", activation="sigmoid")) return model generator = build_generator() generated_face = generator.predict(random_input) </code></pre><ul><li><p>The necessary modules and layers are imported from Keras.</p></li><li><p>The <code>build_generator</code> function creates a sequential model for the generator.</p></li><li><p>The <code>Dense</code> layer acts as a fully connected layer, followed by a reshape layer to format the data into a 7x7 grid.</p></li><li><p><code>Conv2DTranspose</code> layers are used for up-sampling and creating the generated image.</p></li><li><p>The generated model expects a random vector of size 100 (hence <code>input_dim=100</code>).</p></li><li><p>The generator model is then built, and a sample face is generated using the previously defined random input.</p></li></ul><h4><strong>Real Images and Sampled Data</strong></h4><p>For our use case, these would be a collection of thousands of diverse human face photographs. This dataset provides authentic examples, teaching the 'artist' (generator) about various facial structures, skin tones, expressions, and more. It's akin to an artist studying different faces to improve his drawing skills.</p><p>This code defines a function to load real images from a given path into an array.</p><pre><code>import cv2 def load_real_images(path_to_dataset): images = [] for image_path in path_to_dataset: image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE) images.append(image) return np.array(images) real_images = load_real_images(['/path/to/image1.jpg', '/path/to/image2.jpg']) </code></pre><ul><li><p>The <code>cv2</code> module from OpenCV is imported for image loading and processing.</p></li><li><p>The <code>load_real_images</code> function takes a list of image paths and loads each image in grayscale format.</p></li><li><p>These grayscale images are then appended to an <code>images</code> list.</p></li><li><p>The list is then converted to a numpy array and returned.</p><p></p></li></ul><h4><strong>Discriminator</strong></h4><p> Think of this as an art critic. After the artist (generator) produces a face, the critic (discriminator) judges it. It looks at the drawing and compares it to real human faces it has seen. If the drawing closely resembles a real face, the critic acknowledges it. If not, it points out the discrepancies. Over time, as the critic keeps giving feedback, the artist improves, producing even more realistic face drawings.</p><p>This code defines the architecture of the discriminator model. This model's role is to determine whether an input image is real or generated.</p><p>This code defines the architecture of the discriminator model. This model's role is to determine whether an input image is real or generated.</p><pre><code>from keras.layers import Conv2D, Flatten, Dense def build_discriminator(): model = Sequential() model.add(Conv2D(64, kernel_size=4, strides=2, padding="same", input_shape=(28, 28, 1))) model.add(Flatten()) model.add(Dense(1, activation="sigmoid")) return model discriminator = build_discriminator() prediction = discriminator.predict(generated_face) </code></pre><ul><li><p>Relevant layers are imported from Keras.</p></li><li><p>The <code>build_discriminator</code> function creates a sequential model for the discriminator.</p></li><li><p>The <code>Conv2D</code> layer processes the input image, followed by a <code>Flatten</code> layer to prepare the data for the final dense layer.</p></li><li><p>The final <code>Dense</code> layer has a sigmoid activation function, which outputs the probability of the input being a real image.</p></li><li><p>The discriminator model is then built and used to predict whether the previously generated face is real or fake.</p></li></ul><p>Let's consider an architectural use case here. Imagine a project where we need to generate realistic images for a virtual reality real estate platform. GANs can be used to create images of homes, landscapes, or interiors that are realistic and aesthetically appealing, enhancing the user experience of the platform. The generated images can be used to provide a virtual tour, allowing users to experience the property without being physically present. It's about building a bridge between the digital and physical worlds, enhancing the user experience manifold.</p><p>Lastly, let's touch upon <a href="https://www.tensorflow.org/tutorials/generative/style_transfer">Style Transfer</a>, where the style of one image is transferred to another. It&#8217;s like painting a photograph with the style of Van Gogh or Picasso. This technology has a myriad of applications, from art and design to real-time video modifications.</p><div class="subscription-widget-wrap-editor" data-attrs="{&quot;url&quot;:&quot;https://www.tostring.ai/subscribe?&quot;,&quot;text&quot;:&quot;Subscribe&quot;,&quot;language&quot;:&quot;en&quot;}" data-component-name="SubscribeWidgetToDOM"><div class="subscription-widget show-subscribe"><div class="preamble"><p class="cta-caption">toString() is a reader-supported publication. To receive new posts and support my work, consider becoming a free or paid subscriber.</p></div><form class="subscription-widget-subscribe"><input type="email" class="email-input" name="email" placeholder="Type your email&#8230;" tabindex="-1"><input type="submit" class="button primary" value="Subscribe"><div class="fake-input-wrapper"><div class="fake-input"></div><div class="fake-button"></div></div></form></div></div><h2><strong>Conclusion</strong></h2><p>I went through the realms of Large Language Models (LLMs), explored the complexity of Natural Language Processing (NLP), and dig into the creativity unleashed by Generative AI. The concepts and technologies I&#8217;ve discussed in this episode shows to the rapid advancements in the field of AI. As architects, the understanding of these technologies empowers us to design intelligent systems that can interact, understand, and even generate human-like text or realistic images, adding a new dimension to user experiences.</p><p>Our exploration into the heart of machine and human language interaction has revealed a landscape rich with potential. The techniques and models discussed are not futuristic; they are here, and they are being integrated into the architectural designs, delivering solutions that are robust, intelligent, and intuitive.</p><div class="footnote" data-component-name="FootnoteToDOM"><a id="footnote-1" href="#footnote-anchor-1" class="footnote-number" contenteditable="false" target="_self">1</a><div class="footnote-content"><p>Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., ... &amp; Polosukhin, I. (2017). Attention is all you need. In Advances in neural information processing systems (pp. 5998-6008).</p></div></div><div class="footnote" data-component-name="FootnoteToDOM"><a id="footnote-2" href="#footnote-anchor-2" class="footnote-number" contenteditable="false" target="_self">2</a><div class="footnote-content"><p>Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., &amp; Sutskever, I. (2019). Language models are unsupervised multitask learners. OpenAI Blog, 1(8), 9</p></div></div><div class="footnote" data-component-name="FootnoteToDOM"><a id="footnote-3" href="#footnote-anchor-3" class="footnote-number" contenteditable="false" target="_self">3</a><div class="footnote-content"><p>Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., ... &amp; Bengio, Y. (2014). Generative adversarial nets. In Advances in neural information processing systems (pp. 2672-2680).</p></div></div> ]]>
</content:encoded>
</item>
<item>
<title>
<![CDATA[ E3: Architecting Intelligence - Deep Learning ]]>
</title>
<description>
<![CDATA[ Architecture and Artificial Intelligence through Deep Learning ]]>
</description>
<link>https://www.tostring.ai/p/e3-architecting-intelligence-deep</link>
<guid isPermaLink="true">https://www.tostring.ai/p/e3-architecting-intelligence-deep</guid>
<dc:creator>
<![CDATA[ Marco Altea ]]>
</dc:creator>
<pubDate>Fri, 27 Oct 2023 08:30:19 GMT</pubDate>
<enclosure url="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6ec2dd1c-633b-40a0-8c81-08ff49da6a71_3561x3141.png" length="0" type="image/jpeg"/>
<content:encoded>
<![CDATA[ <h2><strong>Introduction</strong></h2><p><a href="https://tostring.substack.com/p/e2-journey-into-how-machines-learn">In the previous episode</a>, I explored the core principles of Machine Learning. Now, I transition to Deep Learning (DL), focusing on Neural Networks, the foundational aspect of DL. Neural Networks are inspired by the human brain's structure, aiding the creation of advanced intelligent systems. This shift to DL represents a deeper exploration into machine intelligence, allowing for more complex data interpretations. As I go into Neural Networks, and later, CNNs and RNNs, let me set the stage for a detailed exploration of DL from an architectural standpoint.</p><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc5e63dda-c075-4bc8-94f8-7e85218440e1_1024x1024.png" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc5e63dda-c075-4bc8-94f8-7e85218440e1_1024x1024.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc5e63dda-c075-4bc8-94f8-7e85218440e1_1024x1024.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc5e63dda-c075-4bc8-94f8-7e85218440e1_1024x1024.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc5e63dda-c075-4bc8-94f8-7e85218440e1_1024x1024.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc5e63dda-c075-4bc8-94f8-7e85218440e1_1024x1024.png" width="566" height="566" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/c5e63dda-c075-4bc8-94f8-7e85218440e1_1024x1024.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1024,&quot;width&quot;:1024,&quot;resizeWidth&quot;:566,&quot;bytes&quot;:1602950,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc5e63dda-c075-4bc8-94f8-7e85218440e1_1024x1024.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc5e63dda-c075-4bc8-94f8-7e85218440e1_1024x1024.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc5e63dda-c075-4bc8-94f8-7e85218440e1_1024x1024.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc5e63dda-c075-4bc8-94f8-7e85218440e1_1024x1024.png 1456w" sizes="100vw" fetchpriority="high"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a></figure></div><p>The history of Deep Learning (DL) reflects a gradual evolution of understanding and technological advancements. Here's a concise list of key milestones and notable figures in the field:</p><div class="subscription-widget-wrap-editor" data-attrs="{&quot;url&quot;:&quot;https://www.tostring.ai/subscribe?&quot;,&quot;text&quot;:&quot;Subscribe&quot;,&quot;language&quot;:&quot;en&quot;}" data-component-name="SubscribeWidgetToDOM"><div class="subscription-widget show-subscribe"><div class="preamble"><p class="cta-caption">toString() is a reader-supported publication. To receive new posts and support my work, consider becoming a free or paid subscriber.</p></div><form class="subscription-widget-subscribe"><input type="email" class="email-input" name="email" placeholder="Type your email&#8230;" tabindex="-1"><input type="submit" class="button primary" value="Subscribe"><div class="fake-input-wrapper"><div class="fake-input"></div><div class="fake-button"></div></div></form></div></div><ol><li><p><strong>Origins in Neural Networks</strong>: The concept of neural networks dates back to the 1940s. In 1943, <a href="https://en.wikipedia.org/wiki/Warren_Sturgis_McCulloch">Warren McCulloch</a> and <a href="https://en.wikipedia.org/wiki/Walter_Pitts">Walter Pitts</a> proposed a computational model of an artificial neuron, laying the groundwork for future developments in neural network theories&#8203;<a href="https://reason.town/deep-learning-milestones/#:~:text=Here%20are%20some%20notable%20milestones,which%20is%20still%20used%20today"><sup>1</sup></a>&#8203;.</p></li><li><p><strong>Perceptron Era</strong>: In 1958, <a href="https://en.wikipedia.org/wiki/Frank_Rosenblatt">Frank Rosenblatt</a> introduced the <a href="https://en.wikipedia.org/wiki/Perceptron">Perceptron</a>, a type of artificial neuron, which became a foundational element of neural network research.</p></li><li><p><strong>Backpropagation Algorithm</strong>: In the 1980s, the backpropagation algorithm was introduced, which is crucial for training multi-layer neural networks. This algorithm significantly contributed to the development and training of deep neural networks.</p></li><li><p><strong>Convolutional Neural Networks (CNNs)</strong>: In 1998, <a href="https://en.wikipedia.org/wiki/Yann_LeCun">Yann LeCun</a> introduced LeNet-5, a pioneering convolutional neural network that significantly influenced the development of CNNs.</p></li><li><p><strong>Deep Learning Renaissance</strong>: With the advent of big data and increased computational power, the early 2000s saw a resurgence in interest and advancements in deep learning. Pioneers like Geoffrey Hinton, Yann LeCun, and Yoshua Bengio played pivotal roles during this period.</p></li><li><p><strong>ImageNet Competition</strong>: The 2012 ImageNet competition marked a significant milestone with the introduction of AlexNet, a deep convolutional neural network that drastically reduced error rates in image recognition tasks, propelling DL to the forefront of AI research.</p></li><li><p><strong>Recent Advancements</strong>: Recent years have witnessed a rapid proliferation of deep learning applications across various domains, powered by advancements in neural network architectures, training algorithms, and the availability of vast amounts of data.</p></li></ol><p>Some of the main sources that I used to understand Deep Learning are</p><ol><li><p>"<a href="http://www.deeplearningbook.org/">Deep Learning</a>" by Ian Goodfellow, Yoshua Bengio, and Aaron Courville.</p></li><li><p><a href="https://www.nature.com/articles/nature14539">&#8220;Deep Learning&#8221;</a> by Yann LeCun, Yoshua Bengio &amp; Geoffrey Hinton&nbsp;</p></li><li><p>"<a href="http://neuralnetworksanddeeplearning.com/">Neural Networks and Deep Learning</a>" by Michael Nielsen.</p></li><li><p>"<a href="https://arxiv.org/abs/1801.00631">Deep Learning: A Critical Appraisal</a>" by Gary Marcus.</p></li></ol><p>And some amazing Substack that facilitate my understandment with two specific post are</p><div class="embedded-post-wrap" data-attrs="{&quot;id&quot;:105172284,&quot;url&quot;:&quot;https://artificialintelligencemadesimple.substack.com/p/how-to-build-large-ai-models-like&quot;,&quot;publication_id&quot;:1315074,&quot;publication_name&quot;:&quot;Artificial Intelligence Made Simple&quot;,&quot;publication_logo_url&quot;:&quot;https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F77504fa0-0f08-4a38-bbde-becb151d2db8_643x644.png&quot;,&quot;title&quot;:&quot;How to build Large AI Models like ChatGPT efficiently&quot;,&quot;truncated_body_text&quot;:&quot;Large Models have captured a lot of attention from people. By adding more parameters and data to the model, we can add more capabilities to a system. Additional parameters allow for more kinds of connections in your neurons, giving your neural networks both better performance on existing tasks and the ability to develop new kinds of skills, as this gif &#8230;&quot;,&quot;date&quot;:&quot;2023-02-26T14:17:19.627Z&quot;,&quot;like_count&quot;:7,&quot;comment_count&quot;:2,&quot;bylines&quot;:[{&quot;id&quot;:8101724,&quot;name&quot;:&quot;Devansh&quot;,&quot;handle&quot;:&quot;chocolatemilkcultleader&quot;,&quot;previous_name&quot;:null,&quot;photo_url&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/f49c53d6-8d45-4cba-a7f9-342282e6fd31_643x644.jpeg&quot;,&quot;bio&quot;:&quot;The best meme-maker in Tech.\nWriter on AI, Software, and the Tech Industry.\nCome say hi, I need more friends&quot;,&quot;profile_set_up_at&quot;:&quot;2021-08-21T20:28:53.612Z&quot;,&quot;publicationUsers&quot;:[{&quot;id&quot;:1274217,&quot;user_id&quot;:8101724,&quot;publication_id&quot;:1315074,&quot;role&quot;:&quot;admin&quot;,&quot;public&quot;:true,&quot;is_primary&quot;:true,&quot;publication&quot;:{&quot;id&quot;:1315074,&quot;name&quot;:&quot;Artificial Intelligence Made Simple&quot;,&quot;subdomain&quot;:&quot;artificialintelligencemadesimple&quot;,&quot;custom_domain&quot;:null,&quot;custom_domain_optional&quot;:false,&quot;hero_text&quot;:&quot;Turning complex ideas in AI Research, Machine Learning, Deep Learning, and Data Science into actionable insights. Read in over 160 countries. Sister Publication to Tech Made Simple&quot;,&quot;logo_url&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/77504fa0-0f08-4a38-bbde-becb151d2db8_643x644.png&quot;,&quot;author_id&quot;:8101724,&quot;theme_var_background_pop&quot;:&quot;#009B50&quot;,&quot;created_at&quot;:&quot;2023-01-14T23:37:24.692Z&quot;,&quot;rss_website_url&quot;:null,&quot;email_from_name&quot;:null,&quot;copyright&quot;:&quot;Devansh&quot;,&quot;founding_plan_name&quot;:null,&quot;community_enabled&quot;:true,&quot;invite_only&quot;:false,&quot;payments_state&quot;:&quot;disabled&quot;,&quot;language&quot;:null,&quot;explicit&quot;:false}},{&quot;id&quot;:109622,&quot;user_id&quot;:8101724,&quot;publication_id&quot;:108704,&quot;role&quot;:&quot;admin&quot;,&quot;public&quot;:true,&quot;is_primary&quot;:false,&quot;publication&quot;:{&quot;id&quot;:108704,&quot;name&quot;:&quot;Technology Made Simple&quot;,&quot;subdomain&quot;:&quot;codinginterviewsmadesimple&quot;,&quot;custom_domain&quot;:null,&quot;custom_domain_optional&quot;:false,&quot;hero_text&quot;:&quot;Deep yet digestible insights about Computer Science, Programming Interviews, Software Engineering Careers, Machine Learning, and the Tech Industry for Tech Leaders. Amazing For Coders and Managers. Beneficial to anyone trying to make money in Tech. &quot;,&quot;logo_url&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/8546dc69-af46-4d5d-9a80-b66cb76c833b_644x644.png&quot;,&quot;author_id&quot;:8101724,&quot;theme_var_background_pop&quot;:&quot;#45D800&quot;,&quot;created_at&quot;:&quot;2020-10-07T10:47:41.199Z&quot;,&quot;rss_website_url&quot;:null,&quot;email_from_name&quot;:&quot;Devansh from Tech Made Simple&quot;,&quot;copyright&quot;:&quot;Devansh&quot;,&quot;founding_plan_name&quot;:&quot;Founding Member&quot;,&quot;community_enabled&quot;:true,&quot;invite_only&quot;:false,&quot;payments_state&quot;:&quot;enabled&quot;,&quot;language&quot;:null,&quot;explicit&quot;:false}}],&quot;twitter_screen_name&quot;:&quot;Machine01776819&quot;,&quot;is_guest&quot;:false,&quot;bestseller_tier&quot;:null}],&quot;utm_campaign&quot;:null,&quot;belowTheFold&quot;:true,&quot;type&quot;:&quot;newsletter&quot;,&quot;language&quot;:&quot;en&quot;}" data-component-name="EmbeddedPostToDOM"><a class="embedded-post" native="true" href="https://artificialintelligencemadesimple.substack.com/p/how-to-build-large-ai-models-like?utm_source=substack&amp;utm_campaign=post_embed&amp;utm_medium=web"><div class="embedded-post-header"><img class="embedded-post-publication-logo" src="https://substackcdn.com/image/fetch/w_56,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F77504fa0-0f08-4a38-bbde-becb151d2db8_643x644.png" loading="lazy"><span class="embedded-post-publication-name">Artificial Intelligence Made Simple</span></div><div class="embedded-post-title-wrapper"><div class="embedded-post-title">How to build Large AI Models like ChatGPT efficiently</div></div><div class="embedded-post-body">Large Models have captured a lot of attention from people. By adding more parameters and data to the model, we can add more capabilities to a system. Additional parameters allow for more kinds of connections in your neurons, giving your neural networks both better performance on existing tasks and the ability to develop new kinds of skills, as this gif &#8230;</div><div class="embedded-post-cta-wrapper"><span class="embedded-post-cta">Read more</span></div><div class="embedded-post-meta">2 years ago &#183; 7 likes &#183; 2 comments &#183; Devansh</div></a></div><div class="embedded-post-wrap" data-attrs="{&quot;id&quot;:83380695,&quot;url&quot;:&quot;https://www.deeplearningweekly.com/p/deep-learning-weekly-issue-275&quot;,&quot;publication_id&quot;:289327,&quot;publication_name&quot;:&quot;Deep Learning Weekly&quot;,&quot;publication_logo_url&quot;:&quot;https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fc63609b6-c5bb-426a-a5c1-b6ce9d56b51e_468x468.png&quot;,&quot;title&quot;:&quot;Deep Learning Weekly: Issue #275&quot;,&quot;truncated_body_text&quot;:&quot;Hey Folks, This week in deep learning, we bring you Meta AI's neural theorem prover that has solved 10 IMO problems, partial blockout experiments at Booking.com, fine-tuning Whisper for Multilingual ASR with Hugging Face Transformers, and a paper on Efficient Spatially Sparse Inference for Conditional GANs and Diffusion Models&quot;,&quot;date&quot;:&quot;2022-11-09T15:49:25.555Z&quot;,&quot;like_count&quot;:9,&quot;comment_count&quot;:0,&quot;bylines&quot;:[{&quot;id&quot;:16414786,&quot;name&quot;:&quot;Miko Planas&quot;,&quot;handle&quot;:null,&quot;previous_name&quot;:null,&quot;photo_url&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/fbdc97c3-70aa-49d6-9215-13e13a5a33db_293x392.png&quot;,&quot;bio&quot;:&quot;Industrial Engineering - Deep Learning - Music Production - Rock Climbing&quot;,&quot;profile_set_up_at&quot;:&quot;2023-01-12T14:36:25.664Z&quot;,&quot;is_guest&quot;:true,&quot;bestseller_tier&quot;:null}],&quot;utm_campaign&quot;:null,&quot;belowTheFold&quot;:true,&quot;type&quot;:&quot;newsletter&quot;,&quot;language&quot;:&quot;en&quot;}" data-component-name="EmbeddedPostToDOM"><a class="embedded-post" native="true" href="https://www.deeplearningweekly.com/p/deep-learning-weekly-issue-275?utm_source=substack&amp;utm_campaign=post_embed&amp;utm_medium=web"><div class="embedded-post-header"><img class="embedded-post-publication-logo" src="https://substackcdn.com/image/fetch/w_56,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fc63609b6-c5bb-426a-a5c1-b6ce9d56b51e_468x468.png" loading="lazy"><span class="embedded-post-publication-name">Deep Learning Weekly</span></div><div class="embedded-post-title-wrapper"><div class="embedded-post-title">Deep Learning Weekly: Issue #275</div></div><div class="embedded-post-body">Hey Folks, This week in deep learning, we bring you Meta AI's neural theorem prover that has solved 10 IMO problems, partial blockout experiments at Booking.com, fine-tuning Whisper for Multilingual ASR with Hugging Face Transformers, and a paper on Efficient Spatially Sparse Inference for Conditional GANs and Diffusion Models&#8230;</div><div class="embedded-post-cta-wrapper"><span class="embedded-post-cta">Read more</span></div><div class="embedded-post-meta">2 years ago &#183; 9 likes &#183; Miko Planas</div></a></div><h2><strong>Neural Networks</strong></h2><p>In my journey into Deep Learning, the first stop is Neural Networks (NNs). Being a cornerstone for many Deep Learning applications, understanding NNs is crucial for an architect to leverage AI in their solutions.</p><p>A Neural Network is a computational model inspired by the human brain's interconnected neuron structure. It's a framework for building and training models to understand and solve complex patterns, making them vital for various AI applications.</p><h3><strong>Components of NN</strong></h3><h4><strong>Input Layer</strong></h4><p>The initial layer where the model receives its data. Each neuron in this layer corresponds to one feature in the data set, acting as the entry point for data to flow into the network.</p><h4><strong>Hidden Layers</strong></h4><p>These are the layers between the input and output layers, where the &#8220;Magic&#8221; happens. Each neuron in a hidden layer receives inputs from all neurons in the previous layer, applies a transformation (typically non-linear), and passes its output to all neurons in the next layer. The presence of multiple hidden layers is what makes a Neural Network <strong>"deep"</strong> - leading to the term Deep Learning.</p><h4><strong>Output Layer</strong></h4><p>The final layer where the model makes its predictions. The number of neurons in this layer corresponds to the number of possible outputs.</p><p>The connections between neurons are represented by weights, which are adjusted during training to minimize the error between the model's predictions and the actual target values.</p><p>Check this diagram below that I have created to represent a NN</p><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F17744ffb-79ea-434b-8e99-c87d8587be6d_1581x1631.png" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F17744ffb-79ea-434b-8e99-c87d8587be6d_1581x1631.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F17744ffb-79ea-434b-8e99-c87d8587be6d_1581x1631.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F17744ffb-79ea-434b-8e99-c87d8587be6d_1581x1631.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F17744ffb-79ea-434b-8e99-c87d8587be6d_1581x1631.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F17744ffb-79ea-434b-8e99-c87d8587be6d_1581x1631.png" width="1456" height="1502" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/17744ffb-79ea-434b-8e99-c87d8587be6d_1581x1631.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1502,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:411265,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F17744ffb-79ea-434b-8e99-c87d8587be6d_1581x1631.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F17744ffb-79ea-434b-8e99-c87d8587be6d_1581x1631.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F17744ffb-79ea-434b-8e99-c87d8587be6d_1581x1631.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F17744ffb-79ea-434b-8e99-c87d8587be6d_1581x1631.png 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a></figure></div><p>Here is a Python code example that translate the diagram above, using <a href="https://www.tensorflow.org/guide">TensorFlow</a></p><pre><code># neural_network.py import tensorflow as tf from tensorflow import keras from tensorflow.keras import layers # Based on the diagram provided: # - Input Layer: 4 neurons (Green Circles) # - Hidden Layer 1: 6 neurons (First set of Orange Circles) # - Hidden Layer 2: 3 neurons (Second set of Orange Circles) # - Hidden Layer 3: 3 neurons (Grey Circles) # - Output Layer: 1 neuron (Blue Circle) # 1. Initializing the Sequential Model model = keras.Sequential() # 2. Adding the Input Layer # Corresponding to the 4 Green Circles in the diagram. # Each neuron corresponds to a distinct feature of the input model.add(layers.Dense(units=4, activation='relu', input_dim=4, name="input_layer")) # 3. Adding Hidden Layers # First Hidden Layer - corresponds to the 6 Orange Circles in the diagram. # Neurons in hidden layers process the incoming data from the previous layer and transform it using an activation function. model.add(layers.Dense(units=6, activation='relu', name="hidden_layer_1")) # Second Hidden Layer - corresponds to the 3 Orange Circles in the diagram. model.add(layers.Dense(units=3, activation='relu', name="hidden_layer_2")) # Third Hidden Layer - corresponds to the 3 Grey Circles in the diagram. model.add(layers.Dense(units=3, activation='relu', name="hidden_layer_3")) # 4. Adding the Output Layer # Corresponding to the single Blue Circle in the diagram. # The neuron in the output layer produces the final prediction of the model. model.add(layers.Dense(units=1, name="output_layer")) # 5. Compile the model # 'mean_squared_error' is a common loss function for regression problems. # The optimizer 'adam' is an algorithm that adjusts neuron weights to minimize the error during training. model.compile(optimizer='adam', loss='mean_squared_error') # NOTE on Nodes (Neurons): # - Nodes in the input layer represent distinct features of the input data. # - Nodes in hidden layers process the data, applying transformations using their weights and activation functions. # - The node in the output layer provides the final prediction of the neural network. # # NOTE on Weights: # Every connection between the neurons in the diagram has a corresponding weight in the model. # These weights determine how much influence one neuron has on the next neuron it's connected to. # During training, the model adjusts these weights to better fit the training data and reduce prediction errors. </code></pre><p>It&#8217;s important to understand that each node in the diagram computes a weighted sum of its inputs and then applies an activation function to this sum. To be specific the activation sum is mathematical function that determines the output of a neuron.</p><p>In the context of the code I provided, I&#8217;m using the activation functions that TensorFlow provides. Specifically, I&#8217;ve chosen the <code>relu</code><a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/ReLU"> (Rectified Linear Unit) </a>activation function for the input and hidden layers.</p><pre><code><code>model.add(layers.Dense(units=6, activation='relu', name="hidden_layer_1"))</code></code></pre><p><code>relu</code> Activation Function: <a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/ReLU">The Rectified Linear Unit (ReLU)</a> is one of the most widely used activation functions in deep neural networks, especially for feedforward and convolutional neural networks. Mathematically, it's defined as </p><div class="latex-rendered" data-attrs="{&quot;persistentExpression&quot;:&quot;f(x)=max(0,x)&quot;,&quot;id&quot;:&quot;GUAQHENNUE&quot;}" data-component-name="LatexBlockToDOM"></div><p>The function returns x if x is greater than or equal to 0, and returns 0 otherwise. The ReLU function is non-linear, which means it allows for complex mappings and is computationally efficient, making the network easier and faster to train.</p><p>The <code>activation='relu'</code> argument specifies that the <code>relu</code> activation function should be used for the neurons in that layer.</p><p>TensorFlow provides <a href="https://www.tensorflow.org/api_docs/python/tf/keras/activations">a variety of other activation functions</a> like <code>sigmoid</code>, <code>tanh</code>, <code>softmax</code>, and more. The choice of activation function depends on the specific task, the nature of the data, and the architecture of the neural network. In many cases, ReLU (or its variants like LeakyReLU or ParametricReLU) is a good default choice for hidden layers in feedforward neural networks. Potential If you have a specific reason or hypothesis, you can customize and create a neural network where each neuron or a group of neurons performs a different specific operation,</p><p>Deep Learning, via Neural Networks, has significantly expanded the capabilities of machine learning, addressing complex problems that were previously unsolvable with traditional machine learning models.</p><h3><strong>Neural Networks vs Classic Machine Learning:</strong></h3><p>Neural Networks, forming the core of Deep Learning, have a number of advantages over traditional machine learning methods:</p><ol><li><p><strong>Automatic Feature Extraction:</strong> Neural Networks have the capability to automatically discover and learn features from raw data. This is a significant advantage over traditional machine learning methods where feature engineering is manual, and domain expertise is required to design features.</p></li><li><p><strong>Complex Problem-Solving:</strong> They can model complex, non-linear relationships, which is crucial for solving complex problems that traditional machine learning models struggle with.</p></li><li><p><strong>Scalability:</strong> Neural Networks tend to perform better as the size of the data increases, making them highly scalable.</p></li><li><p><strong>Multi-dimensional and Sequential Data Handling:</strong> They are adept at handling multi-dimensional and sequential data, which is invaluable in fields like image and video recognition, and natural language processing.</p></li></ol><p>One of the part that fascinate me the most is the <em>Automatic Feature Engineering</em> </p><blockquote><p><em><strong>Feature engineering</strong> or <strong>feature extraction</strong> or <strong>feature discovery</strong> is the process of extracting features (characteristics, properties, attributes) from raw data.<a class="footnote-anchor" data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-1" href="#footnote-1" target="_self">1</a></em></p></blockquote><p>For instance, in a dataset related real estate prices, features might include the size of the property, the number of rooms, the neighborhood's crime rate, proximity to schools, etc. In a text classification problem, features might include word counts, the frequency of certain words, the length of the text, etc.</p><p>In traditional ML, much of the feature engineering needs to be done manually which can be time-consuming and require domain expertise. On the other hand, deep learning models, especially neural networks, are capable of automatic feature extraction from raw data. This is one of the reasons why deep learning models have gained popularity for complex tasks such as image and text analysis where manual feature engineering would be incredibly challenging or impractical.</p><h2><strong>Convolutional Neural Networks (CNN)</strong></h2><p>Convolutional Neural Networks (CNN) are a class of deep learning models specially designed to process grid-like data, such as images. Unlike traditional Neural Networks, CNNs have a unique architecture well-suited to automatically and adaptively learn spatial hierarchies of features from input data.</p><h3><strong>Components of CNN</strong></h3><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6ec2dd1c-633b-40a0-8c81-08ff49da6a71_3561x3141.png" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6ec2dd1c-633b-40a0-8c81-08ff49da6a71_3561x3141.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6ec2dd1c-633b-40a0-8c81-08ff49da6a71_3561x3141.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6ec2dd1c-633b-40a0-8c81-08ff49da6a71_3561x3141.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6ec2dd1c-633b-40a0-8c81-08ff49da6a71_3561x3141.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6ec2dd1c-633b-40a0-8c81-08ff49da6a71_3561x3141.png" width="1456" height="1284" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/6ec2dd1c-633b-40a0-8c81-08ff49da6a71_3561x3141.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1284,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1010443,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6ec2dd1c-633b-40a0-8c81-08ff49da6a71_3561x3141.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6ec2dd1c-633b-40a0-8c81-08ff49da6a71_3561x3141.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6ec2dd1c-633b-40a0-8c81-08ff49da6a71_3561x3141.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6ec2dd1c-633b-40a0-8c81-08ff49da6a71_3561x3141.png 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a></figure></div><h4><strong>Convolutional Layer</strong></h4><p>This is the core building block of a CNN. The layer's parameters consist of a set of learnable filters (or kernels), which have a small receptive field, but extend through the full depth of the input volume. During the forward pass, each filter is convolved across the width and height of the input volume, computing the dot product between the entries of the filter and the input, producing a 2-dimensional activation map.</p><h4><strong>Pooling Layer</strong></h4><p>Pooling (subsampling or down-sampling) reduces the dimensionality of each feature map and retains the most essential information. It could be done through various methods like max pooling, average pooling, etc.</p><h4><strong>Fully Connected Layer</strong></h4><p>Fully connected layers connect every neuron in one layer to every neuron in the next layer, which is the same as traditional neural networks as explained above.</p><h4><strong>Activation Functions</strong></h4><p>Activation functions like ReLU (Rectified Linear Unit) introduce non-linear properties to the system. Their main purpose is to convert a input signal of a node in a A-NN to an output signal. That output signal now is used as a input in the next layer in the stack.</p><h4><strong>Output Layer</strong></h4><p>The final layer which produces the output based on the learned features</p><p>Now I used TensorFlow's Keras API to create a Convolutional Neural Network (CNN) model that matches the diagram.</p><pre><code># CNN_Model.py import tensorflow as tf from tensorflow.keras import layers, models # Initializing the CNN model model = models.Sequential() # Referencing the Image Icon in the provided diagram # Assuming the input image has a shape of (64, 64, 3), which is a standard for RGB images. # Convolution Block 1 (referenced as Blue in the diagram) model.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(64, 64, 3))) model.add(layers.MaxPooling2D((2, 2))) # Convolution Block 2 (referenced as Green in the diagram) model.add(layers.Conv2D(64, (3,3), activation='relu')) model.add(layers.MaxPooling2D((2, 2))) # Convolution Block 3 (referenced as Orange in the diagram) model.add(layers.Conv2D(128, (3,3), activation='relu')) model.add(layers.MaxPooling2D((2, 2))) # Flatten Layer (referenced as Gray in the diagram) model.add(layers.Flatten()) # Fully Connected Layer 1 (represented as circles in "Layer 1") model.add(layers.Dense(128, activation='relu')) # Fully Connected Layer 2 (represented as circles in "Layer 2") model.add(layers.Dense(64, activation='relu')) # Fully Connected Layer 3 (represented as circles in "Layer 3") model.add(layers.Dense(32, activation='relu')) # Output Layer (represented as the "Output" Yellow rectangle in the diagram) # Assuming a binary classification task for simplicity model.add(layers.Dense(1, activation='sigmoid')) # Use 'softmax' for multi-class problems. model.compile(optimizer='adam', loss='binary_crossentropy', # Use 'categorical_crossentropy' for multi-class problems. metrics=['accuracy']) # Printing the model summary for clarity model.summary() </code></pre><ol><li><p>I start by importing the necessary modules from TensorFlow's Keras API.</p></li><li><p>The <code>Sequential</code><a href="https://www.tensorflow.org/api_docs/python/tf/keras/Sequential"> model</a> is initialized, indicating that layers are added in sequence.</p></li><li><p>Following the structure of the provided image:</p><ul><li><p>We add three <code>Conv2D</code><a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D"> layers</a> for convolution operations, where each layer attempts to identify patterns in the image. They are followed by <code>MaxPooling2D</code><a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPooling2D"> layers</a> which down-sample the spatial dimensions of the previous layer.</p></li><li><p>The <code>Flatten</code><a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/Flatten"> layer</a> converts the 2D matrices from previous layers into a 1D vector.</p></li><li><p>Three fully connected <code>Dense</code><a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense"> layers</a> follow the flattening operation. They perform high-level reasoning based on the patterns identified in previous layers.</p></li><li><p>Finally, an output <code>Dense</code> layer is added. I assumed a binary classification task, but this can be modified based on the number of classes in the task.</p></li></ul></li><li><p>The <code>compile</code><a href="https://www.tensorflow.org/api_docs/python/tf/keras/Model#compile"> method</a> prepares the model for training, specifying the optimizer, loss function, and evaluation metric.</p></li><li><p><code>model.summary() </code><a href="https://www.tensorflow.org/api_docs/python/tf/keras/Model#summary">method</a> prints a summary of the model's architecture, so you can visually inspect the sequence of layers.</p></li></ol><p>As an architect, CNNs opens up a new spectrum of design solutions. With CNNs, applications like real-time image and video recognition, or even complex anomaly detection in multidimensional data become feasible. The<strong> automated feature extraction</strong> capability of CNNs can significantly reduce the time and effort required in the data preprocessing stage, allowing for quicker deployments and iterations. Understanding the architectural underpinnings and the potential of CNNs can lead to more informed decisions when designing systems revolving around image or video data processing.</p><h2><strong>Recurrent Neural Networks (RNN)</strong></h2><p>Recurrent Neural Networks (RNN)<a class="footnote-anchor" data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-2" href="#footnote-2" target="_self">2</a> are a class of artificial neural networks where connections between nodes form a directed graph along a temporal sequence. Unlike traditional neural networks, RNNs have a "memory" that captures information about what has been calculated so far. This feature makes RNNs extremely useful for tasks involving sequential data like time series prediction, natural language processing, and speech recognition.</p><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F198ad895-a6bd-47c0-bd5b-72f7347dd97a_1581x1881.png" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F198ad895-a6bd-47c0-bd5b-72f7347dd97a_1581x1881.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F198ad895-a6bd-47c0-bd5b-72f7347dd97a_1581x1881.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F198ad895-a6bd-47c0-bd5b-72f7347dd97a_1581x1881.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F198ad895-a6bd-47c0-bd5b-72f7347dd97a_1581x1881.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F198ad895-a6bd-47c0-bd5b-72f7347dd97a_1581x1881.png" width="1456" height="1732" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/198ad895-a6bd-47c0-bd5b-72f7347dd97a_1581x1881.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1732,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:421459,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F198ad895-a6bd-47c0-bd5b-72f7347dd97a_1581x1881.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F198ad895-a6bd-47c0-bd5b-72f7347dd97a_1581x1881.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F198ad895-a6bd-47c0-bd5b-72f7347dd97a_1581x1881.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F198ad895-a6bd-47c0-bd5b-72f7347dd97a_1581x1881.png 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a></figure></div><h3><strong>Components of RNN</strong></h3><h4><strong>Recurrent Layer</strong></h4><p>The recurrent layer consists of a loop that connects the current time step to the previous time step, enabling the network to use information from the past in the current computation.</p><h4><strong>Hidden State</strong></h4><p>The hidden state captures information from previous time steps. It's like the memory of the network, retaining crucial insights from past data to help in current processing.</p><h4><strong>Output Layer</strong></h4><p>The output layer generates the final output for the current time step based on the current input and the hidden state.</p><h4><strong>Activation Functions</strong></h4><p>Similar to other neural networks, activation functions introduce non-linearity into the system, which enables the network to learn from the error, and make adjustments to the weights of the inputs.</p><h4>Loss Function</h4><p>The loss function (like Cross-Entropy or Mean Squared Error) measures the discrepancy between the predicted output and the true output, guiding the optimization of the network weights.</p><h3><strong>Recurrent Mechanism</strong></h3><h4><strong>Hidden State</strong></h4><p>The primary component responsible for memory in RNNs is the hidden state. The hidden state is a representation that captures information from past inputs and carries it forward to help process future inputs. At each time step, the hidden state is updated based on the current input and the previous hidden state. This way, it encapsulates information from all the previous steps up to the current step.</p><pre><code># Simplified RNN mechanism hidden_state = initial_state # This state will be updated over time # Combine the input and the current state to generate the new state # Now, hidden_state contains information from the past and the current input for input in sequence: hidden_state = activation_function(W * input + U * hidden_state + b) </code></pre><h4> <strong>Recurrent Connections</strong></h4><p>The recurrent connections are what allow the network to maintain this memory. They create a looped pathway that feeds the hidden state from one step back into the network for the next step. This recurrent loop essentially creates a form of memory, where information from previous steps can continue to influence the processing of new steps.</p><h4><strong>Memory in Action</strong></h4><p>Consider a simple task of predicting the next word in a sentence. If the current word is "sky", and the previous words were "The", and "blue", an RNN could use its memory of these previous words to help predict that the next word might be "is". The memory in this case helps the RNN understand the context in which the current word appears.</p><h4><strong>Memory Duration</strong></h4><p>The ability of RNNs to maintain this memory over many steps is both its strength and its weakness. While it's useful for understanding context over sequences, the memory in basic RNNs tends to be quite short-term due to the vanishing gradient problem, which makes it hard for the network to learn from interactions occurring over longer sequences. Advanced variants of RNNs like Long Short-Term Memory (LSTM) networks and Gated Recurrent Units (GRUs) have been developed to address this, providing longer-term memory capabilities and making RNNs even more powerful for handling sequential data.</p><p>In summary, memory in RNNs facilitates the processing and understanding of sequential or temporal data by allowing the network to use information from past inputs while processing current inputs, which is crucial for tasks like language modeling, time series prediction, and many other applications where understanding context over time is essential.</p><p>I again used TensorFlow's Keras API to create a Recurrent Neural Network (RNN) model that matches the diagram. </p><pre><code># RNN_Model.py import tensorflow as tf from tensorflow.keras import layers, models # Initializing the model model = models.Sequential() # Input Layer (represented as green circles in the diagram) # Assuming input data is of shape (n, m) where n represents features and m represents samples. model.add(layers.Input(shape=(None,))) # Hidden Layer 1 (referenced as "Layer 1" in the diagram) # Assuming 5 neurons based on the diagram model.add(layers.Dense(5, activation='relu')) # Recurrence within Hidden Layer (indicated by the dashed red line) # A simple recurrence can be implemented using a SimpleRNN layer in Keras. # Here, we're assuming recurrence in the second hidden layer. # Assuming 5 neurons model.add(layers.SimpleRNN(5, activation='relu', return_sequences=True)) # Hidden Layer 2 (referenced as "Layer 2" in the diagram) # After the SimpleRNN layer, the data will be 3D (batch_size, timesteps, features). # So, we need to flatten the data to feed into the Dense layer. model.add(layers.Flatten()) model.add(layers.Dense(5, activation='relu')) # Assuming 5 neurons based on the diagram # Output Layer (represented as the blue circle in the diagram) # Assuming a single output for regression task. model.add(layers.Dense(1)) # Compiling the model model.compile(optimizer='adam', loss='mean_squared_error') # Printing the model summary for clarity model.summary()</code></pre><ol><li><p>The <code>Sequential</code> model is initialized.</p></li><li><p>The <code>Input</code> layer is added to define the input shape of the data. The actual shape would be dependent on the dataset.</p></li><li><p>The first hidden layer (<code>Layer 1</code> in the diagram) is added with 5 neurons, as visually indicated.</p></li><li><p>To capture the recurrence shown in the diagram, a <code>SimpleRNN</code><a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/SimpleRNN"> layer</a> is added. This layer can capture sequences in the data. The layer has 5 neurons, aligning with the number of circles in the diagram.</p></li><li><p>As the <code>SimpleRNN</code> produces 3D output data (batch_size, timesteps, features), we use the <code>Flatten</code> layer to reshape it for the next dense layer.</p></li><li><p>Another dense hidden layer (<code>Layer 2</code> in the diagram) with 5 neurons follows.</p></li><li><p>The final output layer is added. For simplicity, I assumed this is a regression task with a single output. If it's a classification task, you might want to use an activation like <code>sigmoid</code> or <code>softmax</code> and adjust the loss function accordingly during compilation.</p></li><li><p>The model is compiled using the Adam optimizer and a mean squared error loss, typically used for regression tasks.</p></li></ol><p>Understanding RNNs provides a way to design solutions around problems involving sequential data. The ability to handle temporal dynamics opens a new possibilities in application areas like real-time analytics, natural language processing, and many others. From an architectural standpoint, understanding the mechanisms of RNNs and their potential applications can be a cornerstone in building intelligent systems capable of interpreting and reacting to sequential or time-dependent data.</p><div class="subscription-widget-wrap-editor" data-attrs="{&quot;url&quot;:&quot;https://www.tostring.ai/subscribe?&quot;,&quot;text&quot;:&quot;Subscribe&quot;,&quot;language&quot;:&quot;en&quot;}" data-component-name="SubscribeWidgetToDOM"><div class="subscription-widget show-subscribe"><div class="preamble"><p class="cta-caption">toString() is a reader-supported publication. To receive new posts and support my work, consider becoming a free or paid subscriber.</p></div><form class="subscription-widget-subscribe"><input type="email" class="email-input" name="email" placeholder="Type your email&#8230;" tabindex="-1"><input type="submit" class="button primary" value="Subscribe"><div class="fake-input-wrapper"><div class="fake-input"></div><div class="fake-button"></div></div></form></div></div><h3><strong>Conclusion</strong></h3><p>Deep Learning is a paradigm where machines can learn from data at a depth which was previously unthought of. As a software architect, understanding and leveraging the intricacies of Neural Networks, CNNs, and RNNs opens up a frontier of possibilities in designing intelligent systems capable of self-learning, recognizing complex patterns, and making informed decisions over time.</p><p>As this episode comes to a close, the anticipation for the subsequent explorations into the heart of AI keeps the quest for knowledge aflame. The journey continues to be as exhilarating as it is enlightening, each step forward is a step into the future of software architecture, where machines not only compute but learn, adapt, and evolve.</p><p>As we close the chapter on Neural Networks, our next episode will delve into Large Language Models (LLMs) and the transformative world of Generative AI.</p><p><strong>Here's a brief on what to anticipate</strong>:</p><ol><li><p><strong>LLMs</strong>:</p><ul><li><p>Exploring Transformer Architecture and Attention Mechanisms.</p></li><li><p>Strategies of Pre-training and Fine-tuning.</p></li></ul></li><li><p><strong>Natural Language Processing</strong>:</p><ul><li><p>Insights into Text Mining and Sentiment Analysis.</p></li></ul></li><li><p><strong>Generative AI</strong>:</p><ul><li><p>Unveiling Generative Adversarial Networks (GANs) and Text Generation Techniques.</p></li></ul></li></ol><p>Stay tuned for the next episode in this AI Odyssey.</p><div class="footnote" data-component-name="FootnoteToDOM"><a id="footnote-1" href="#footnote-anchor-1" class="footnote-number" contenteditable="false" target="_self">1</a><div class="footnote-content"><p>https://en.wikipedia.org/wiki/Feature_engineering</p></div></div><div class="footnote" data-component-name="FootnoteToDOM"><a id="footnote-2" href="#footnote-anchor-2" class="footnote-number" contenteditable="false" target="_self">2</a><div class="footnote-content"><p>https://developer.ibm.com/articles/cc-cognitive-recurrent-neural-networks/</p><p></p></div></div> ]]>
</content:encoded>
</item>
<item>
<title>
<![CDATA[ E2: Journey into how Machines learn ]]>
</title>
<description>
<![CDATA[ Breaking Down ML ]]>
</description>
<link>https://www.tostring.ai/p/e2-journey-into-how-machines-learn</link>
<guid isPermaLink="true">https://www.tostring.ai/p/e2-journey-into-how-machines-learn</guid>
<dc:creator>
<![CDATA[ Marco Altea ]]>
</dc:creator>
<pubDate>Fri, 20 Oct 2023 07:00:30 GMT</pubDate>
<enclosure url="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F206d6575-bcc8-459d-a7b8-6b671f465932_1024x1024.png" length="0" type="image/jpeg"/>
<content:encoded>
<![CDATA[ <h3><strong>Introduction</strong></h3><p>As the digital landscape continuously change, introducing new paradigms, it&#8217;s a constant of a life for Software and Solution architect. The first chapter of my AI Odyssey went into Artificial Intelligence and Large Language Models, unravelling their foundational parts. My next stop is Machine Learning (ML). This realm is the fuel of the intelligence in AI.</p><p>Machine Learning, at its core, is about teaching machines to learn from data, to find patterns, and to make decisions (without awareness or consciousness). It's a foundational aspect in the broad field of AI, marking the initial steps towards equipping machines with a form of intelligence.</p><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F206d6575-bcc8-459d-a7b8-6b671f465932_1024x1024.png" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F206d6575-bcc8-459d-a7b8-6b671f465932_1024x1024.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F206d6575-bcc8-459d-a7b8-6b671f465932_1024x1024.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F206d6575-bcc8-459d-a7b8-6b671f465932_1024x1024.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F206d6575-bcc8-459d-a7b8-6b671f465932_1024x1024.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F206d6575-bcc8-459d-a7b8-6b671f465932_1024x1024.png" width="572" height="572" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/206d6575-bcc8-459d-a7b8-6b671f465932_1024x1024.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1024,&quot;width&quot;:1024,&quot;resizeWidth&quot;:572,&quot;bytes&quot;:2319644,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F206d6575-bcc8-459d-a7b8-6b671f465932_1024x1024.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F206d6575-bcc8-459d-a7b8-6b671f465932_1024x1024.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F206d6575-bcc8-459d-a7b8-6b671f465932_1024x1024.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F206d6575-bcc8-459d-a7b8-6b671f465932_1024x1024.png 1456w" sizes="100vw" fetchpriority="high"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a></figure></div><p></p><p>As an architect, exploring into ML means gaining a new perspective on the digital ecosystem. It's about understanding the mechanics that allow machines to exhibit human-like intelligence and using this knowledge to build strong, intelligent systems. Mastering ML concepts goes beyond theory, it's a practical journey to improve my architectural skills, to create systems that are not only efficient but also have the ability to learn, evolve, and adapt to the constantly changing digital environment.</p><p>This journey into ML and DL extends beyond just algorithms and models. It's about how I, as architect, can utilize learning machines to drive innovation, solve real-world issues, and develop systems that adapt to the dynamic digital age. </p><h3><strong>Unveiling Machine Learning (ML)</strong></h3><p>Machine Learning (ML) sits at the heart of modern computational innovation. It's not about programming explicit instructions, but rather feeding a system a large amount of data and allowing it to learn the patterns<a class="footnote-anchor" data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-1" href="#footnote-1" target="_self">1</a>. This premise is simple yet powerful. As an architect, I find it amazing how a machine can be trained to discern patterns and make predictions or decisions based on data. </p><p><em>This is the crux of ML and where our exploration begins.</em></p><p>The realm of ML is broad, encapsulating various learning paradigms. It's essential from my reading to grasp these to comprehend how machines learn and adapt. The primary paradigms are:</p><h4>Supervised Learning</h4><p>Supervised learning is a type of Machine Learning paradigm where the model is trained on labelled data. The data is provided with the answer key, and the algorithm iteratively makes predictions on the training data and is corrected by the teacher (In this context, the term "teacher" metaphorically refers to the provided labels or the ground truth in the dataset), allowing the model to learn over time.</p><h5>The Mathematics Behind it:</h5><p>In Supervised Learning, we typically have a dataset of input-output pairs, denoted as <br></p><div class="latex-rendered" data-attrs="{&quot;persistentExpression&quot;:&quot;(x \n1\n&#8203;\n ,y \n1\n&#8203;\n ),(x \n2\n&#8203;\n ,y \n2\n&#8203;\n ),...,(x \nn\n&#8203;\n ,y \nn\n&#8203;\n )&quot;,&quot;id&quot;:&quot;SYUADHRCNK&quot;}" data-component-name="LatexBlockToDOM"></div><p>where <em>x</em> represents the input data and <em>y</em> represents the labels.</p><p>One common algorithm used in Supervised Learning is Linear Regression. The goal is to find the parameters that minimize the difference between the predicted outputs and the true outputs. Mathematically, it&#8217;s defined as &#8220;loss function&#8221;, usually the Mean Squared Error (MSE) loss.</p><p>Linear Regression is like finding the straight line that best fits or represents the relationship between house size and price. The closer this line is to the actual prices, the better, a fantastic explanation of the Linear Regression you can find it here</p><div class="embedded-post-wrap" data-attrs="{&quot;id&quot;:54474544,&quot;url&quot;:&quot;https://bowtiedraptor.substack.com/p/understanding-linear-regression&quot;,&quot;publication_id&quot;:617941,&quot;publication_name&quot;:&quot;Data Science &amp; Machine Learning 101&quot;,&quot;publication_logo_url&quot;:&quot;https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F5ef5c621-b4cc-4ad4-9f90-a15a8b49e008_657x657.png&quot;,&quot;title&quot;:&quot;Understanding Linear Regression&quot;,&quot;truncated_body_text&quot;:&quot;Required Readings Basic Data Wrangling Knowledge on Normal Distribution How to work with libraries Table of Contents: Where You Will Use this? What is Regression? What is Linear Regression (Multiple)? The Assumptions of Linear Regression Implementing Linear Regression&quot;,&quot;date&quot;:&quot;2022-05-18T13:18:46.509Z&quot;,&quot;like_count&quot;:4,&quot;comment_count&quot;:9,&quot;bylines&quot;:[{&quot;id&quot;:34373038,&quot;name&quot;:&quot;BowTied_Raptor&quot;,&quot;handle&quot;:&quot;bowtiedraptor&quot;,&quot;previous_name&quot;:null,&quot;photo_url&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/e856c8a7-1bde-42a0-87ac-de9a554f1b8d_400x400.jpeg&quot;,&quot;bio&quot;:&quot;Writes about Data Science/AI/ML&quot;,&quot;profile_set_up_at&quot;:&quot;2021-05-25T13:25:47.486Z&quot;,&quot;publicationUsers&quot;:[{&quot;id&quot;:550495,&quot;user_id&quot;:34373038,&quot;publication_id&quot;:617941,&quot;role&quot;:&quot;admin&quot;,&quot;public&quot;:true,&quot;is_primary&quot;:false,&quot;publication&quot;:{&quot;id&quot;:617941,&quot;name&quot;:&quot;Data Science &amp; Machine Learning 101&quot;,&quot;subdomain&quot;:&quot;bowtiedraptor&quot;,&quot;custom_domain&quot;:null,&quot;custom_domain_optional&quot;:false,&quot;hero_text&quot;:&quot;By Data Professionals, for Data Professionals. \nThis is your centralized Website that has all of your data professional needs:\nWe cover:\n - Money Making Guides\n - Job Searching\n - Technical Skills (R, Python, SQL, MLOps, etc...)\n - Industry Knowledge&quot;,&quot;logo_url&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/5ef5c621-b4cc-4ad4-9f90-a15a8b49e008_657x657.png&quot;,&quot;author_id&quot;:34373038,&quot;theme_var_background_pop&quot;:&quot;#FF0000&quot;,&quot;created_at&quot;:&quot;2021-12-17T05:13:30.963Z&quot;,&quot;rss_website_url&quot;:null,&quot;email_from_name&quot;:&quot;BT_Raptor - Data Science &amp; Machine Learning 101&quot;,&quot;copyright&quot;:&quot;BowTied_Raptor&quot;,&quot;founding_plan_name&quot;:null,&quot;community_enabled&quot;:true,&quot;invite_only&quot;:false,&quot;payments_state&quot;:&quot;enabled&quot;,&quot;language&quot;:null,&quot;explicit&quot;:false}}],&quot;twitter_screen_name&quot;:&quot;BowTied_Raptor&quot;,&quot;is_guest&quot;:false,&quot;bestseller_tier&quot;:100}],&quot;utm_campaign&quot;:null,&quot;belowTheFold&quot;:true,&quot;type&quot;:&quot;newsletter&quot;,&quot;language&quot;:&quot;en&quot;}" data-component-name="EmbeddedPostToDOM"><a class="embedded-post" native="true" href="https://bowtiedraptor.substack.com/p/understanding-linear-regression?utm_source=substack&amp;utm_campaign=post_embed&amp;utm_medium=web"><div class="embedded-post-header"><img class="embedded-post-publication-logo" src="https://substackcdn.com/image/fetch/w_56,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F5ef5c621-b4cc-4ad4-9f90-a15a8b49e008_657x657.png" loading="lazy"><span class="embedded-post-publication-name">Data Science &amp; Machine Learning 101</span></div><div class="embedded-post-title-wrapper"><div class="embedded-post-title">Understanding Linear Regression</div></div><div class="embedded-post-body">Required Readings Basic Data Wrangling Knowledge on Normal Distribution How to work with libraries Table of Contents: Where You Will Use this? What is Regression? What is Linear Regression (Multiple)? The Assumptions of Linear Regression Implementing Linear Regression&#8230;</div><div class="embedded-post-cta-wrapper"><span class="embedded-post-cta">Read more</span></div><div class="embedded-post-meta">3 years ago &#183; 4 likes &#183; 9 comments &#183; BowTied_Raptor</div></a></div><p>The Mean Squared Error (MSE) is a way to measure how well the line fits the data by averaging the squares of the differences (errors) between the predicted prices and the actual prices. Our goal is to adjust the line to minimize these errors, resulting in the best possible predictions.</p><div class="subscription-widget-wrap-editor" data-attrs="{&quot;url&quot;:&quot;https://www.tostring.ai/subscribe?&quot;,&quot;text&quot;:&quot;Subscribe&quot;,&quot;language&quot;:&quot;en&quot;}" data-component-name="SubscribeWidgetToDOM"><div class="subscription-widget show-subscribe"><div class="preamble"><p class="cta-caption">toString() is a reader-supported publication. To receive new posts and support my work, consider becoming a free or paid subscriber.</p></div><form class="subscription-widget-subscribe"><input type="email" class="email-input" name="email" placeholder="Type your email&#8230;" tabindex="-1"><input type="submit" class="button primary" value="Subscribe"><div class="fake-input-wrapper"><div class="fake-input"></div><div class="fake-button"></div></div></form></div></div><p></p><h5>Real-World Use Case: Predicting House Prices</h5><p>Let's consider a simplified scenario where I&#8217;m using a single feature (house size) to predict the house price. Our dataset consists of various house sizes and their corresponding price</p><p><strong>Collecting and Preparing Data</strong>:</p><ul><li><p>Gather a dataset of house sizes and their prices.</p></li><li><p>Split the data into a training set and a testing set.</p></li></ul><p><strong>Choosing a Model</strong>:</p><ul><li><p>Choose Linear Regression as our model since we're dealing with continuous data.</p></li></ul><div class="captioned-image-container"><figure><a class="image-link image2" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4b00ac9b-7e07-447e-af80-f072a93f582b_354x96.svg" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4b00ac9b-7e07-447e-af80-f072a93f582b_354x96.svg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4b00ac9b-7e07-447e-af80-f072a93f582b_354x96.svg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4b00ac9b-7e07-447e-af80-f072a93f582b_354x96.svg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4b00ac9b-7e07-447e-af80-f072a93f582b_354x96.svg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4b00ac9b-7e07-447e-af80-f072a93f582b_354x96.svg" width="668" height="181.22252747252747" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/4b00ac9b-7e07-447e-af80-f072a93f582b_354x96.svg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:395,&quot;width&quot;:1456,&quot;resizeWidth&quot;:668,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;\\mathrm{MSE} = \\frac{1}{n} \\sum_{i=1}^{n}(Y_{i}-\\hat{Y}_{i})^2&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" class="sizing-normal" alt="\mathrm{MSE} = \frac{1}{n} \sum_{i=1}^{n}(Y_{i}-\hat{Y}_{i})^2" title="\mathrm{MSE} = \frac{1}{n} \sum_{i=1}^{n}(Y_{i}-\hat{Y}_{i})^2" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4b00ac9b-7e07-447e-af80-f072a93f582b_354x96.svg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4b00ac9b-7e07-447e-af80-f072a93f582b_354x96.svg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4b00ac9b-7e07-447e-af80-f072a93f582b_354x96.svg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4b00ac9b-7e07-447e-af80-f072a93f582b_354x96.svg 1456w" sizes="100vw" loading="lazy"></picture><div></div></div></a></figure></div><ul><li><p><em>n</em>: The total number of data points (e.g., the number of houses you're considering).</p></li><li><p><em>yi</em>&#8203;: The actual value of the target variable for the <em>i</em>-th data point (e.g., the actual price of the <em>i</em>-th house).</p></li><li><p><em>y</em>^&#8203;<em>i</em>&#8203;: The predicted value of the target variable for the <em>i</em>-th data point (e.g., the price of the <em>i</em>-th house predicted by your model).</p></li><li><p>&#8721;: This symbol represents summation, meaning you'll add up the squared differences for all <em>n</em> data points.</p></li><li><p>(<em>yi</em>&#8203;&#8722;<em>y</em>^&#8203;<em>i</em>&#8203;)2: This part of the formula represents the squared difference between the actual value and the predicted value for each data point.</p></li></ul><p>In simpler terms, we are finding the average of the squared differences between the actual values and the predicted values, which gives you a measure of the accuracy of your model.</p><ol><li><p><strong>Training the Model</strong>:</p><ul><li><p>Use the training set to find the parameters that minimize the MSE loss.</p></li></ul></li><li><p><strong>Evaluating the Model</strong>:</p><ul><li><p>Use the testing set to evaluate the model's performance.</p></li><li><p>Measure the accuracy using metrics like R-squared or Root Mean Squared Error (RMSE).</p></li></ul></li><li><p><strong>Making Predictions</strong>:</p><ul><li><p>Now, given a new house size, use the learned parameters to predict its price.</p></li></ul></li><li><p><strong>Interpreting the Results</strong>:</p><ul><li><p>Analyze how well the model generalizes to new, unseen data.</p></li></ul></li></ol><p>This process shows how Supervised Learning algorithms like Linear Regression can be used to make predictions on continuous data, thus aiding in better decision-making and system design from an architectural standpoint.</p><h4>Unsupervised Learning</h4><p>Unsupervised Learning (UL) is another realm of Machine Learning, where the algorithms are left on their own to discover and present the interesting structures in the data. Unlike Supervised Learning, there are no labels here, no teacher to correct the model. The model learns through observation and finds structures in the data on its own.</p><p>One classic example of Unsupervised Learning is clustering.</p><p>Clustering<a class="footnote-anchor" data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-2" href="#footnote-2" target="_self">2</a> is a technique used to group data points together based on certain similarities, without having prior knowledge of these groups. Imagine we have a dataset of different varieties of wines, each wine represents a data point with features like color, alcohol content, and sugar level. </p><pre><code> data = { 'Wine_Variety': ['Merlot', 'Chardonnay', 'Cabernet Sauvignon', 'Pinot Noir', 'Riesling', 'Sauvignon Blanc', 'Zinfandel'], 'Color': ['Red', 'White', 'Red', 'Red', 'White', 'White', 'Red'], 'Alcohol_Content': [13.5, 14.0, 13.8, 13.4, 11.5, 13.0, 14.5], # in percentage 'Sugar_Level': [1.5, 2.0, 1.2, 1.8, 2.5, 1.9, 2.2] # scale from 1 to 3 (1-Dry, 2-Medium, 3-Sweet) }</code></pre><p>The essence of clustering lies in finding inherent groupings within the data. The algorithm explores the structure of the data to identify clusters of wines that share similar characteristics, essentially uncovering hidden patterns. This way, even without pre-defined labels, the wines are categorized into different groups, making the data more understandable and ready for further analysis.</p><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F930481d5-4c58-4921-9679-a62f0ac37eb1_1024x1024.png" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F930481d5-4c58-4921-9679-a62f0ac37eb1_1024x1024.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F930481d5-4c58-4921-9679-a62f0ac37eb1_1024x1024.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F930481d5-4c58-4921-9679-a62f0ac37eb1_1024x1024.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F930481d5-4c58-4921-9679-a62f0ac37eb1_1024x1024.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F930481d5-4c58-4921-9679-a62f0ac37eb1_1024x1024.png" width="1024" height="1024" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/930481d5-4c58-4921-9679-a62f0ac37eb1_1024x1024.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1024,&quot;width&quot;:1024,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1008314,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F930481d5-4c58-4921-9679-a62f0ac37eb1_1024x1024.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F930481d5-4c58-4921-9679-a62f0ac37eb1_1024x1024.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F930481d5-4c58-4921-9679-a62f0ac37eb1_1024x1024.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F930481d5-4c58-4921-9679-a62f0ac37eb1_1024x1024.png 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a></figure></div><p>Probably the most popular clustering algorithm used in unsupervised machine learning and data analysis is K-means. The algorithm categorizes the data into K number of clusters. It works iteratively to assign each data point to one of K groups based on the features that are provided</p><p><strong>Step 1:</strong> Initialization - Randomly initialize K centroids. </p><p><strong>Step 2:</strong> Assignment - Assign each data point to the nearest centroid, and it becomes a member of that cluster. </p><p><strong>Step 3:</strong> Update - Calculate the new centroid (mean) of each cluster. </p><p><strong>Step 4:</strong> Repeat Steps 2 and 3 until there are no changes in the assignments or a maximum number of iterations is reached.</p><pre><code># File path: /your_directory/wine_clustering.py # Importing necessary libraries from sklearn.cluster import KMeans from sklearn.preprocessing import LabelEncoder import pandas as pd # Wine dataset data = { 'Wine_Variety': ['Merlot', 'Chardonnay', 'Cabernet Sauvignon', 'Pinot Noir', 'Riesling', 'Sauvignon Blanc', 'Zinfandel'], 'Color': ['Red', 'White', 'Red', 'Red', 'White', 'White', 'Red'], 'Alcohol_Content': [13.5, 14.0, 13.8, 13.4, 11.5, 13.0, 14.5], 'Sugar_Level': [1.5, 2.0, 1.2, 1.8, 2.5, 1.9, 2.2] } df_wine = pd.DataFrame(data) # Converting the 'Color' column to numerical values le = LabelEncoder() df_wine['Color'] = le.fit_transform(df_wine['Color']) # Red:1, White:0 # Defining the number of clusters num_clusters = 3 # Creating the KMeans object and fitting it to the wine data kmeans = KMeans(n_clusters=num_clusters, random_state=0).fit(df_wine[['Color', 'Alcohol_Content', 'Sugar_Level']]) # The labels of the clusters labels = kmeans.labels_ # The centroids of the clusters centroids = kmeans.cluster_centers_ # Adding the cluster labels to the original DataFrame df_wine['Cluster'] = labels # Now df_wine has an additional column 'Cluster' indicating the cluster each wine </code></pre><p>In this code</p><ol><li><p>The 'Color' column is converted to numerical values using the <code>LabelEncoder</code> from scikit-learn, where Red is encoded as 1 and White is encoded as 0.</p></li><li><p>The KMeans object is created and fitted to the wine data using the specified number of clusters (<code>num_clusters = 3</code>).</p></li><li><p>Cluster labels are generated and added to the original DataFrame in a new column called 'Cluster'.</p></li></ol><p>Output <a href="https://onecompiler.com/python/3zqxen5yy">Python One Compiler Code</a> :</p><pre><code> Wine_Variety Color Alcohol_Content Sugar_Level Cluster 0 Merlot 0 13.5 1.5 1 1 Chardonnay 1 14.0 2.0 2 2 Cabernet Sauvignon 0 13.8 1.2 1 3 Pinot Noir 0 13.4 1.8 1 4 Riesling 1 11.5 2.5 0 5 Sauvignon Blanc 1 13.0 1.9 2 6 Zinfandel 0 14.5 2.2 1</code></pre><h5>The Mathematics Behind it:</h5><p>The objective of K-means is to minimize the variance within each cluster and maximize the variance between different clusters. Mathematically, it&#8217;s defined as an objective function J that we aim to minimize</p><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9bbfa971-6177-4b84-ab97-72eec914539a_552x257.png" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9bbfa971-6177-4b84-ab97-72eec914539a_552x257.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9bbfa971-6177-4b84-ab97-72eec914539a_552x257.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9bbfa971-6177-4b84-ab97-72eec914539a_552x257.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9bbfa971-6177-4b84-ab97-72eec914539a_552x257.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9bbfa971-6177-4b84-ab97-72eec914539a_552x257.png" width="552" height="257" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/9bbfa971-6177-4b84-ab97-72eec914539a_552x257.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:257,&quot;width&quot;:552,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:16401,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9bbfa971-6177-4b84-ab97-72eec914539a_552x257.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9bbfa971-6177-4b84-ab97-72eec914539a_552x257.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9bbfa971-6177-4b84-ab97-72eec914539a_552x257.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9bbfa971-6177-4b84-ab97-72eec914539a_552x257.png 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a></figure></div><p><strong>Algorithm</strong></p><ol><li><p>Clusters the data into <em>k</em> groups where <em>k</em>&nbsp; is predefined.</p></li><li><p>Select <em>k</em> points at random as cluster centers.</p></li><li><p>Assign objects to their closest cluster center according to the <em>Euclidean distance</em> function.</p></li><li><p>Calculate the centroid or mean of all objects in each cluster.</p></li><li><p>Repeat steps 2, 3 and 4 until the same points are assigned to each cluster in consecutive rounds.</p></li></ol><p>As an architect, the potential of uncovering hidden structures in data, which could be pivotal in designing intelligent systems that can discover and adapt to the underlying patterns in the ever-evolving digital landscape.</p><h4>Reinforcement Learning</h4><p>Reinforcement Learning (RL) is a type of learning where an agent learns how to behave in an environment by performing certain actions and observing the rewards of those actions. It's much like learning by trial and error. In RL, the agent receives feedback in the form of rewards or penalties, which it uses to adjust its behavior to achieve the maximum cumulative reward</p><p>Imagine I&#8217;m developing a wine recommendation system (our agent) to suggest wines to customers based on their past preferences. Each successful recommendation, where a customer buys or positively rates a wine, rewards our system, while unsuccessful recommendations penalize it. Over time, our system learns to make better recommendations, maximizing customer satisfaction and, by extension, sales.</p><pre><code>import numpy as np # Define the states, actions, rewards, and other parameters states = [...] # e.g., different customer profiles actions = [...] # e.g., different wine recommendations rewards = np.zeros((len(states), len(actions))) # initialize rewards matrix q_values = np.zeros((len(states), len(actions))) # initialize Q-values matrix alpha = 0.1 # learning rate gamma = 0.9 # discount factor # Simulate the Q-learning process for episode in range(1000): # assume 1000 episodes state = np.random.choice(states) # start with a random state while True: action = np.argmax(q_values[state, :] + np.random.randn(1, len(actions)) * (1./(episode+1))) # choose an action reward = rewards[state, action] # get the reward next_state = ... # determine the next state # Update the Q-value q_values[state, action] = q_values[state, action] + alpha * (reward + gamma * np.max(q_values[next_state, :]) - q_values[state, action]) state = next_state # move to the next state if ...: # check if the episode ends break </code></pre><p>In this code snippet, I initialize our Q-values and simulate the Q-learning process over 1000 episodes to improve the wine recommendation system. With each episode, the Q-values are updated, and the recommendation policy improves, leading to better wine recommendations over time.</p><h5>The Mathematics Behind it:</h5><p>In RL, the agent uses a strategy known as a policy to decide its actions. One common approach is using a Q-Learning algorithm, which estimates the total expected rewards for each action in each state. The Q-value for a particular state-action pair is updated using the formula:<a class="footnote-anchor" data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-3" href="#footnote-3" target="_self">3</a></p><div class="captioned-image-container"><figure><a class="image-link image2" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2bc7f167-576c-4eed-b968-1e05ba312aab_819x107.svg" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2bc7f167-576c-4eed-b968-1e05ba312aab_819x107.svg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2bc7f167-576c-4eed-b968-1e05ba312aab_819x107.svg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2bc7f167-576c-4eed-b968-1e05ba312aab_819x107.svg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2bc7f167-576c-4eed-b968-1e05ba312aab_819x107.svg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2bc7f167-576c-4eed-b968-1e05ba312aab_819x107.svg" width="1456" height="190" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/2bc7f167-576c-4eed-b968-1e05ba312aab_819x107.svg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:190,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;{\\displaystyle Q^{new}(s_{t},a_{t})\\leftarrow (1-\\underbrace {\\alpha } _{\\text{learning rate}})\\cdot \\underbrace {Q(s_{t},a_{t})} _{\\text{current value}}+\\underbrace {\\alpha } _{\\text{learning rate}}\\cdot {\\bigg (}\\underbrace {\\underbrace {r_{t}} _{\\text{reward}}+\\underbrace {\\gamma } _{\\text{discount factor}}\\cdot \\underbrace {\\max _{a}Q(s_{t+1},a)} _{\\text{estimate of optimal future value}}} _{\\text{new value (temporal difference target)}}{\\bigg )}}&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" class="sizing-normal" alt="{\displaystyle Q^{new}(s_{t},a_{t})\leftarrow (1-\underbrace {\alpha } _{\text{learning rate}})\cdot \underbrace {Q(s_{t},a_{t})} _{\text{current value}}+\underbrace {\alpha } _{\text{learning rate}}\cdot {\bigg (}\underbrace {\underbrace {r_{t}} _{\text{reward}}+\underbrace {\gamma } _{\text{discount factor}}\cdot \underbrace {\max _{a}Q(s_{t+1},a)} _{\text{estimate of optimal future value}}} _{\text{new value (temporal difference target)}}{\bigg )}}" title="{\displaystyle Q^{new}(s_{t},a_{t})\leftarrow (1-\underbrace {\alpha } _{\text{learning rate}})\cdot \underbrace {Q(s_{t},a_{t})} _{\text{current value}}+\underbrace {\alpha } _{\text{learning rate}}\cdot {\bigg (}\underbrace {\underbrace {r_{t}} _{\text{reward}}+\underbrace {\gamma } _{\text{discount factor}}\cdot \underbrace {\max _{a}Q(s_{t+1},a)} _{\text{estimate of optimal future value}}} _{\text{new value (temporal difference target)}}{\bigg )}}" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2bc7f167-576c-4eed-b968-1e05ba312aab_819x107.svg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2bc7f167-576c-4eed-b968-1e05ba312aab_819x107.svg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2bc7f167-576c-4eed-b968-1e05ba312aab_819x107.svg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2bc7f167-576c-4eed-b968-1e05ba312aab_819x107.svg 1456w" sizes="100vw" loading="lazy"></picture><div></div></div></a></figure></div><ul><li><p><em>s</em> and <em>s</em>&#8242; are the current and next states,</p></li><li><p><em>a</em> and <em>a</em>&#8242; are the current and potential future actions,</p></li><li><p><em>r</em> is the immediate reward,</p></li><li><p><em>&#945;</em> is the learning rate (how much we update our Q-value),</p></li><li><p><em>&#947;</em> is the discount factor (how much we value future rewards).</p></li></ul><p></p><h3><strong>Architectural Insights</strong></h3><p>In my journey, especially in commerce projects, platforms like Salesforce Commerce Cloud and SAP Commerce have been my playgrounds. These platforms leverage machine learning extensively to power their recommendation and promotion engines, providing a more tailored shopping experience. For instance, on Salesforce Commerce Cloud, the Einstein AI provides personalized recommendations by analyzing shopper data and behaviors using </p><ul><li><p><strong>Linear Regression</strong>: For predicting numerical values like sales forecasts.</p></li><li><p><strong>Classification Algorithms</strong>: For categorizing data into various classes. Algorithms like Random Forest, SVM, and Decision Trees might be employed.</p></li></ul><p>Designing systems around Machine Learning (ML) like this one calls for a understanding of scalability, efficiency, and deployment strategies.</p><p>Scalability isn&#8217;t just about handling increased load; it's about ensuring the ML models can be re-trained with larger datasets to improve accuracy over time. Efficiency touches on optimizing computational resources, minimizing latency, and ensuring the ML algorithms are fine-tuned for performance. Deployment strategies should be crafted to allow for smooth transitions, version control of models, and robust monitoring to catch anomalies early.</p><h4><strong>Training Scalability</strong></h4><p><strong>Distributed Training</strong><a class="footnote-anchor" data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-4" href="#footnote-4" target="_self">4</a></p><p>This is a technique that partitions the data and model across multiple nodes to parallelize the computational workload. From an architectural standpoint, it leverages horizontal scaling, capitalizing on data parallelism and model parallelism techniques. By distributing the model's parameters and layers across various GPUs or even across multiple servers, we can achieve a significant reduction in training time. This enables organizations to expedite their time-to-market and handle large-scale, high-dimensional data efficiently. It's critical to integrate Distributed Training into the architecture from the get-go, ensuring seamless scalability while keeping an eye on network latency and data synchronization overhead.</p><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2d19df82-f59a-4cda-9a40-cad8fb1ff0e0_1391x972.png" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2d19df82-f59a-4cda-9a40-cad8fb1ff0e0_1391x972.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2d19df82-f59a-4cda-9a40-cad8fb1ff0e0_1391x972.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2d19df82-f59a-4cda-9a40-cad8fb1ff0e0_1391x972.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2d19df82-f59a-4cda-9a40-cad8fb1ff0e0_1391x972.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2d19df82-f59a-4cda-9a40-cad8fb1ff0e0_1391x972.png" width="1391" height="972" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/2d19df82-f59a-4cda-9a40-cad8fb1ff0e0_1391x972.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:972,&quot;width&quot;:1391,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:109611,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2d19df82-f59a-4cda-9a40-cad8fb1ff0e0_1391x972.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2d19df82-f59a-4cda-9a40-cad8fb1ff0e0_1391x972.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2d19df82-f59a-4cda-9a40-cad8fb1ff0e0_1391x972.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2d19df82-f59a-4cda-9a40-cad8fb1ff0e0_1391x972.png 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a></figure></div><h4>Data Parallelism</h4><p>Data Parallelism involves distributing the dataset across multiple nodes (usually GPUs) and training a replica of the model on each node. Each node computes the gradients based on its subset of the data, which are then aggregated to update the model.</p><p><strong>How It Works</strong>:</p><ol><li><p>Partition the dataset into smaller batches.</p></li><li><p>Distribute the batches across multiple GPUs.</p></li><li><p>Each GPU computes the forward and backward pass using its subset of data.</p></li><li><p>Aggregate the gradients from all GPUs.</p></li><li><p>Update the model parameters.</p></li></ol><p><strong>Pros</strong>:</p><ul><li><p><strong>Simplicity</strong>: Easier to implement and manage.</p></li><li><p><strong>Batch Size</strong>: Allows for larger effective batch sizes, which can lead to a more stable and improved convergence.</p></li><li><p><strong>Scalability</strong>: Highly scalable as you can add more GPUs to handle larger datasets.</p></li></ul><p><strong>Cons</strong>:</p><ul><li><p><strong>Communication Overhead</strong>: Requires synchronization to aggregate gradients, which can be bandwidth-intensive.</p></li><li><p><strong>Limited by Dataset</strong>: If the dataset is too small, it may not benefit much from data parallelism.</p></li></ul><h4>Model Parallelism</h4><p><strong>Definition</strong>:<br>Model Parallelism involves splitting the model itself across multiple nodes. Each node is responsible for computing the forward and backward passes for its part of the model.</p><p><strong>How It Works</strong>:</p><ol><li><p>Divide the model layers or parameters across multiple GPUs.</p></li><li><p>Each GPU computes the forward and backward pass for its part of the model.</p></li><li><p>Communicate the intermediate outputs between GPUs as needed.</p></li></ol><p><strong>Pros</strong>:</p><ul><li><p><strong>Memory Efficiency</strong>: Allows for training of models that would not fit into the memory of a single GPU.</p></li><li><p><strong>Complex Models</strong>: Enables training of more complex models.</p></li></ul><p><strong>Cons</strong>:</p><ul><li><p><strong>Communication Overhead</strong>: Requires frequent communication between GPUs to share intermediate outputs.</p></li><li><p><strong>Implementation Complexity</strong>: More challenging to implement and manage compared to data parallelism.</p></li></ul><h4><strong>Data Parallelism vs Model Parallelism</strong></h4><ol><li><p><strong>Ease of Implementation</strong>:</p><ul><li><p><strong>Data Parallelism</strong>: Generally easier to implement.</p></li><li><p><strong>Model Parallelism</strong>: Requires more intricate handling of model layers and states.</p></li></ul></li><li><p><strong>Memory Utilization</strong>:</p><ul><li><p><strong>Data Parallelism</strong>: Can be limited by the memory of a single GPU for storing the model.</p></li><li><p><strong>Model Parallelism</strong>: More efficient in using memory for very large models.</p></li></ul></li><li><p><strong>Communication Overhead</strong>:</p><ul><li><p><strong>Data Parallelism</strong>: Involves less frequent but larger data transfers (aggregating gradients).</p></li><li><p><strong>Model Parallelism</strong>: Requires more frequent but smaller data transfers (intermediate layer outputs).</p></li></ul></li><li><p><strong>Scalability</strong>:</p><ul><li><p><strong>Data Parallelism</strong>: Scales well with larger datasets.</p></li><li><p><strong>Model Parallelism</strong>: Scales well with model complexity.</p></li></ul></li><li><p><strong>Use-Cases</strong>:</p><ul><li><p><strong>Data Parallelism</strong>: Effective for large-scale but simpler models.</p></li><li><p><strong>Model Parallelism</strong>: Necessary for complex models with many parameters that won't fit into a single GPU's memory.</p></li></ul></li></ol><ol><li><p><strong>Strategy: Data Sharding</strong></p><ul><li><p><em>Pros:</em> Efficient handling of large datasets, reduces memory load.</p></li><li><p><em>Cons:</em> Requires consistent data distribution, potential loss of inter-shard information.</p><p></p></li></ul></li></ol><h3><strong>Conclusion</strong></h3><p>In this episode, I've broken down the core concepts of Machine Learning, crucial for any architect aiming to leverage AI within system designs. The discussion around design considerations for ML systems, focusing on scalability, is fundamental for the architectural planning of robust, intelligent systems. The next episode will further this exploration into Deep Learning, extending our toolkit and understanding for designing AI-driven architectures.</p><p>Engage and with this learning journey; share your insights or ask questions in the comments below. If you found value in this exploration, share it within your network. Stay tuned for the next episode where we'll delve deeper into Deep Learning, further broadening our architectural horizon in the AI realm. Subscribe now to stay updated!</p><div class="subscription-widget-wrap-editor" data-attrs="{&quot;url&quot;:&quot;https://www.tostring.ai/subscribe?&quot;,&quot;text&quot;:&quot;Subscribe&quot;,&quot;language&quot;:&quot;en&quot;}" data-component-name="SubscribeWidgetToDOM"><div class="subscription-widget show-subscribe"><div class="preamble"><p class="cta-caption">toString() is a reader-supported publication. To receive new posts and support my work, consider becoming a free or paid subscriber.</p></div><form class="subscription-widget-subscribe"><input type="email" class="email-input" name="email" placeholder="Type your email&#8230;" tabindex="-1"><input type="submit" class="button primary" value="Subscribe"><div class="fake-input-wrapper"><div class="fake-input"></div><div class="fake-button"></div></div></form></div></div><div class="footnote" data-component-name="FootnoteToDOM"><a id="footnote-1" href="#footnote-anchor-1" class="footnote-number" contenteditable="false" target="_self">1</a><div class="footnote-content"><p>https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf</p></div></div><div class="footnote" data-component-name="FootnoteToDOM"><a id="footnote-2" href="#footnote-anchor-2" class="footnote-number" contenteditable="false" target="_self">2</a><div class="footnote-content"><p>https://developers.google.com/machine-learning/clustering/clustering-algorithms</p></div></div><div class="footnote" data-component-name="FootnoteToDOM"><a id="footnote-3" href="#footnote-anchor-3" class="footnote-number" contenteditable="false" target="_self">3</a><div class="footnote-content"><p>https://static1.squarespace.com/static/5ff2adbe3fe4fe33db902812/t/6009dd9fa7bc363aa822d2c7/1611259312432/ISLR+Seventh+Printing.pdf</p></div></div><div class="footnote" data-component-name="FootnoteToDOM"><a id="footnote-4" href="#footnote-anchor-4" class="footnote-number" contenteditable="false" target="_self">4</a><div class="footnote-content"><p>https://storage.googleapis.com/pub-tools-public-publication-data/pdf/40565.pdf</p><p></p></div></div> ]]>
</content:encoded>
</item>
<item>
<title>
<![CDATA[ E1 - From Code to Cognition: My AI Exploration Begins ]]>
</title>
<description>
<![CDATA[ Introduction to AI and LLM - history and basic concepts ]]>
</description>
<link>https://www.tostring.ai/p/e1-from-code-to-cognition-my-ai-exploration</link>
<guid isPermaLink="true">https://www.tostring.ai/p/e1-from-code-to-cognition-my-ai-exploration</guid>
<dc:creator>
<![CDATA[ Marco Altea ]]>
</dc:creator>
<pubDate>Fri, 13 Oct 2023 08:40:55 GMT</pubDate>
<enclosure url="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F751132e6-7ab7-4720-9984-a1a5787a7df3_1024x1024.png" length="0" type="image/jpeg"/>
<content:encoded>
<![CDATA[ <h3>1. Introduction</h3><p>In a world where the term "Artificial Intelligence" (AI) has become ubiquitous, it's crucial to ground my understanding in its foundational aspects. John McCarthy, a luminary in the domain from Stanford University, delved deep into the basic questions surrounding AI in his paper <a href="https://www-formal.stanford.edu/jmc/whatisai.pdf">"WHAT IS ARTIFICIAL INTELLIGENCE?"</a>. At its core, AI revolves around the science and engineering of creating intelligent machines, especially intelligent computer programs. Human intelligence, on the other hand, is often characterized by our ability to perceive, reason, learn from experience, and adapt to varying situations. People often think AI and human intelligence are the same thing. But even if AI might seem like it's thinking like us, it's actually pretty different in its own ways. That's an important thing to remember! </p><p>While AI may often engage in <strong>simulations of human intelligence</strong>, it's essential to understand that a simulation, by definition, can mimic or act like the real thing but is not the genuine article itself. Thus, AI's reflection of human-like intelligence is a crafted representation, not a genuine replication. Understanding intelligence itself is complex, described by McCarthy as the computational aspect of the ability to achieve goals. The realm of AI research is vast and multifaceted, navigating beyond mere simulations of human intelligence</p><div class="subscription-widget-wrap-editor" data-attrs="{&quot;url&quot;:&quot;https://www.tostring.ai/subscribe?&quot;,&quot;text&quot;:&quot;Subscribe&quot;,&quot;language&quot;:&quot;en&quot;}" data-component-name="SubscribeWidgetToDOM"><div class="subscription-widget show-subscribe"><div class="preamble"><p class="cta-caption">toString() is a reader-supported publication. To receive new posts and support my work, consider becoming a free or paid subscriber.</p></div><form class="subscription-widget-subscribe"><input type="email" class="email-input" name="email" placeholder="Type your email&#8230;" tabindex="-1"><input type="submit" class="button primary" value="Subscribe"><div class="fake-input-wrapper"><div class="fake-input"></div><div class="fake-button"></div></div></form></div></div><h3>2. The Evolution of Artificial Intelligence</h3><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff6360024-26aa-4e18-8219-09e7518e155e_1813x900.png" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff6360024-26aa-4e18-8219-09e7518e155e_1813x900.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff6360024-26aa-4e18-8219-09e7518e155e_1813x900.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff6360024-26aa-4e18-8219-09e7518e155e_1813x900.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff6360024-26aa-4e18-8219-09e7518e155e_1813x900.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff6360024-26aa-4e18-8219-09e7518e155e_1813x900.png" width="1456" height="723" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/f6360024-26aa-4e18-8219-09e7518e155e_1813x900.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:723,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:478002,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff6360024-26aa-4e18-8219-09e7518e155e_1813x900.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff6360024-26aa-4e18-8219-09e7518e155e_1813x900.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff6360024-26aa-4e18-8219-09e7518e155e_1813x900.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff6360024-26aa-4e18-8219-09e7518e155e_1813x900.png 1456w" sizes="100vw" fetchpriority="high"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a></figure></div><p><strong>1950s</strong>: The initiation of AI was marked by Alan Turing's <strong>Turing Test</strong>, a theoretical benchmark for gauging machine intelligence. The core idea was simple: if a machine could converse indistinguishably from a human, it could be termed 'intelligent'. Concurrently, John McCarthy's <strong>Lisp</strong> emerged as a pioneering language for AI due to its symbolic processing capabilities, representing a shift from mere arithmetic computations to symbolic reasoning.</p><p><strong>1960s</strong>: The advent of <strong>rule-based systems</strong> became evident. Joseph Weizenbaum's ELIZA utilized <strong>pattern-matching algorithms</strong> to replicate human-like interactions, marking an early exploration into Natural Language Processing (NLP). Though rudimentary, it demonstrated that machines could, at a basic level, "understand" and generate human language.</p><p><strong>1970s</strong>: Expert systems, epitomized by <strong>MYCIN</strong>, brought forth a new paradigm. MYCIN, using a <strong>backward chaining algorithm</strong>, diagnosed bacterial infections. It marked an evolutionary step by employing rule-based logic on domain-specific knowledge, showcasing the potential of machines to emulate specialized human decision-making. Concurrently, the Stanford Cart, using basic <strong>computer vision algorithms</strong>, created the promise of autonomous movement.</p><p><strong>1980s</strong>: <strong>Expert systems</strong> further matured. They encapsulated human expertise using a combination of <strong>knowledge bases and inference engines</strong>. Yet, their rigidity was evident; they were only as good as the rules fed into them. This decade also marked a resurgence of interest in <strong>neural networks</strong>, especially with the Backpropagation algorithm, which allowed the optimization of weights in multi-layered networks, paving the way for deep learning.</p><p><strong>1990s</strong>: <strong>IBM's Deep Blue</strong>, while a hardware marvel, utilized <strong>alpha-beta pruning</strong> and advanced <strong>evaluation heuristics</strong> to search through vast chess positions. This marked an evolutionary leap in combinatorial optimization. Simultaneously, Sony's <strong>AIBO</strong>, a blend of <strong> sensors and real-time processing</strong>, showcased AI's potential in robotics.</p><p><strong>2000s</strong>: The <strong>DARPA Grand Challenge</strong> was emblematic of advancements in sensor fusion and real-time decision-making. Machine learning began to shift from purely supervised paradigms to semi-supervised and unsupervised methods. Techniques like <strong>Random Forests, SVMs</strong>, and <strong>Boosting</strong> became predominant, laying the groundwork for more complex architectures.</p><p><strong>2010s</strong>: The term <strong>deep learning</strong> became synonymous with AI. DeepMind's AlphaGo combined <strong>deep convolutional networks</strong> with <strong>Monte Carlo Tree Search</strong>, marking a significant advancement in reinforcement learning. Architectures evolved from simple feed-forward networks to more complex structures like <strong>RNNs</strong>, <strong>LSTMs</strong>, and <strong>Transformers</strong>. OpenAI's GPT-2's transformer architecture showcased the potential of <strong>attention mechanisms</strong>, setting new benchmarks in NLP.</p><p><strong>2020s</strong>: OpenAI's <strong>GPT-3</strong> brought <strong>zero-shot and few-shot learning</strong> into the spotlight, emphasizing the capability of models to generalize from limited data. This evolution underscores a trend: from handcrafted rules to data-driven decision-making, from shallow models to deep, intricate architectures.</p><h3>3. Basic Terminology and Applications</h3><p><strong>Artificial Intelligence (AI):</strong> AI refers to the capability of a machine to <strong>mimic</strong> intelligent human behavior. It's a broad field that encompasses everything from robotic process automation to actual robotics.</p><p><strong>Machine Learning (ML):</strong> ML allows computers to learn from data. Instead of being explicitly programmed to perform a task, the machine uses data and algorithms to learn how to perform the task by itself.</p><p><strong>Deep Learning (DL):</strong> Deep Learning is a subfield of ML. It's primarily concerned with algorithms inspired by the structure and function of the brain called artificial neural networks. These algorithms are known for processing vast amounts of data, including unstructured data like images and text.</p><p><strong>Large Language Models (LLM):</strong> LLMs, like GPT-4, are a type of Deep Learning model designed to understand and generate human-like text based on the patterns they've learned from massive datasets. They are particularly known for their ability to generate coherent and contextually relevant sentences over long passages.</p><h3><strong>Real-world applications: How AI touches our everyday lives:</strong></h3><ol><li><p><strong>Personal Assistants:</strong> Virtual personal assistants, like Siri, Alexa, and Google Assistant, use AI to interpret and respond to user prompts.</p></li><li><p><strong>Recommendation Systems:</strong> From Netflix movie suggestions to Amazon product recommendations, these systems use ML algorithms to tailor content to individual user preferences.</p></li><li><p><strong>Autonomous Vehicles:</strong> Cars like those from Tesla use a combination of sensors and AI algorithms to drive themselves.</p></li><li><p><strong>Medical Diagnosis:</strong> Advanced AI tools can help in diagnosing diseases and conditions from medical imagery with impressive accuracy.</p></li><li><p><strong>Language Translation:</strong> Platforms like Google Translate employ Deep Learning models to provide real-time translation across dozens of languages.</p></li><li><p><strong>Financial Trading:</strong> AI-powered systems analyze market conditions in real-time to make trading decisions at speeds far surpassing human capabilities.</p></li><li><p><strong>Chatbots and Customer Service:</strong> Many websites now have chatbot assistants that can answer user queries in real-time, improving user experience and efficiency.</p></li><li><p><strong>Smart Home Devices:</strong> Devices like Nest or Ring use AI to learn user behaviors and preferences, adjusting settings automatically for user convenience.</p></li></ol><p>These applications highlight the extensive reach of AI technologies in various industries and our daily lives.</p><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F751132e6-7ab7-4720-9984-a1a5787a7df3_1024x1024.png" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F751132e6-7ab7-4720-9984-a1a5787a7df3_1024x1024.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F751132e6-7ab7-4720-9984-a1a5787a7df3_1024x1024.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F751132e6-7ab7-4720-9984-a1a5787a7df3_1024x1024.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F751132e6-7ab7-4720-9984-a1a5787a7df3_1024x1024.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F751132e6-7ab7-4720-9984-a1a5787a7df3_1024x1024.png" width="512" height="512" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/751132e6-7ab7-4720-9984-a1a5787a7df3_1024x1024.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1024,&quot;width&quot;:1024,&quot;resizeWidth&quot;:512,&quot;bytes&quot;:1177179,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F751132e6-7ab7-4720-9984-a1a5787a7df3_1024x1024.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F751132e6-7ab7-4720-9984-a1a5787a7df3_1024x1024.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F751132e6-7ab7-4720-9984-a1a5787a7df3_1024x1024.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F751132e6-7ab7-4720-9984-a1a5787a7df3_1024x1024.png 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a></figure></div><p></p><h3>4. The Backbone of AI: Mathematical Foundations</h3><p>At the foundation of Artificial Intelligence, there are mathematical principles. These pillars grant AI its strength and capabilities.</p><h4>4.1. Linear Algebra</h4><p><em><strong>Definition:</strong></em><br>Linear algebra is a branch of mathematics concerning linear equations, linear functions, and their representations in vector spaces and through matrices. Fundamentally, it deals with vectors, matrices, determinants, and systems of linear equations.</p><p><em><strong>Relevance to AI:</strong></em><br>In AI, and particularly in deep learning, linear algebra is crucial. Data, whether they are images, sound, or numerical values, are often represented as vectors or matrices. When processing this data, especially in neural networks, computations are performed using the principles of linear algebra. These computations include operations like matrix multiplication, finding eigenvectors/eigenvalues, and more. The efficiency and scalability of these operations are essential for training large neural networks on vast datasets.</p><p><em><strong>Use case example:</strong></em><br>Imagine training a neural network to recognize characters from popular culture. </p><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdff733c6-f476-4bcd-87b4-1b6240231e62_1200x1191.jpeg" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdff733c6-f476-4bcd-87b4-1b6240231e62_1200x1191.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdff733c6-f476-4bcd-87b4-1b6240231e62_1200x1191.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdff733c6-f476-4bcd-87b4-1b6240231e62_1200x1191.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdff733c6-f476-4bcd-87b4-1b6240231e62_1200x1191.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdff733c6-f476-4bcd-87b4-1b6240231e62_1200x1191.jpeg" width="438" height="434.715" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/dff733c6-f476-4bcd-87b4-1b6240231e62_1200x1191.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1191,&quot;width&quot;:1200,&quot;resizeWidth&quot;:438,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Obi-Wan show reveals return of Darth Vader in first-look photo&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" class="sizing-normal" alt="Obi-Wan show reveals return of Darth Vader in first-look photo" title="Obi-Wan show reveals return of Darth Vader in first-look photo" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdff733c6-f476-4bcd-87b4-1b6240231e62_1200x1191.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdff733c6-f476-4bcd-87b4-1b6240231e62_1200x1191.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdff733c6-f476-4bcd-87b4-1b6240231e62_1200x1191.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdff733c6-f476-4bcd-87b4-1b6240231e62_1200x1191.jpeg 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a></figure></div><div class="captioned-button-wrap" data-attrs="{&quot;url&quot;:&quot;https://www.tostring.ai/p/e1-from-code-to-cognition-my-ai-exploration?utm_source=substack&utm_medium=email&utm_content=share&action=share&token=eyJ1c2VyX2lkIjoyMTE1MDMzMywicG9zdF9pZCI6MTM3ODk4NDA2LCJpYXQiOjE3MzgxNjE5MjIsImV4cCI6MTc0MDc1MzkyMiwiaXNzIjoicHViLTgzMTY2NiIsInN1YiI6InBvc3QtcmVhY3Rpb24ifQ.5_ENMz-UQAavYQp16LY62hzOifiKev-yFVB1AOHzbbE&quot;,&quot;text&quot;:&quot;Share&quot;}" data-component-name="CaptionedButtonToDOM"><div class="preamble"><p class="cta-caption">Thank you for reading toString(). This post is public so feel free to share it.</p></div><p class="button-wrapper" data-attrs="{&quot;url&quot;:&quot;https://www.tostring.ai/p/e1-from-code-to-cognition-my-ai-exploration?utm_source=substack&utm_medium=email&utm_content=share&action=share&token=eyJ1c2VyX2lkIjoyMTE1MDMzMywicG9zdF9pZCI6MTM3ODk4NDA2LCJpYXQiOjE3MzgxNjE5MjIsImV4cCI6MTc0MDc1MzkyMiwiaXNzIjoicHViLTgzMTY2NiIsInN1YiI6InBvc3QtcmVhY3Rpb24ifQ.5_ENMz-UQAavYQp16LY62hzOifiKev-yFVB1AOHzbbE&quot;,&quot;text&quot;:&quot;Share&quot;}" data-component-name="ButtonCreateButton"><a class="button primary" href="https://www.tostring.ai/p/e1-from-code-to-cognition-my-ai-exploration?utm_source=substack&utm_medium=email&utm_content=share&action=share&token=eyJ1c2VyX2lkIjoyMTE1MDMzMywicG9zdF9pZCI6MTM3ODk4NDA2LCJpYXQiOjE3MzgxNjE5MjIsImV4cCI6MTc0MDc1MzkyMiwiaXNzIjoicHViLTgzMTY2NiIsInN1YiI6InBvc3QtcmVhY3Rpb24ifQ.5_ENMz-UQAavYQp16LY62hzOifiKev-yFVB1AOHzbbE"><span>Share</span></a></p></div><p>The image provided, for instance, represents Darth Vader from the Star Wars series. An image can be thought of as a matrix where each entry in the matrix represents the pixel intensity (and possibly color channels). When this image is fed into a neural network, the matrix undergoes various linear algebraic operations, like matrix multiplications, to transform the raw pixel values into a form that the network can use to recognize and classify the character. Through multiple layers and operations, the network might learn to pick up on unique features such as the distinct helmet shape, the pattern of the grille on the mouthpiece, or the silhouette of the cape, which all signal that this could be an image of Darth Vader.</p><p>Imagine the image of Darth Vader being represented as a matrix. </p><pre><code># Example Python Code for Matrix-Vector Multiplication related to the Darth Vader image # Let's assume a simplified 3x3 grayscale image of Darth Vader # (in reality, the image would have thousands or millions of pixels, # and possibly three channels for RGB) # Simplified pixel matrix of the image (just an illustrative example) darth_vader_image = [ [230, 235, 232], # top row of the image [50, 40, 48], # middle row representing the darker mask region [220, 225, 222] # bottom row of the image ] # A sample weight matrix from the first layer of a neural network weights = [ [0.1, 0.2, 0.1], [0.2, 0.5, 0.2], [0.1, 0.2, 0.1] ] # Multiplying the image matrix with the weight matrix to get the transformed matrix transformed_matrix = [[0, 0, 0], [0, 0, 0], [0, 0, 0]] for i in range(3): for j in range(3): transformed_matrix[i][j] = darth_vader_image[i][j] * weights[i][j] print(transformed_matrix) </code></pre><p>In the context of our Darth Vader image example:</p><ul><li><p>The <code>weights</code> matrix represents the first layer of a hypothetical neural network.</p></li><li><p>This matrix is used to transform the input image matrix (Darth Vader's image in this case) into another matrix that highlights or de-emphasizes certain features. This transformed matrix is then passed to subsequent layers of the network.</p></li></ul><p>In my illustrative example, I simply multiplied the image pixel values by these weights. In a real-world scenario, after this multiplication, a bias might be added, and then an activation function (like ReLU, sigmoid, etc.) would be applied to introduce non-linearity into the model.</p><p>Linear algebra, at its core, provides the mathematical foundation for representing and manipulating data in AI. In our example of identifying characters like Darth Vader, the image data is converted into matrices, and operations on these matrices, like matrix-vector multiplications, are performed. The weights, which are learned through training, determine the importance of specific features. By efficiently handling vast amounts of data and ensuring accurate computations using linear algebra principles, I can train models to recognize intricate patterns and make intelligent decisions. In the context of our character identification task, understanding linear algebra is paramount, ensuring that complex visual data can be distilled into meaningful insights, making it an indispensable tool in the realm of AI.</p><h4>4.2. Probability and Statistics</h4><p><em><strong>Definition</strong></em><strong>:</strong> Probability and Statistics are intertwined fields of mathematics. While probability provides a measure of the likelihood of a specific event occurring, statistics focuses on collecting, analyzing, interpreting, and presenting data in a meaningful manner.</p><p><em><strong>Relevance to AI:</strong></em> At its core, AI is essentially a statistical machine. Given vast amounts of data, AI models, especially those under machine learning, employ probability and statistics to recognize patterns, make predictions, and draw inferences. When an AI system provides a prediction, it often accompanies it with a confidence score, which is a direct application of probability. Furthermore, during the model training phase, statistical methods help determine the reliability and validity of the model's performance, ensuring that the model's decisions are not just mere coincidences but are statistically significant.</p><h4>4.3. Calculus</h4><p><em><strong>Definition:</strong></em> Calculus is a branch of mathematics that studies continuous change, primarily through derivatives and integrals. It's broken down into two main categories: Differential Calculus, which examines rates of change and the slopes of curves, and Integral Calculus, which looks at areas under curves.</p><p><em><strong>Relevance to AI:</strong></em> Calculus plays a foundational role in AI, especially in training algorithms like neural networks. For example, the backpropagation algorithm used in training neural networks involves calculating gradients (derivatives) of a loss function with respect to the model's parameters. These gradients guide how the parameters should be adjusted during the training process. The goal is to minimize the loss function, and this optimization is achieved using techniques from calculus.</p><p><em><strong>Use Case Example:</strong></em> Imagine training a simple neural network to recognize handwritten digits. During training, the network makes predictions, and the difference between its predictions and the actual labels is computed using a loss function. To minimize this loss, the network needs to adjust its weights and biases, which is done by understanding the gradient (or direction and magnitude of change) of the loss function with respect to these parameters.</p><pre><code>def compute_gradient(loss_function, weights): """ Calculate the gradient of the loss function with respect to the network's weights. This is a simplified example; in practice, tools like TensorFlow or PyTorch handle these computations. """ h = 1e-5 # a small value gradient = [] for i, weight in enumerate(weights): weights[i] = weight + h loss1 = loss_function(weights) weights[i] = weight - h loss2 = loss_function(weights) gradient.append((loss1 - loss2) / (2 * h)) weights[i] = weight # reset the weight return gradient </code></pre><h3>5. Introduction to <strong>Neural Network</strong></h3><p><strong>Neural Network </strong>- A neural network is a computational model inspired by the structure of biological neural systems. It comprises interconnected processing elements, called neurons, that process information using a connectionist approach to computation. The operations of a neural network are organized into layers. Each neuron in a layer receives input from the previous layer, processes it through a mathematical transformation involving weights, biases, and an activation function, and then sends the output to neurons in the next layer. Neural networks are trained using a set of input-output pairs, adjusting the weights via optimization techniques such as gradient descent to minimize the error between predicted and actual outputs.</p><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F69d7eb1c-0ca2-49a0-8f4e-5a104b08dcb1_1120x631.png" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F69d7eb1c-0ca2-49a0-8f4e-5a104b08dcb1_1120x631.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F69d7eb1c-0ca2-49a0-8f4e-5a104b08dcb1_1120x631.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F69d7eb1c-0ca2-49a0-8f4e-5a104b08dcb1_1120x631.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F69d7eb1c-0ca2-49a0-8f4e-5a104b08dcb1_1120x631.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F69d7eb1c-0ca2-49a0-8f4e-5a104b08dcb1_1120x631.png" width="1120" height="631" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/69d7eb1c-0ca2-49a0-8f4e-5a104b08dcb1_1120x631.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:631,&quot;width&quot;:1120,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Deep learning neural network&quot;,&quot;title&quot;:&quot;Deep learning neural network&quot;,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" class="sizing-normal" alt="Deep learning neural network" title="Deep learning neural network" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F69d7eb1c-0ca2-49a0-8f4e-5a104b08dcb1_1120x631.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F69d7eb1c-0ca2-49a0-8f4e-5a104b08dcb1_1120x631.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F69d7eb1c-0ca2-49a0-8f4e-5a104b08dcb1_1120x631.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F69d7eb1c-0ca2-49a0-8f4e-5a104b08dcb1_1120x631.png 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a><figcaption class="image-caption"><a href="https://www.ibm.com/topics/neural-networks">Source</a></figcaption></figure></div><p><strong>Example: Handwritten Digit Classification</strong></p><p>Imagine I'm trying to build a system that recognizes handwritten digits from 0 to 9. For this, I'll use the <a href="https://www.tensorflow.org/datasets/catalog/mnist">MNIST</a> dataset, which contains grayscale images of handwritten digits.</p><p>Given the deep neural network visual:</p><ul><li><p>The <strong>Input layer</strong> will have as many neurons as there are pixels in each image. MNIST images are 28x28 pixels, so I&#8217;d have 784 input neurons.</p></li><li><p>The <strong>Multiple Hidden layers</strong> can vary, but for simplicity, let's assume I have two hidden layers with 128 neurons each.</p></li><li><p>The <strong>Output layer</strong> will have 10 neurons, each representing a digit from 0 to 9. The neuron with the highest activation predicts the digit.</p></li></ul><h4>Code Sample:</h4><p>Let's build a neural network model using TensorFlow/Keras:</p><pre><code><code>import tensorflow as tf # Define the model model = tf.keras.models.Sequential() # Input Layer: Flatten the 28x28 images to a 784x1 vector model.add(tf.keras.layers.Flatten(input_shape=(28, 28))) # First Hidden Layer: 128 neurons with ReLU activation model.add(tf.keras.layers.Dense(128, activation='relu')) # Second Hidden Layer: 128 neurons with ReLU activation model.add(tf.keras.layers.Dense(128, activation='relu')) # Output Layer: 10 neurons (for digits 0-9) with softmax activation # to get probabilities for each class model.add(tf.keras.layers.Dense(10, activation='softmax')) # Compile the model model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])</code></code></pre><h3><strong>How the Neural Network Works with this Code:</strong></h3><ol><li><p><strong>Input Layer</strong>: The <code>Flatten</code> layer takes in the 28x28 pixel images and transforms them into a single row of 784 pixels.</p></li><li><p><strong>Hidden Layers</strong>: The <code>Dense</code> layers with 128 neurons each, and <code>relu</code> activation function introduce non-linearity to the model. This allows the neural network to learn complex patterns.</p></li><li><p><strong>Output Layer</strong>: The final <code>Dense</code> layer has 10 neurons, one for each digit. I use the <code>softmax</code> activation because it turns logits (raw output scores) into probabilities for each class.</p></li></ol><p>When trained on the MNIST dataset, this neural network will learn to recognize patterns of handwritten digits. The weights between the neurons adjust during training to minimize the difference between the predicted and actual digits.</p><h3><strong>Visualization and Understanding:</strong></h3><p>Using the provided image:</p><ul><li><p><strong>Input Layer (Blue circles on the left)</strong>: Represents the pixels of an image.</p></li><li><p><strong>Hidden Layers (Green circles in the middle)</strong>: These are the layers where the magic happens. Here, our network learns patterns, features, and characteristics about the images.</p></li><li><p><strong>Output Layer (Blue circles on the right)</strong>: The final decisions are made here. The neuron with the highest value gives the predicted digit.</p></li></ul><p>Each arrow connecting the circles represents a weight. During training, the network adjusts these weights based on the error of its predictions.</p><div class="subscription-widget-wrap-editor" data-attrs="{&quot;url&quot;:&quot;https://www.tostring.ai/subscribe?&quot;,&quot;text&quot;:&quot;Subscribe&quot;,&quot;language&quot;:&quot;en&quot;}" data-component-name="SubscribeWidgetToDOM"><div class="subscription-widget show-subscribe"><div class="preamble"><p class="cta-caption">toString() is a reader-supported publication. To receive new posts and support my work, consider becoming a free or paid subscriber.</p></div><form class="subscription-widget-subscribe"><input type="email" class="email-input" name="email" placeholder="Type your email&#8230;" tabindex="-1"><input type="submit" class="button primary" value="Subscribe"><div class="fake-input-wrapper"><div class="fake-input"></div><div class="fake-button"></div></div></form></div></div><h3><strong>6. Introduction to Large Language Models (LLM): A Deep Dive for Architects</strong></h3><p>As we transition into an era where text-driven interfaces take precedence, Large Language Models (LLMs) have become instrumental in creating a more contextual and interactive user experience. For software architects, understanding the underlying design and structure of LLMs is paramount. Here, I delve into the intricate architecture of these models and discuss their applicability in real-world systems.</p><h3><strong>LLM Architecture: A Closer Look</strong></h3><p>The image offers a schematic representation of the transformer architecture, the foundational design behind modern Large Language Models (LLMs) such as GPT-3. This architecture was introduced in the landmark paper <a href="https://arxiv.org/pdf/1706.03762.pdf">"Attention Is All You Need"</a> by Ashish Vaswani and his team at Google</p><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F63dfe2b8-b5d4-479b-b9f7-f5fe19656a7a_409x595.webp" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F63dfe2b8-b5d4-479b-b9f7-f5fe19656a7a_409x595.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F63dfe2b8-b5d4-479b-b9f7-f5fe19656a7a_409x595.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F63dfe2b8-b5d4-479b-b9f7-f5fe19656a7a_409x595.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F63dfe2b8-b5d4-479b-b9f7-f5fe19656a7a_409x595.webp 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F63dfe2b8-b5d4-479b-b9f7-f5fe19656a7a_409x595.webp" width="409" height="595" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/63dfe2b8-b5d4-479b-b9f7-f5fe19656a7a_409x595.webp&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:595,&quot;width&quot;:409,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F63dfe2b8-b5d4-479b-b9f7-f5fe19656a7a_409x595.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F63dfe2b8-b5d4-479b-b9f7-f5fe19656a7a_409x595.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F63dfe2b8-b5d4-479b-b9f7-f5fe19656a7a_409x595.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F63dfe2b8-b5d4-479b-b9f7-f5fe19656a7a_409x595.webp 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a></figure></div><h4>1. <strong>Inputs and Embeddings:</strong></h4><p>The bottom-most section of the diagram showcases how raw inputs are processed:</p><ul><li><p><strong>Input Embedding</strong>: Textual data, in tokenized format, is transformed into dense vectors using embeddings. This acts as the initial representation of the data which the transformer will process.</p></li><li><p><strong>Positional Encoding</strong>: Since transformers don't inherently process data in sequence, positional encodings are added to ensure that the model retains information about the position of each token in a sequence.</p></li></ul><h4>2. <strong>Multi-Head Attention Mechanism:</strong></h4><p>A distinguishing feature of the transformer:</p><ul><li><p><strong>Multi-Head Attention</strong>: Allows the model to focus on different parts of the input data simultaneously. It computes attention weights for different "heads", enabling the model to capture various aspects of the data.</p></li><li><p><strong>Masked Multi-Head Attention</strong>: Used primarily in the decoder section (as seen in the right-hand portion of the diagram). This ensures that while predicting a particular token, the model doesn't have access to future tokens.</p></li></ul><h4>3. <strong>Feed Forward Neural Networks:</strong></h4><p>Contained within each block of the architecture:</p><ul><li><p>Every layer in the transformer contains a feed-forward neural network, which operates independently on each position.</p></li></ul><h4>4. <strong>Add &amp; Norm:</strong></h4><p>A crucial component for the model's stability and performance:</p><ul><li><p>After each main operation (attention or feed-forward), the output goes through an "Add &amp; Norm" step which includes residual connections and layer normalization. This aids in preventing the vanishing gradient problem and ensures smoother training.</p></li></ul><h4>5. <strong>Linear Layers and Softmax:</strong></h4><p>The final steps before producing an output:</p><ul><li><p><strong>Linear Layer</strong>: It transforms the output from the decoder's final layer.</p></li><li><p><strong>Softmax</strong>: Converts the raw output scores (logits) from the linear layer into probabilities. This is especially crucial when the model is used for tasks like classification.</p></li></ul><h4>6. <strong>Stacking:</strong></h4><p>As indicated by "N x" in the diagram, the transformer stacks these blocks multiple times, which allows it to learn more complex relationships and dependencies in the data.</p><h4>Use case example</h4><p>The Transformer architecture introduced in the paper revolutionized natural language processing tasks by utilizing self-attention mechanisms. The Language Model (LLM) based on this architecture can be thought of as a neural network model designed to understand and generate human language. It's particularly suited for tasks like machine translation, text summarization, and language generation.</p><p><em><strong>1. Tokenization and Input Embeddings:</strong></em></p><ul><li><p>The input sentence is first tokenized into subword or word-level tokens. Each token is represented as a vector using pre-trained embeddings (e.g., Word2Vec, GloVe).</p></li><li><p>These embeddings are then transformed into input embeddings for the model. In the original Transformer, these embeddings have a fixed dimension.</p></li></ul><p><em><strong>2. Positional Encoding:</strong></em></p><ul><li><p>Since the Transformer doesn't inherently understand the order of words in a sequence, positional encoding is added to the input embeddings.</p></li><li><p>Positional encoding vectors are calculated based on the position of each token in the input sequence and added element-wise to the embeddings.</p></li><li><p>This gives the model information about the relative positions of tokens in the sequence.</p></li></ul><p><em><strong>3. Encoder:</strong></em></p><p>a. <strong>Self-Attention Mechanism:</strong> - The input embeddings with positional encodings are passed through multiple self-attention layers in parallel. - In each self-attention layer, queries, keys, and values are computed from the input embeddings. - Attention scores are calculated by taking the dot product of queries and keys, followed by scaling and applying a softmax function. - These attention scores determine how much each token should attend to other tokens in the same input sequence. - The weighted sum of values based on attention scores produces the attended representation for each token. - This mechanism allows the model to capture dependencies and relationships between words, emphasizing important connections.</p><p>b. <strong>Multi-Head Attention:</strong> - Multiple self-attention heads operate in parallel in each layer. - Each head has its own set of learned parameters, allowing it to focus on different aspects of the input. - The outputs of all heads are concatenated and linearly transformed to create the final attention output for that layer.</p><p>c. <strong>Residual Connection and Layer Normalization:</strong> - After each self-attention sub-layer, there is a residual connection that bypasses the sub-layer and a layer normalization step. - This helps in preventing the vanishing gradient problem during training and ensures smooth information flow through the network.</p><p>d. <strong>Feed-Forward Neural Network (FFN):</strong> - After self-attention, the output is passed through a feed-forward neural network. - The FFN consists of two linear transformations followed by an activation function (commonly ReLU) and another linear transformation. - This network captures complex, non-linear relationships between tokens.</p><p>e. <strong>Residual Connection and Layer Normalization (Again):</strong> - Similar to self-attention sub-layers, after the FFN, there is another residual connection and layer normalization.</p><p><strong>4. Decoder:</strong></p><ul><li><p>The decoder architecture closely resembles the encoder but with some differences. It also includes the following components:</p></li></ul><p>a. <strong>Masked Self-Attention Mechanism:</strong> - In the decoder, self-attention is applied with a masking mechanism that prevents the model from attending to future positions in the output sequence.</p><p>b. <strong>Encoder-Decoder Attention:</strong> - In addition to the masked self-attention, the decoder also attends to the output of the encoder's final layer. - This allows the decoder to consider the entire input sequence while generating the output.</p><p>c. <strong>Residual Connections and Layer Normalization:</strong> - Similar to the encoder, residual connections and layer normalization are applied after each sub-layer in the decoder.</p><p><strong>5. Output Generation:</strong></p><ul><li><p>The final output from the decoder is passed through a linear layer followed by a softmax activation function.</p></li><li><p>This produces a probability distribution over the vocabulary for each position in the output sequence.</p></li><li><p>During training, the model is optimized to generate the correct target sequence by minimizing a suitable loss function like cross-entropy.</p></li></ul><p><strong>Information Flow:</strong></p><ul><li><p>Information flows through the Transformer architecture in a hierarchical manner, with each layer capturing different levels of abstraction and dependencies between tokens.</p></li><li><p>Self-attention mechanisms determine how much each token attends to other tokens in the input sequence, allowing the model to weigh their importance.</p></li><li><p>The residual connections and layer normalization ensure that information can flow smoothly through the network without vanishing gradients.</p></li><li><p>During decoding, the model attends to both the encoder's output and its own previously generated output to produce contextually relevant translations.</p><p></p></li></ul><div class="subscription-widget-wrap-editor" data-attrs="{&quot;url&quot;:&quot;https://www.tostring.ai/subscribe?&quot;,&quot;text&quot;:&quot;Subscribe&quot;,&quot;language&quot;:&quot;en&quot;}" data-component-name="SubscribeWidgetToDOM"><div class="subscription-widget show-subscribe"><div class="preamble"><p class="cta-caption">toString() is a reader-supported publication. To receive new posts and support my work, consider becoming a free or paid subscriber.</p></div><form class="subscription-widget-subscribe"><input type="email" class="email-input" name="email" placeholder="Type your email&#8230;" tabindex="-1"><input type="submit" class="button primary" value="Subscribe"><div class="fake-input-wrapper"><div class="fake-input"></div><div class="fake-button"></div></div></form></div></div><h3>6. Conclusion</h3><p>In the first post of "AI Odyssey" series, I went into the foundational aspects of Artificial Intelligence (AI) and Large Language Models (LLMs). I explored the basics of AI, the building blocks of neural networks, and took a look at the architecture that underpins modern LLMs, inspired by the groundbreaking paper "Attention Is All You Need."</p><p>As I go further into the world of AI, my next chapter will navigate the terrain of Deep Learning and Machine Learning Concepts. I&#8217;ll dissect various algorithms, dissect their strengths and weaknesses, and shed light on their practical applications.</p><p>It's important to note that this effort is a dynamic journey, fueled by my ongoing exploration and learning of AI. The purpose of this blog post series is twofold: to solidify my understanding of these complex subjects and, just as importantly, to share this knowledge with you.</p><p class="button-wrapper" data-attrs="{&quot;url&quot;:&quot;https://www.tostring.ai/p/e1-from-code-to-cognition-my-ai-exploration/comments&quot;,&quot;text&quot;:&quot;Leave a comment&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a class="button primary" href="https://www.tostring.ai/p/e1-from-code-to-cognition-my-ai-exploration/comments"><span>Leave a comment</span></a></p> ]]>
</content:encoded>
</item>
<item>
<title>
<![CDATA[ Digital Descent: The Code Behind Apollo 11's Lunar Landing ]]>
</title>
<description>
<![CDATA[ Analyzing the P63 Lunar Landing Braking Phase and Celebrating Margaret Hamilton's Contributions ]]>
</description>
<link>https://www.tostring.ai/p/digital-descent-the-code-behind-apollo</link>
<guid isPermaLink="true">https://www.tostring.ai/p/digital-descent-the-code-behind-apollo</guid>
<dc:creator>
<![CDATA[ Marco Altea ]]>
</dc:creator>
<pubDate>Mon, 02 Oct 2023 19:55:42 GMT</pubDate>
<enclosure url="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff9cd7679-6ab9-4f9c-9ae3-88b500821b55_2349x2362.jpeg" length="0" type="image/jpeg"/>
<content:encoded>
<![CDATA[ <h3><strong>Chapter 1: Introduction to the Apollo Guidance Computer (AGC)</strong></h3><p>Ever since I was a young kid, the moon had always seemed like a dream. The story of Apollo 11's journey to that distant world was the stuff of legends, a story that fascinated me. And at the heart of this epic voyage was a humble, yet extraordinarily capable companion - the Apollo Guidance Computer (AGC).</p><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F427a78b8-5aed-47e4-aef1-3ade5e123f26_2048x1536.jpeg" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F427a78b8-5aed-47e4-aef1-3ade5e123f26_2048x1536.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F427a78b8-5aed-47e4-aef1-3ade5e123f26_2048x1536.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F427a78b8-5aed-47e4-aef1-3ade5e123f26_2048x1536.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F427a78b8-5aed-47e4-aef1-3ade5e123f26_2048x1536.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F427a78b8-5aed-47e4-aef1-3ade5e123f26_2048x1536.jpeg" width="1456" height="1092" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/427a78b8-5aed-47e4-aef1-3ade5e123f26_2048x1536.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1092,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F427a78b8-5aed-47e4-aef1-3ade5e123f26_2048x1536.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F427a78b8-5aed-47e4-aef1-3ade5e123f26_2048x1536.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F427a78b8-5aed-47e4-aef1-3ade5e123f26_2048x1536.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F427a78b8-5aed-47e4-aef1-3ade5e123f26_2048x1536.jpeg 1456w" sizes="100vw" fetchpriority="high"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a></figure></div><p>The AGC was nothing short of a technological marvel birthed by the brilliant minds at the MIT Instrumentation Laboratory. It was compact, designed to withstand the brutal conditions of space, and packed to guide the spacecraft through the cosmos. With just 2.048 MHz of processing power and a 2048-word RAM, the AGC was not the powerhouse we'd imagine it to be, but it was sturdy and dependable, a true companion to the astronauts aboard Apollo 11.</p><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F56731d57-21ad-41ab-a315-64c3ab282b0d_1024x961.jpeg" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F56731d57-21ad-41ab-a315-64c3ab282b0d_1024x961.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F56731d57-21ad-41ab-a315-64c3ab282b0d_1024x961.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F56731d57-21ad-41ab-a315-64c3ab282b0d_1024x961.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F56731d57-21ad-41ab-a315-64c3ab282b0d_1024x961.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F56731d57-21ad-41ab-a315-64c3ab282b0d_1024x961.jpeg" width="1024" height="961" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/56731d57-21ad-41ab-a315-64c3ab282b0d_1024x961.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:961,&quot;width&quot;:1024,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;undefined&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" class="sizing-normal" alt="undefined" title="undefined" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F56731d57-21ad-41ab-a315-64c3ab282b0d_1024x961.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F56731d57-21ad-41ab-a315-64c3ab282b0d_1024x961.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F56731d57-21ad-41ab-a315-64c3ab282b0d_1024x961.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F56731d57-21ad-41ab-a315-64c3ab282b0d_1024x961.jpeg 1456w" sizes="100vw"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a><figcaption class="image-caption"><em>The display and keyboard (DSKY) interface of the Apollo Guidance Computer mounted on the control panel of the command module, with the flight director attitude indicator (FDAI) above</em></figcaption></figure></div><p>Creating a computer that could navigate to the Moon and back was not easy task. The software had to be bug-free, with no room for error, as even a minor glitch could spell doom. And the hardware? It had to endure the relentless battering of space conditions, from intense radiation to the whims of microgravity.</p><p>The AGC's software was coded in a unique AGC assembly language, hard-wired into core rope memory, a form of read-only memory hand-woven with an artisan's precision. </p><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F227c0222-a42b-42e5-a55a-c626adbe0932_1920x2019.jpeg" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F227c0222-a42b-42e5-a55a-c626adbe0932_1920x2019.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F227c0222-a42b-42e5-a55a-c626adbe0932_1920x2019.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F227c0222-a42b-42e5-a55a-c626adbe0932_1920x2019.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F227c0222-a42b-42e5-a55a-c626adbe0932_1920x2019.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F227c0222-a42b-42e5-a55a-c626adbe0932_1920x2019.jpeg" width="1456" height="1531" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/227c0222-a42b-42e5-a55a-c626adbe0932_1920x2019.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1531,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;undefined&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" class="sizing-normal" alt="undefined" title="undefined" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F227c0222-a42b-42e5-a55a-c626adbe0932_1920x2019.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F227c0222-a42b-42e5-a55a-c626adbe0932_1920x2019.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F227c0222-a42b-42e5-a55a-c626adbe0932_1920x2019.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F227c0222-a42b-42e5-a55a-c626adbe0932_1920x2019.jpeg 1456w" sizes="100vw"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a><figcaption class="image-caption">Core rope memory test sample from the <a href="https://en.wikipedia.org/wiki/Apollo_program">Apollo program</a></figcaption></figure></div><h6></h6><p></p><p>As I dive into the saga of Apollo 11, I'll explore the P63 Lunar Landing Braking Phase, a core segment of code that orchestrated the Lunar Module's descent onto the moon's barren plains. The P63 code it's a good example of great software engineering and a foresight that was way ahead of its time, ensuring the mission's success against all odds.</p><p>In the chapters that follow, I'll try to explain the P63 Lunar Landing Braking Phase code, and paying homage to the incredible minds behind it, including my hero: Margaret Hamilton, a luminary whose contributions echo through the annals of software engineering (fun fact, she invented the name &#8220;software engineer&#8221;)</p><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbefc3660-0b9e-4f9a-9f13-57547f04613f_1000x555.jpeg" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbefc3660-0b9e-4f9a-9f13-57547f04613f_1000x555.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbefc3660-0b9e-4f9a-9f13-57547f04613f_1000x555.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbefc3660-0b9e-4f9a-9f13-57547f04613f_1000x555.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbefc3660-0b9e-4f9a-9f13-57547f04613f_1000x555.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbefc3660-0b9e-4f9a-9f13-57547f04613f_1000x555.jpeg" width="1000" height="555" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/befc3660-0b9e-4f9a-9f13-57547f04613f_1000x555.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:555,&quot;width&quot;:1000,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Mockup of the new LEGO minifig of computer scientist Margaret Hamilton (Maia Weinstock/Flickr) and the real-life Hamilton standing next to the navigation software she and her team at MIT produced for NASA's Apollo project in 1969 (Draper Laboratory/Wikipedia)&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" class="sizing-normal" alt="Mockup of the new LEGO minifig of computer scientist Margaret Hamilton (Maia Weinstock/Flickr) and the real-life Hamilton standing next to the navigation software she and her team at MIT produced for NASA's Apollo project in 1969 (Draper Laboratory/Wikipedia)" title="Mockup of the new LEGO minifig of computer scientist Margaret Hamilton (Maia Weinstock/Flickr) and the real-life Hamilton standing next to the navigation software she and her team at MIT produced for NASA's Apollo project in 1969 (Draper Laboratory/Wikipedia)" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbefc3660-0b9e-4f9a-9f13-57547f04613f_1000x555.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbefc3660-0b9e-4f9a-9f13-57547f04613f_1000x555.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbefc3660-0b9e-4f9a-9f13-57547f04613f_1000x555.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbefc3660-0b9e-4f9a-9f13-57547f04613f_1000x555.jpeg 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a></figure></div><div><hr></div><h3><strong>Chapter 2: Analysis of the Code for the P63 Lunar Landing Braking Phase</strong></h3><p></p><p>The Apollo Guidance Computer (AGC) is the Assembly language used for scripting the Apollo 11 mission, I've invested a bit of time to get an high level comprehension of it with the help of <a href="https://www.ibiblio.org/apollo/developer.html#gsc.tab=0">AGC Developer Info</a> and GPT4 LLM. Unlike the high-level languages we often encounter today, AGC Assembly is a low-level language tailored for the specific hardware it controls.</p><p>In AGC Assembly, each instruction directly manipulate the hardware to perform desired actions. Here's how an "Hello, <s>World</s> Moon!" script might look, although AGC Assembly was never meant for such mundane tasks (indeed we are printing a number)</p><pre><code> # Description: Displays the number 08101986 (my Birthday) on the DSKY. # Start of the program COUNT* DisplayNumber.agc # CONSTANTS AND VARIABLES NumberSignal OCT 03411 # Octal representation of 08101986 DSKYChannel EQUALS 10 # DSKY Channel # ACTUAL ROUTINE CA NumberSignal # Load the number signal into the accumulator EXTEND # Extend the instruction WRITE DSKYChannel # Send accumulator data to the DSKY TC ENDPGM # End the program # End of program END </code></pre><p>Now, diving into the treasure trove that is the <strong><a href="https://github.com/chrislgarry/Apollo-11">Apollo 11 GitHub repository</a></strong>, there lies a file named <code>THE_LUNAR_LANDING.agc</code> in the <code>Luminary099</code> directory. This file is the gatekeeper to understanding the moon's descent, storing the code for the P63 Lunar Landing Braking Phase among other critical mission phases.</p><p></p><p>As our astronauts approached the moon, ready to initiate the landing sequence, a simple command triggered the P63 Lunar Landing Braking Phase, setting in motion a meticulously crafted routine designed to guide the Lunar Module to a safe landing.</p><p></p><h3><strong>Chapter 3: Description of Astronaut and AGC interactions during the descent</strong></h3><p>To help me with this chapter, I reviewed <a href="https://history.nasa.gov/alsj/a11/a11transcript_tec.html">Apollo 11 Mission transcript</a> and this <a href="https://www.youtube.com/watch?v=RONIax0_1ec&amp;ab_channel=Apollo11-ApolloFlightJournal">NASA Video</a> and try to combine those moments with the <a href="https://github.com/chrislgarry/Apollo-11/blob/master/Luminary099/THE_LUNAR_LANDING.agc">code</a> of the Lunar landing </p><p>As the Lunar Module (LM) "Eagle" orbited the Moon with astronauts Neil Armstrong and Buzz Aldrin on board. Houston and the astronauts were engaged in a meticulous review of the descent plan, ensuring every system was primed for the task ahead.</p><blockquote><p>Houston: &#8220;Eagle, Houston. We read you now. You're GO for PDI. Over.&#8221;</p><p>Armstrong: "Roger, understand."</p></blockquote><p>The confirmation of "GO for PDI" from Houston was more than a technical go-ahead; it was a collective affirmation of readiness to transition from orbital flight to the descent towards the lunar surface.</p><blockquote><p>Columbia: &#8220;Coming up on 1 minute to TIG, Neil. How's it looking?&#8221;</p><p>Armstrong: &#8220;Pretty good.&#8221;</p></blockquote><p>The stage was set. The astronauts reviewed their checklists one last time, rechecked the systems, and with a shared breath of anticipation, prepared to input the commands that would initiate the descent procedure. The discourse with Houston provided a structured cadence, within which the rhythmic dance of man, machine, and mission was about to unfold against the vast, silent backdrop of space.</p><h4>3.1 Setting the Stage: The Descent Commences</h4><p>The descent to the lunar surface was a mission-critical phase. Our astronauts, Armstrong and Aldrin, found themselves steering towards the unknown, with only their training, Houston's guidance, and the Apollo Guidance Computer (AGC) as their allies.</p><p>The air crackled with tension as the communication between Apollo 11 and Houston set the pace for this phase. With a go from Houston, Armstrong and Aldrin initiated the descent sequence via the DSKY (Display and Keyboard Unit), the interface to the AGC.</p><blockquote><p>Houston: "You are Go for powered descent."</p><p>Armstrong: "Roger, understand, Go for powered descent."</p></blockquote><p>As Armstrong keyed in Verb 37 Noun 63 on the DSKY</p><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F827c8892-1d3a-45ee-b6bd-314ead2017be_300x289.jpeg" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F827c8892-1d3a-45ee-b6bd-314ead2017be_300x289.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F827c8892-1d3a-45ee-b6bd-314ead2017be_300x289.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F827c8892-1d3a-45ee-b6bd-314ead2017be_300x289.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F827c8892-1d3a-45ee-b6bd-314ead2017be_300x289.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F827c8892-1d3a-45ee-b6bd-314ead2017be_300x289.jpeg" width="300" height="289" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/827c8892-1d3a-45ee-b6bd-314ead2017be_300x289.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:289,&quot;width&quot;:300,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F827c8892-1d3a-45ee-b6bd-314ead2017be_300x289.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F827c8892-1d3a-45ee-b6bd-314ead2017be_300x289.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F827c8892-1d3a-45ee-b6bd-314ead2017be_300x289.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F827c8892-1d3a-45ee-b6bd-314ead2017be_300x289.jpeg 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a></figure></div><p></p><p>the AGC was instructed to transition to a new phase of the mission&#8212;the descent phase.</p><pre><code>COUNT* PHASCHNG PHASCHNG TC PHASCHNG OCT 04024 </code></pre><p>In this code, <code>PHASCHNG</code> (short for "Phase Change.") is a routine that tells the AGC, "Hey, it's time to switch gears and get ready for the descent phase."</p><ol><li><p><code>COUNT* PHASCHNG</code>: This line is specifying a memory location labeled <code>PHASCHNG</code>. <code>COUNT</code> is a directive used in AGC assembly language to set the location counter to a specific address, in this case, the address labeled <code>PHASCHNG</code>. This is essentially marking the start of a new section of code.</p></li><li><p><code>PHASCHNG TC PHASCHNG</code>: In this line, <code>PHASCHNG</code> is the label for this instruction. <code>TC</code> stands for "Transfer Control", which is an instruction that tells the AGC to jump to another part of the program specified by the address following <code>TC</code>. In this case, it's telling the AGC to jump to the instruction at the <code>PHASCHNG</code> address, essentially creating a loop. </p></li><li><p><code>OCT 04024</code>: This line is specifying an octal (base 8) value <code>04024</code>. In the AGC, octal was often used for representing data. The meaning of this value would depend on the context in which it's used within the AGC program.</p></li></ol><p>When the astronauts inputted <strong>Verb 37 Noun 63</strong> into the DSKY, the AGC would interpret it, and the corresponding pre-programmed routine in the AGC's software would be executed to carry out the required action for that phase change. </p><p>From the <a href="https://nassp.space/index.php/Virtual_AGC">Virtual AGC</a> documentation for flying with the Virtual AGC.</p><p><strong>Verb 37 : </strong>From the documentation, Verb 37 is denoted as "Change program," which instructs the AGC to switch to a different program or routine.</p><p><strong>Noun 63</strong> : Delta-altitude, altitude rate and altitude. This phase is crucial for reducing the spacecraft's velocity as it approaches the lunar surface.</p><p>Combining these, the command Verb 37 Noun 63 could imply a change in the program to initiate or engage with the "Braking Phase" of the lunar descent.</p><p></p><h4>3.2 The Eagle Approaches: Code in Action</h4><p>When Aldrin inputted <strong>Verb 16 Noun 68 </strong>on the DSKY, he was essentially asking the AGC to display the rate at which they were descending towards the moon.</p><ul><li><p><strong>Verb 16</strong>: In the context of the DSKY, a Verb represents an action or command. Verb 16 is typically associated with monitoring or displaying a particular value or set of values.</p></li><li><p><strong>Noun 68</strong>: A Noun specifies the data or object upon which the Verb is to act. Noun 68 represent downrange distance, time-to-go in braking phase (minutes and seconds), velocity. within the AGC software.</p></li></ul><pre><code>COUNT* BURNBABY BURNBABY CAF PHASCHNG TS PHASCHNG</code></pre><p>The routine "<strong>BURNBABY</strong>" in the Apollo 11 Guidance Computer code is associated with firing the Lunar Module's engine</p><ol><li><p><code>COUNT* BURNBABY</code><strong>:</strong></p><ul><li><p>The <code>COUNT*</code> statement is a directive to the assembler. It&#8217;s used here to specify a location counter, essentially telling the assembler where to place the following code in memory.</p></li><li><p><code>BURNBABY</code> is a label that identifies the location of this block of code. It&#8217;s akin to a name tag on a suitcase, allowing other parts of the program to find and reference this particular block.</p></li></ul></li><li><p><code>BURNBABY CAF PHASCHNG</code>:</p><ul><li><p>Here&#8217;s where the action begins. <code>CAF</code> stands for "Clear and Add", a command that clears the accumulator (a special register used for arithmetic operations) and then adds the value of <code>PHASCHNG</code> to it.</p></li><li><p><code>PHASCHNG</code> is a constant or a memory location (its name suggesting a phase change). It holds a value that, when added to the accumulator, sets up the desired conditions for the engine burn.</p></li></ul></li><li><p><code>TS PHASCHNG</code>:</p><ul><li><p><code>TS</code> stands for "Transfer to Storage", an instruction that takes the current value in the accumulator and stores it in the specified location, in this case, back into <code>PHASCHNG</code>.</p></li><li><p>This line essentially updates the value of <code>PHASCHNG</code> with the new value from the accumulator, reflecting the conditions for the engine burn.</p></li></ul></li></ol><p>This snippet illustrates a straightforward, yet consequential, operation: preparing the system for an engine burn by updating a particular value (<code>PHASCHNG</code>) in memory.</p><p>Now, when Buzz Aldrin inputted Verb 16 Noun 68 on the DSKY, he was essentially instructing the AGC to display the descent rate, as Verb 16 is associated with monitoring or displaying values, and Noun 68 relates to critical descent parameters. This interaction between astronaut and machine, facilitated by a well-defined and executed code, ensured the crew stayed informed and in control during this crucial phase of the mission.</p><div class="pullquote"><p>Fun Fact: The name of the Apollo 11 Guidance Computer routine "BURNBABY" has an intriguing backstory. It traces its roots to the 1965 Los Angeles riots, inspired by the iconic phrase "Burn, baby! BURN!" used by charismatic disc jockey Magnificent Montague while spinning the hottest records of the time. This tidbit was shared by one of the routine's authors, Don Eyles, during a gathering of AGC developers celebrating the 40th anniversary of the first moonwalk&#8203;</p></div><blockquote><p>Houston: "Descent engine command override, off."</p><p>Armstrong: "Engine arm is off."</p><p>Houston: "Roger. Copy."</p></blockquote><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbe751c5b-f9a4-4df3-90f6-b181467b26e4_1200x650.jpeg" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbe751c5b-f9a4-4df3-90f6-b181467b26e4_1200x650.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbe751c5b-f9a4-4df3-90f6-b181467b26e4_1200x650.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbe751c5b-f9a4-4df3-90f6-b181467b26e4_1200x650.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbe751c5b-f9a4-4df3-90f6-b181467b26e4_1200x650.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbe751c5b-f9a4-4df3-90f6-b181467b26e4_1200x650.jpeg" width="1200" height="650" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/be751c5b-f9a4-4df3-90f6-b181467b26e4_1200x650.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:650,&quot;width&quot;:1200,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;View of Moon with Earth rising on the horizon&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" class="sizing-normal" alt="View of Moon with Earth rising on the horizon" title="View of Moon with Earth rising on the horizon" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbe751c5b-f9a4-4df3-90f6-b181467b26e4_1200x650.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbe751c5b-f9a4-4df3-90f6-b181467b26e4_1200x650.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbe751c5b-f9a4-4df3-90f6-b181467b26e4_1200x650.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbe751c5b-f9a4-4df3-90f6-b181467b26e4_1200x650.jpeg 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a></figure></div><h3><strong>3.3 The Final Moments: Touchdown</strong></h3><p>As the lunar surface neared</p><pre><code>COUNT* BURNBABY TOUCHDWN CAF FOUR # signify touchdown</code></pre><ol><li><p><code>COUNT* BURNBABY</code> acts as a memory location directive.</p></li><li><p><code>TOUCHDWN</code> is a label, identifying this block of code.</p></li><li><p><code>CAF FOUR</code> clears the accumulator and adds the value of <code>FOUR</code> to it, which likely represents a constant with a value of 4.</p></li><li><p>This operation updates the accumulator to signify a touchdown event, akin to how <code>BURNBABY</code> routine was used earlier in the descent phase to prepare for engine burn, illustrating how different routines were triggered to manage various phases of the lunar landing.</p></li></ol><p>this transition wasn't initiated by Armstrong or Aldrin directly. Instead, it was triggered automatically by the AGC based on the lunar module's sensors detecting contact with the lunar surface. The AGC was programmed to transition through various phases of the landing autonomously, reacting to sensor data and executing the appropriate routines to manage the descent and touchdown on the moon's surface.</p><p></p><blockquote><p>04 06 45 52 LMP (EAGLE)<br>413 is in.<br><br>04 06 45 57 CC<br>We copy you down, Eagle.<br><br>04 06 45 59 CDR (TRANQ)<br>Houston, Tranquility Base here.<br><br>04 06 46 04 CDR (TRANQ)<br><strong>THE EAGLE HAS LANDED.</strong><br><br>04 06 46 06 CC<br>Roger, Tranquility. We copy you on the ground. You got a bunch of guys about to turn blue. We're breathing again. Thanks a lot.<br><br>04 06 46 16 CDR (TRANQ)<br>Thank you.<br><br>04 06 46 18 CC<br>You're looking good here.<br><br>04 06 46 23 CDR (TRANQ)<br>Okay. We're going to be busy for a minute.<br><br>04 06 46 25 LMP (TRANQ)<br>MASTER ARM, ON. Take care of the ... I'll get this ...<br><br>04 06 46 38 LMP (TRANQ)<br>Very smooth touchdown.</p><p></p></blockquote><p>This transcript captures the real-time communication between the astronauts and Mission Control during the historic lunar landing.</p><p></p><p> </p><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff9cd7679-6ab9-4f9c-9ae3-88b500821b55_2349x2362.jpeg" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff9cd7679-6ab9-4f9c-9ae3-88b500821b55_2349x2362.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff9cd7679-6ab9-4f9c-9ae3-88b500821b55_2349x2362.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff9cd7679-6ab9-4f9c-9ae3-88b500821b55_2349x2362.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff9cd7679-6ab9-4f9c-9ae3-88b500821b55_2349x2362.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff9cd7679-6ab9-4f9c-9ae3-88b500821b55_2349x2362.jpeg" width="1456" height="1464" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/f9cd7679-6ab9-4f9c-9ae3-88b500821b55_2349x2362.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1464,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;NASA - NSSDCA - Spacecraft - Details&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" class="sizing-normal" alt="NASA - NSSDCA - Spacecraft - Details" title="NASA - NSSDCA - Spacecraft - Details" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff9cd7679-6ab9-4f9c-9ae3-88b500821b55_2349x2362.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff9cd7679-6ab9-4f9c-9ae3-88b500821b55_2349x2362.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff9cd7679-6ab9-4f9c-9ae3-88b500821b55_2349x2362.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff9cd7679-6ab9-4f9c-9ae3-88b500821b55_2349x2362.jpeg 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a><figcaption class="image-caption">The Apollo 11 Lunar Module (LM) "Eagle" - Source <a href="https://nssdc.gsfc.nasa.gov/nmc/spacecraft/display.action?id=1969-059C">NASA</a></figcaption></figure></div><div class="subscription-widget-wrap-editor" data-attrs="{&quot;url&quot;:&quot;https://www.tostring.ai/subscribe?&quot;,&quot;text&quot;:&quot;Subscribe&quot;,&quot;language&quot;:&quot;en&quot;}" data-component-name="SubscribeWidgetToDOM"><div class="subscription-widget show-subscribe"><div class="preamble"><p class="cta-caption">toString() is a reader-supported publication. To receive new posts and support my work, consider becoming a free or paid subscriber.</p></div><form class="subscription-widget-subscribe"><input type="email" class="email-input" name="email" placeholder="Type your email&#8230;" tabindex="-1"><input type="submit" class="button primary" value="Subscribe"><div class="fake-input-wrapper"><div class="fake-input"></div><div class="fake-button"></div></div></form></div></div><h3>Chapter 4: The Legacy: AGC's Impact on Modern Computing</h3><p>The Apollo Guidance Computer (AGC) marked a significant milestone in the evolution of computing. This piece of engineering, developed in the 1960s, showcased the potential of digital computers in executing critical real-time, reliable calculations that were crucial for space exploration. The design principles, the rigorous testing and verification processes, and the innovative software-hardware integration of the AGC laid a strong foundation for the subsequent advancements in computing technology.</p><p>The AGC's triumph in guiding Apollo 11 to the moon and back underscored the critical role of software in complex systems. </p><p>Moreover, the AGC was a testament to the power of human-machine collaboration. It demonstrated how well-designed systems could augment human capabilities, enabling astronauts to perform precise navigational calculations and make informed decisions during the mission. </p><p>Furthermore, the modularity and reliability of the AGC's hardware and software architectures inspired a generation of computer scientists and engineers. The principles of fault tolerance, error detection and correction, and systematic testing that were inherent to the AGC's design are now staples in the field of computer science.</p><p>The AGC's legacy extends beyond its technical accomplishments. It symbolizes a monumental human achievement and stands as a testament to the spirit of innovation, collaboration, and exploration</p><h3>Chapter 5: Margaret Hamilton: The Woman Who Took Us to the Moon</h3><p>Margaret Hamilton's journey began long before Apollo 11. Born in 1936, she dove into the world of software at a time when the term "software engineering" didn't even exist. </p><div class="pullquote"><p>Margaret Hamilton coined the term "software engineering" during her work on the Apollo missions. She felt that software development was as complex and critical as hardware engineering, and thus deserved the same level of professional recognition. By introducing this term, Hamilton helped elevate the field, emphasizing the importance of a systematic, engineering-based approach to software development, which was crucial in gaining respect and resources for software activities, eventually shaping the profession into what it is today.</p></div><p>Her work at MIT Instrumentation Laboratory was groundbreaking. She led the team that developed the on-board flight software for Apollo missions. Among her remarkable contributions was the software capable of detecting system errors and recovering from a computer crash. </p><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0a2f9f25-f948-4d6c-b7de-6415e8dab76b_1200x800.jpeg" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0a2f9f25-f948-4d6c-b7de-6415e8dab76b_1200x800.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0a2f9f25-f948-4d6c-b7de-6415e8dab76b_1200x800.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0a2f9f25-f948-4d6c-b7de-6415e8dab76b_1200x800.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0a2f9f25-f948-4d6c-b7de-6415e8dab76b_1200x800.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0a2f9f25-f948-4d6c-b7de-6415e8dab76b_1200x800.jpeg" width="1200" height="800" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/0a2f9f25-f948-4d6c-b7de-6415e8dab76b_1200x800.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:800,&quot;width&quot;:1200,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Margaret Hamilton: the Apollo software engineer who saved the moon landing - Vox&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" class="sizing-normal" alt="Margaret Hamilton: the Apollo software engineer who saved the moon landing - Vox" title="Margaret Hamilton: the Apollo software engineer who saved the moon landing - Vox" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0a2f9f25-f948-4d6c-b7de-6415e8dab76b_1200x800.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0a2f9f25-f948-4d6c-b7de-6415e8dab76b_1200x800.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0a2f9f25-f948-4d6c-b7de-6415e8dab76b_1200x800.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0a2f9f25-f948-4d6c-b7de-6415e8dab76b_1200x800.jpeg 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a></figure></div><p>Margaret Hamilton and her team developed a robust error detection and recovery system for Apollo 11's on-board flight software. Through a system called "asynchronous executive," her software could prioritize tasks based on their importance. When an unexpected error occurred during Apollo 11's descent, causing system overloads, Hamilton's software automatically shed less critical tasks to ensure the computer could continue managing the descent and landing processes. This real-time error detection and recovery showcased an advanced level of software reliability and automation that was groundbreaking at the time.</p><p>Hamilton's legacy continues to inspire. Her story is a lesson in vision, resilience, and the profound impact one individual can have on the world. <br></p><h3><strong>Conclusion: Cheers to Code, Cosmos, and Birthdays </strong></h3><p>Writing this post has been a blast, and what a way to gear up for my birthday! Diving into Apollo 11&#8217;s code and reading all the trancript took me on a journey back in time, and I couldn&#8217;t have asked for a better way to celebrate. </p><p></p><h3><strong>Bonus Chapter: A Snapshot of History</strong></h3><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe3e1ffbb-6286-4dc1-8217-02b402af8385_3446x1550.png" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe3e1ffbb-6286-4dc1-8217-02b402af8385_3446x1550.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe3e1ffbb-6286-4dc1-8217-02b402af8385_3446x1550.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe3e1ffbb-6286-4dc1-8217-02b402af8385_3446x1550.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe3e1ffbb-6286-4dc1-8217-02b402af8385_3446x1550.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe3e1ffbb-6286-4dc1-8217-02b402af8385_3446x1550.png" width="1456" height="655" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/e3e1ffbb-6286-4dc1-8217-02b402af8385_3446x1550.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:655,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:510086,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe3e1ffbb-6286-4dc1-8217-02b402af8385_3446x1550.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe3e1ffbb-6286-4dc1-8217-02b402af8385_3446x1550.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe3e1ffbb-6286-4dc1-8217-02b402af8385_3446x1550.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe3e1ffbb-6286-4dc1-8217-02b402af8385_3446x1550.png 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a><figcaption class="image-caption">Source: <a href="https://history.nasa.gov/alsj/a11/a11transcript_tec.html">NASA Transcript </a></figcaption></figure></div><p>Attached is a screenshot of the transcript between Houston and Apollo 11. This dialogue shows how the world was tuned in, celebrating the mission. Reading it, you can almost feel the global excitement. It's a peek into a time when the world united to witness humans stepping on the moon. It's these dialogues that help us relive those iconic moments, understand the camaraderie, the humor, and the anticipation that encapsulated the mission, making the exploration of Apollo 11's code even more profound.</p> ]]>
</content:encoded>
</item>
<item>
<title>
<![CDATA[ Steering Towards Autonomy: A Deep Dive into Self-Driving Vehicles ]]>
</title>
<description>
<![CDATA[ From Sensor Technologies to Social Impact: What You Need to Know About Autonomous Cars ]]>
</description>
<link>https://www.tostring.ai/p/steering-towards-autonomy-a-deep</link>
<guid isPermaLink="true">https://www.tostring.ai/p/steering-towards-autonomy-a-deep</guid>
<dc:creator>
<![CDATA[ Marco Altea ]]>
</dc:creator>
<pubDate>Wed, 27 Sep 2023 16:34:05 GMT</pubDate>
<enclosure url="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5a22aaca-bef2-4d2c-8d73-0a2835fb71c4_1024x1024.png" length="0" type="image/jpeg"/>
<content:encoded>
<![CDATA[ <div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5a22aaca-bef2-4d2c-8d73-0a2835fb71c4_1024x1024.png" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5a22aaca-bef2-4d2c-8d73-0a2835fb71c4_1024x1024.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5a22aaca-bef2-4d2c-8d73-0a2835fb71c4_1024x1024.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5a22aaca-bef2-4d2c-8d73-0a2835fb71c4_1024x1024.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5a22aaca-bef2-4d2c-8d73-0a2835fb71c4_1024x1024.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5a22aaca-bef2-4d2c-8d73-0a2835fb71c4_1024x1024.png" width="1024" height="1024" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/5a22aaca-bef2-4d2c-8d73-0a2835fb71c4_1024x1024.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1024,&quot;width&quot;:1024,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:2056165,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5a22aaca-bef2-4d2c-8d73-0a2835fb71c4_1024x1024.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5a22aaca-bef2-4d2c-8d73-0a2835fb71c4_1024x1024.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5a22aaca-bef2-4d2c-8d73-0a2835fb71c4_1024x1024.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5a22aaca-bef2-4d2c-8d73-0a2835fb71c4_1024x1024.png 1456w" sizes="100vw" fetchpriority="high"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a></figure></div><p></p><h3>Introduction</h3><p>In recent years, the streets of San Francisco have transformed into a real-world testing ground for autonomous vehicles (AV). Companies like Waymo, owned by Google, and General Motors-owned Cruise have been at the forefront of this technological revolution. Despite the futuristic allure and the promise of safer, more efficient transportation, the journey towards fully autonomous taxis is full of challenges and controversies.</p><div id="youtube2-8gooo2MhX9s" class="youtube-wrap" data-attrs="{&quot;videoId&quot;:&quot;8gooo2MhX9s&quot;,&quot;startTime&quot;:null,&quot;endTime&quot;:null}" data-component-name="Youtube2ToDOM"><div class="youtube-inner"><iframe src="https://www.youtube-nocookie.com/embed/8gooo2MhX9s?rel=0&amp;autoplay=0&amp;showinfo=0&amp;enablejsapi=0" frameborder="0" loading="lazy" gesture="media" allow="autoplay; fullscreen" allowautoplay="true" allowfullscreen="true" width="728" height="409"></iframe></div></div><p><a href="https://www.nytimes.com/2023/08/21/technology/waymo-driverless-cars-san-francisco.html">The New York Times</a> describes the experience of riding in a Waymo taxi as "futuristic," with voice-guided instructions and a strict no-touch policy for the steering wheel. However, the article also raises concerns about the safety of these vehicles, especially in a city known for its hilly and congested streets. Waymo's cars have begun to function as paid taxis, but not without objections from San Francisco officials who question the vehicles' safety records.</p><p><a href="https://www.wired.com/story/robotaxis-cruise-waymo-san-francisco/">Wired's</a> coverage adds another layer to the debate, highlighting the regulatory problems faced by these companies. Despite years of testing, the vehicles have been criticized for causing traffic jams and delaying first responders. The California Public Utilities Commission's approval for Waymo and Cruise to operate comes with its own set of responsibilities and challenges, emphasizing the need for safety and data transparency.</p><p>As we try to understand the world of autonomous taxis, my writing exercise aims to explore the technological landscape and the ethical dilemmas that come with it. From Waymo's advanced machine learning algorithms to the regulatory landscape, I will try to take a comprehensive look at what it truly takes to put a driverless car on the road.</p><div class="subscription-widget-wrap-editor" data-attrs="{&quot;url&quot;:&quot;https://www.tostring.ai/subscribe?&quot;,&quot;text&quot;:&quot;Subscribe&quot;,&quot;language&quot;:&quot;en&quot;}" data-component-name="SubscribeWidgetToDOM"><div class="subscription-widget show-subscribe"><div class="preamble"><p class="cta-caption">toString() is a reader-supported publication. To receive new posts and support my work, consider becoming a free or paid subscriber.</p></div><form class="subscription-widget-subscribe"><input type="email" class="email-input" name="email" placeholder="Type your email&#8230;" tabindex="-1"><input type="submit" class="button primary" value="Subscribe"><div class="fake-input-wrapper"><div class="fake-input"></div><div class="fake-button"></div></div></form></div></div><h2><strong>Autonomous Vehicle Technologies</strong></h2><p></p><h3><strong>Sensors</strong></h3><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdd194d58-e040-4e7a-b965-d6f0940b90c1_2542x1955.webp" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdd194d58-e040-4e7a-b965-d6f0940b90c1_2542x1955.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdd194d58-e040-4e7a-b965-d6f0940b90c1_2542x1955.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdd194d58-e040-4e7a-b965-d6f0940b90c1_2542x1955.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdd194d58-e040-4e7a-b965-d6f0940b90c1_2542x1955.webp 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdd194d58-e040-4e7a-b965-d6f0940b90c1_2542x1955.webp" width="1456" height="1120" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/dd194d58-e040-4e7a-b965-d6f0940b90c1_2542x1955.webp&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1120,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1028904,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/webp&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdd194d58-e040-4e7a-b965-d6f0940b90c1_2542x1955.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdd194d58-e040-4e7a-b965-d6f0940b90c1_2542x1955.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdd194d58-e040-4e7a-b965-d6f0940b90c1_2542x1955.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdd194d58-e040-4e7a-b965-d6f0940b90c1_2542x1955.webp 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a></figure></div><h6>Source (<a href="https://www.mdpi.com/1223304">An Overview of Autonomous Vehicles Sensors and Their Vulnerability to Weather Conditions</a>)</h6><p></p><p>The backbone of any autonomous vehicle lies in its sensor technology. These sensors serve as the "eyes and ears" of the vehicle, capturing a wide array of data that is processed in real-time to make driving decisions. Among the most critical sensors are LiDAR, RaDAR, and cameras, each with its unique capabilities and applications.</p><p></p><h4>LiDAR (Light Detection and Ranging)</h4><p>LiDAR uses laser beams to measure distances and create a 3D map of the vehicle's surroundings. It is particularly effective in detecting the shape and size of objects, even in low-light conditions. Waymo, for instance, has developed a custom suite of LiDAR sensors that can detect objects up to 300 meters away.</p><p></p><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd379fb47-f7c5-4efd-9549-e4dcb3db0bf2_960x270.gif" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd379fb47-f7c5-4efd-9549-e4dcb3db0bf2_960x270.gif 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd379fb47-f7c5-4efd-9549-e4dcb3db0bf2_960x270.gif 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd379fb47-f7c5-4efd-9549-e4dcb3db0bf2_960x270.gif 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd379fb47-f7c5-4efd-9549-e4dcb3db0bf2_960x270.gif 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd379fb47-f7c5-4efd-9549-e4dcb3db0bf2_960x270.gif" width="960" height="270" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/d379fb47-f7c5-4efd-9549-e4dcb3db0bf2_960x270.gif&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:270,&quot;width&quot;:960,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:12168381,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/gif&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd379fb47-f7c5-4efd-9549-e4dcb3db0bf2_960x270.gif 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd379fb47-f7c5-4efd-9549-e4dcb3db0bf2_960x270.gif 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd379fb47-f7c5-4efd-9549-e4dcb3db0bf2_960x270.gif 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd379fb47-f7c5-4efd-9549-e4dcb3db0bf2_960x270.gif 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a></figure></div><h6>Source (<a href="https://waymo.com/blog/2021/10/the-waymo-driver-handbook-perception.html">Waymo Blog</a>)<br></h6><h4>RaDAR (Radio Detection and Ranging)</h4><p>RaDAR employs radio waves to determine the velocity, range, and angle of objects around the vehicle. Unlike LiDAR, RaDAR is less affected by weather conditions like fog or rain, making it a crucial component for all-weather autonomous driving. Waymo's latest hardware integrates RaDAR to provide a more comprehensive understanding of the vehicle's environment.</p><h4>Cameras</h4><p>Cameras offer the advantage of color and texture recognition, which is vital for tasks like reading traffic signs or detecting lane markings. They are usually less expensive than LiDAR and RaDAR, but are more susceptible to varying lighting and weather conditions. Waymo's vehicles use high-resolution cameras to complement the data gathered by LiDAR and RaDAR, ensuring a 360-degree view of the road.</p><div class="captioned-button-wrap" data-attrs="{&quot;url&quot;:&quot;https://www.tostring.ai/p/steering-towards-autonomy-a-deep?utm_source=substack&utm_medium=email&utm_content=share&action=share&token=eyJ1c2VyX2lkIjoyMTE1MDMzMywicG9zdF9pZCI6MTM3NDQ4MTQxLCJpYXQiOjE3MzgxNjE5MjIsImV4cCI6MTc0MDc1MzkyMiwiaXNzIjoicHViLTgzMTY2NiIsInN1YiI6InBvc3QtcmVhY3Rpb24ifQ.QtrSszwDR3Yof9Mv64ElJkcBU9tlCytfrZUp0flu1s0&quot;,&quot;text&quot;:&quot;Share&quot;}" data-component-name="CaptionedButtonToDOM"><div class="preamble"><p class="cta-caption">Thank you for reading toString(). This post is public so feel free to share it.</p></div><p class="button-wrapper" data-attrs="{&quot;url&quot;:&quot;https://www.tostring.ai/p/steering-towards-autonomy-a-deep?utm_source=substack&utm_medium=email&utm_content=share&action=share&token=eyJ1c2VyX2lkIjoyMTE1MDMzMywicG9zdF9pZCI6MTM3NDQ4MTQxLCJpYXQiOjE3MzgxNjE5MjIsImV4cCI6MTc0MDc1MzkyMiwiaXNzIjoicHViLTgzMTY2NiIsInN1YiI6InBvc3QtcmVhY3Rpb24ifQ.QtrSszwDR3Yof9Mv64ElJkcBU9tlCytfrZUp0flu1s0&quot;,&quot;text&quot;:&quot;Share&quot;}" data-component-name="ButtonCreateButton"><a class="button primary" href="https://www.tostring.ai/p/steering-towards-autonomy-a-deep?utm_source=substack&utm_medium=email&utm_content=share&action=share&token=eyJ1c2VyX2lkIjoyMTE1MDMzMywicG9zdF9pZCI6MTM3NDQ4MTQxLCJpYXQiOjE3MzgxNjE5MjIsImV4cCI6MTc0MDc1MzkyMiwiaXNzIjoicHViLTgzMTY2NiIsInN1YiI6InBvc3QtcmVhY3Rpb24ifQ.QtrSszwDR3Yof9Mv64ElJkcBU9tlCytfrZUp0flu1s0"><span>Share</span></a></p></div><h2><strong>Machine Learning and AI</strong></h2><p>The rise of AV is intrinsically linked to advancements in machine learning and artificial intelligence (AI). These technologies serve as the "brain" of the vehicle, processing the data collected by sensors to make real-time driving decisions. Below, we delve into how machine learning and AI are revolutionizing the field of autonomous driving.</p><p></p><h3><strong>Data Processing and Sensor Fusion</strong></h3><p>One of the primary roles of machine learning in AVs is data processing and sensor fusion. The vehicle's sensors generate a massive amount of data that needs to be processed in real-time. Machine learning algorithms are employed to fuse this data from multiple sources (LiDAR, RaDAR, cameras) to create a unified and accurate representation of the vehicle's surroundings.</p><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F22ce10e6-da14-4c3b-9440-f1774e2f891b_1024x432.jpeg" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F22ce10e6-da14-4c3b-9440-f1774e2f891b_1024x432.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F22ce10e6-da14-4c3b-9440-f1774e2f891b_1024x432.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F22ce10e6-da14-4c3b-9440-f1774e2f891b_1024x432.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F22ce10e6-da14-4c3b-9440-f1774e2f891b_1024x432.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F22ce10e6-da14-4c3b-9440-f1774e2f891b_1024x432.jpeg" width="1024" height="432" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/22ce10e6-da14-4c3b-9440-f1774e2f891b_1024x432.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:432,&quot;width&quot;:1024,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Figure6&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" class="sizing-normal" alt="Figure6" title="Figure6" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F22ce10e6-da14-4c3b-9440-f1774e2f891b_1024x432.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F22ce10e6-da14-4c3b-9440-f1774e2f891b_1024x432.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F22ce10e6-da14-4c3b-9440-f1774e2f891b_1024x432.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F22ce10e6-da14-4c3b-9440-f1774e2f891b_1024x432.jpeg 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a></figure></div><h6>Source (<a href="https://www.edge-ai-vision.com/2019/01/multi-sensor-fusion-for-robust-device-autonomy/">edge-ai-vision.com</a>)</h6><h3><strong>Decision-Making and Control</strong></h3><p>Machine learning models are trained to make driving decisions based on the processed sensor data. These decisions range from simple tasks like lane-keeping and speed control to complex manoeuvres like overtaking and navigating through intersections. Advanced algorithms also account for dynamic elements like pedestrians, other vehicles, and varying road conditions.</p><div id="youtube2-VAhBWF3PRM8" class="youtube-wrap" data-attrs="{&quot;videoId&quot;:&quot;VAhBWF3PRM8&quot;,&quot;startTime&quot;:null,&quot;endTime&quot;:null}" data-component-name="Youtube2ToDOM"><div class="youtube-inner"><iframe src="https://www.youtube-nocookie.com/embed/VAhBWF3PRM8?rel=0&amp;autoplay=0&amp;showinfo=0&amp;enablejsapi=0" frameborder="0" loading="lazy" gesture="media" allow="autoplay; fullscreen" allowautoplay="true" allowfullscreen="true" width="728" height="409"></iframe></div></div><h3><strong>Simulation and Testing</strong></h3><p>Before deploying on real roads, autonomous driving algorithms undergo rigorous testing in simulation environments. Waymo, for example, uses highly detailed simulations to train its machine learning models. These simulations mimic real-world conditions, allowing the algorithms to learn from millions of driving scenarios without ever hitting the road.</p><div class="subscription-widget-wrap-editor" data-attrs="{&quot;url&quot;:&quot;https://www.tostring.ai/subscribe?&quot;,&quot;text&quot;:&quot;Subscribe&quot;,&quot;language&quot;:&quot;en&quot;}" data-component-name="SubscribeWidgetToDOM"><div class="subscription-widget show-subscribe"><div class="preamble"><p class="cta-caption">toString() is a reader-supported publication. To receive new posts and support my work, consider becoming a free or paid subscriber.</p></div><form class="subscription-widget-subscribe"><input type="email" class="email-input" name="email" placeholder="Type your email&#8230;" tabindex="-1"><input type="submit" class="button primary" value="Subscribe"><div class="fake-input-wrapper"><div class="fake-input"></div><div class="fake-button"></div></div></form></div></div><h3><strong>AutoML and Evolutionary Algorithms</strong></h3><p>Waymo has also explored the use of AutoML and evolutionary algorithms to automate the design of machine learning models. These advanced techniques optimize the model's architecture, making it more efficient and effective in handling the complexities of autonomous driving.</p><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc9901e45-b5aa-49b5-87b8-3946610ba4bd_1600x536.png" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc9901e45-b5aa-49b5-87b8-3946610ba4bd_1600x536.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc9901e45-b5aa-49b5-87b8-3946610ba4bd_1600x536.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc9901e45-b5aa-49b5-87b8-3946610ba4bd_1600x536.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc9901e45-b5aa-49b5-87b8-3946610ba4bd_1600x536.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc9901e45-b5aa-49b5-87b8-3946610ba4bd_1600x536.png" width="1456" height="488" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/c9901e45-b5aa-49b5-87b8-3946610ba4bd_1600x536.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:488,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Thumbnail&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" class="sizing-normal" alt="Thumbnail" title="Thumbnail" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc9901e45-b5aa-49b5-87b8-3946610ba4bd_1600x536.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc9901e45-b5aa-49b5-87b8-3946610ba4bd_1600x536.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc9901e45-b5aa-49b5-87b8-3946610ba4bd_1600x536.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc9901e45-b5aa-49b5-87b8-3946610ba4bd_1600x536.png 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a></figure></div><h6>Source (<a href="https://waymo.com/blog/2019/07/automl-automating-design-of-machine.html">Waymo Blog</a>)</h6><p></p><h2><strong>Safety and Reliability</strong></h2><p>As AVs take to the roads, safety and reliability remain big concerns for both the industry and the public. The promise of reducing human error and accidents is exciting, but it also brings forth a host of challenges that need to be addressed in details. Here's how AVs are tackling these issues</p><h3><strong>Safety Protocols and Features</strong></h3><p>AV are equipped with a range of safety protocols and features designed to prevent accidents and protect passengers. These include emergency braking systems, collision avoidance algorithms, and secure communication channels for vehicle-to-vehicle and vehicle-to-infrastructure interactions. Waymo's vehicles, for instance, undergo rigorous safety validation, including structured tests and millions of miles of road testing.</p><h3><strong>Weather Adaptability</strong></h3><p>One of the most significant challenges forAVs is operating reliably in varying weather conditions. Waymo and Tesla have invested in cutting-edge weather research to make its vehicles adaptable to conditions like rain, fog, and snow. The companies use real-time weather data and predictive algorithms to adjust the vehicle's driving behaviour accordingly.</p><div id="youtube2-c2tlbPaau8A" class="youtube-wrap" data-attrs="{&quot;videoId&quot;:&quot;c2tlbPaau8A&quot;,&quot;startTime&quot;:null,&quot;endTime&quot;:null}" data-component-name="Youtube2ToDOM"><div class="youtube-inner"><iframe src="https://www.youtube-nocookie.com/embed/c2tlbPaau8A?rel=0&amp;autoplay=0&amp;showinfo=0&amp;enablejsapi=0" frameborder="0" loading="lazy" gesture="media" allow="autoplay; fullscreen" allowautoplay="true" allowfullscreen="true" width="728" height="409"></iframe></div></div><h3><strong>Redundancy Systems</strong></h3><p>To enhance reliability, AVs employ redundancy systems. These are backup systems designed to take over in case of a primary system failure. For example, if a LiDAR sensor fails, the vehicle can rely on its cameras and RaDAR to continue safe operation.</p><div class="captioned-button-wrap" data-attrs="{&quot;url&quot;:&quot;https://www.tostring.ai/p/steering-towards-autonomy-a-deep?utm_source=substack&utm_medium=email&utm_content=share&action=share&token=eyJ1c2VyX2lkIjoyMTE1MDMzMywicG9zdF9pZCI6MTM3NDQ4MTQxLCJpYXQiOjE3MzgxNjE5MjIsImV4cCI6MTc0MDc1MzkyMiwiaXNzIjoicHViLTgzMTY2NiIsInN1YiI6InBvc3QtcmVhY3Rpb24ifQ.QtrSszwDR3Yof9Mv64ElJkcBU9tlCytfrZUp0flu1s0&quot;,&quot;text&quot;:&quot;Share&quot;}" data-component-name="CaptionedButtonToDOM"><div class="preamble"><p class="cta-caption">Thank you for reading toString(). This post is public so feel free to share it.</p></div><p class="button-wrapper" data-attrs="{&quot;url&quot;:&quot;https://www.tostring.ai/p/steering-towards-autonomy-a-deep?utm_source=substack&utm_medium=email&utm_content=share&action=share&token=eyJ1c2VyX2lkIjoyMTE1MDMzMywicG9zdF9pZCI6MTM3NDQ4MTQxLCJpYXQiOjE3MzgxNjE5MjIsImV4cCI6MTc0MDc1MzkyMiwiaXNzIjoicHViLTgzMTY2NiIsInN1YiI6InBvc3QtcmVhY3Rpb24ifQ.QtrSszwDR3Yof9Mv64ElJkcBU9tlCytfrZUp0flu1s0&quot;,&quot;text&quot;:&quot;Share&quot;}" data-component-name="ButtonCreateButton"><a class="button primary" href="https://www.tostring.ai/p/steering-towards-autonomy-a-deep?utm_source=substack&utm_medium=email&utm_content=share&action=share&token=eyJ1c2VyX2lkIjoyMTE1MDMzMywicG9zdF9pZCI6MTM3NDQ4MTQxLCJpYXQiOjE3MzgxNjE5MjIsImV4cCI6MTc0MDc1MzkyMiwiaXNzIjoicHViLTgzMTY2NiIsInN1YiI6InBvc3QtcmVhY3Rpb24ifQ.QtrSszwDR3Yof9Mv64ElJkcBU9tlCytfrZUp0flu1s0"><span>Share</span></a></p></div><h2><strong>Connectivity Requirements</strong></h2><p>AV are not isolated entities, they are part of a larger ecosystem that includes other vehicles, infrastructure, and even pedestrians. Here's how connectivity plays a vital role in the functioning of AVs:</p><h3><strong>Vehicle-to-Everything (V2X)</strong></h3><p>One of the key aspects of connectivity in AVs is Vehicle-to-Everything (V2X) communication. This encompasses </p><ul><li><p>Vehicle-to-Vehicle (V2V)</p></li><li><p>Vehicle-to-Infrastructure (V2I)</p></li><li><p>Vehicle-to-Pedestrian (V2P) interactions. </p></li></ul><p>V2X communication allows AVS to share information and make coordinated decisions, enhancing road safety and traffic efficiency.</p><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcc11521a-840b-4e96-8980-18caa5bd0f83_550x403.gif" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcc11521a-840b-4e96-8980-18caa5bd0f83_550x403.gif 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcc11521a-840b-4e96-8980-18caa5bd0f83_550x403.gif 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcc11521a-840b-4e96-8980-18caa5bd0f83_550x403.gif 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcc11521a-840b-4e96-8980-18caa5bd0f83_550x403.gif 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcc11521a-840b-4e96-8980-18caa5bd0f83_550x403.gif" width="550" height="403" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/cc11521a-840b-4e96-8980-18caa5bd0f83_550x403.gif&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:403,&quot;width&quot;:550,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;FIGURE 2. - V2X communication infrastructure using different technologies.&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" class="sizing-normal" alt="FIGURE 2. - V2X communication infrastructure using different technologies." title="FIGURE 2. - V2X communication infrastructure using different technologies." srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcc11521a-840b-4e96-8980-18caa5bd0f83_550x403.gif 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcc11521a-840b-4e96-8980-18caa5bd0f83_550x403.gif 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcc11521a-840b-4e96-8980-18caa5bd0f83_550x403.gif 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcc11521a-840b-4e96-8980-18caa5bd0f83_550x403.gif 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a></figure></div><h6>Source: (<a href="https://ieeexplore.ieee.org/abstract/document/8668495">5G Communication: An Overview of Vehicle-to-Everything, Drones, and Healthcare Use-Cases</a>)</h6><h3><strong>Real-Time Data Streaming</strong></h3><p>AV require real-time data streaming for functions like navigation, traffic updates, and emergency response. High-speed, low-latency networks like 5G are becoming increasingly important for these applications. They enable the vehicle to receive and process data in real-time, making driving decisions more accurate and timely.</p><h3><strong>Evolution and Future Trends</strong></h3><p>As we look towards the future, autonomous vehicles promise to revolutionize transportation in numerous ways. While the focus is often on the positive impacts like increased safety and efficiency, it's essential to consider some of the unintended consequences that may arise. Here's a look at what the future holds, both good and bad</p><h3><strong>Reduced Traffic Accidents</strong></h3><p>One of the most touted benefits of autonomous vehicles is the potential for significantly reducing traffic accidents. Human error is a leading cause of road accidents, and autonomous vehicles aim to eliminate this factor. While this is undoubtedly a positive development, it leads us to an unexpected issue:</p><h4>Reduced Organ Donations</h4><p>A less-discussed consequence of fewer road accidents is the potential impact on organ donations. In many countries, a significant percentage of organ donations come from victims of fatal road accidents. As autonomous vehicles make roads safer, this source of organ donations could diminish, posing challenges for healthcare systems already grappling with organ shortages.</p><h3><strong>Data Privacy and Surveillance</strong></h3><p>As autonomous vehicles collect vast amounts of data, concerns about data privacy and surveillance arise. Regulatory frameworks will need to address how this data is stored, accessed, and used, balancing the benefits of data analysis with the protection of individual privacy.</p><p></p><h3><strong>Wrap-up</strong></h3><p>The journey towards fully AVs is a complex and multi-faceted journey, filled with both promise and challenges. From advanced sensor technologies and machine learning algorithms to safety protocols and robust connectivity solutions, the industry is making significant strides in bringing this revolutionary form of transportation to the masses. However, as we've explored, the rise of autonomous vehicles is not without its unintended consequences and this is's a testament to the transformative power of this technology that its impact extends beyond the realm of transportation, touching on aspects of healthcare, employment, and ethics.</p><div class="subscription-widget-wrap-editor" data-attrs="{&quot;url&quot;:&quot;https://www.tostring.ai/subscribe?&quot;,&quot;text&quot;:&quot;Subscribe&quot;,&quot;language&quot;:&quot;en&quot;}" data-component-name="SubscribeWidgetToDOM"><div class="subscription-widget show-subscribe"><div class="preamble"><p class="cta-caption">toString() is a reader-supported publication. To receive new posts and support my work, consider becoming a free or paid subscriber.</p></div><form class="subscription-widget-subscribe"><input type="email" class="email-input" name="email" placeholder="Type your email&#8230;" tabindex="-1"><input type="submit" class="button primary" value="Subscribe"><div class="fake-input-wrapper"><div class="fake-input"></div><div class="fake-button"></div></div></form></div></div><p>Thank you for joining me on this deep dive into the world of autonomous vehicles. </p><p></p><p class="button-wrapper" data-attrs="{&quot;url&quot;:&quot;https://www.tostring.ai/p/steering-towards-autonomy-a-deep/comments&quot;,&quot;text&quot;:&quot;Leave a comment&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a class="button primary" href="https://www.tostring.ai/p/steering-towards-autonomy-a-deep/comments"><span>Leave a comment</span></a></p><div><hr></div><h5>Source references:</h5><h6>https://waymo.com/blog/2019/08/introducing-waymos-suite-of-custom.html </h6><h6>https://waymo.com/blog/2019/09/scenes-from-street.html </h6><h6>https://waymo.com/blog/2019/08/how-simulation-turns-one-flashing.html </h6><h6>https://waymo.com/blog/2019/08/google-io-recap-turning-self-driving.html </h6><h6>https://waymo.com/blog/2019/08/learning-to-drive-beyond-pure-imitation_26.html</h6><h6>https://waymo.com/blog/2019/07/automl-automating-design-of-machine.html </h6><h6>https://waymo.com/blog/2019/08/how-evolutionary-selection-can-train.html </h6><h6>https://waymo.com/blog/2021/10/the-waymo-driver-handbook-perception.html</h6><h6>https://waymo.com/blog/2022/02/utilizing-key-point-and-pose-estimation.html </h6><h6>https://waymo.com/blog/2022/11/using-cutting-edge-weather-research-to-advance-the-Waymo-Driver.html </h6><h6>https://waymo.com/blog/2023/08/the-waymo-drivers-rapid-learning-curve.html https://medium.com/@justinmilner/a-visual-guide-to-the-software-architecture-of-autonomous-vehicles-390b1744cbd6 https://spectrum.ieee.org/6-key-connectivity-requirements-of-autonomous-driving</h6><h6>https://en.wikipedia.org/wiki/Vehicle-to-everything</h6><h6>https://ieeexplore.ieee.org/abstract/document/8668495</h6><h6>https://fortune.com/2014/08/15/if-driverless-cars-save-lives-where-will-we-get-organs/</h6><p></p><div><hr></div><h6>Some phrase reformulations and grammar checks were performed with the assistance of ChatGPT-4 by OpenAI.</h6> ]]>
</content:encoded>
</item>
<item>
<title>
<![CDATA[ Designing an Apocalypse-Resilient Cosmic Internet ]]>
</title>
<description>
<![CDATA[ A Technical Dive into Building a Network that Survives Earth's Apocalypse ]]>
</description>
<link>https://www.tostring.ai/p/designing-an-apocalypse-resilient</link>
<guid isPermaLink="true">https://www.tostring.ai/p/designing-an-apocalypse-resilient</guid>
<dc:creator>
<![CDATA[ Marco Altea ]]>
</dc:creator>
<pubDate>Wed, 20 Sep 2023 12:48:33 GMT</pubDate>
<enclosure url="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4153195-1b10-46e3-b6cd-8c5ef78e9a35_1024x1024.png" length="0" type="image/jpeg"/>
<content:encoded>
<![CDATA[ <h3>Introduction</h3><p>The Internet has become the epitome of human connectivity and knowledge sharing. As we've grown increasingly dependent on this intricate web of networks, its vulnerabilities have also become apparent. A cosmic internet, resilient even to Earth-bound apocalypses, is moving from the realm of luxury to necessity.</p><p>But before diving into the technicalities, let's set the stage: The aim of this post is not just to discuss the architecture of a hypothetical cosmic internet. It's about having fun with the idea, stimulating our collective imaginations, and maybe, just maybe, inspiring some thought-provoking discussions. I'm an experienced software architect, but let's be clear&#8212;my expertise doesn't extend to cosmic network design. This is a venture into the exciting unknown, a blend of science and imagination, and I invite you to join me on this speculative journey.</p><div class="subscription-widget-wrap-editor" data-attrs="{&quot;url&quot;:&quot;https://www.tostring.ai/subscribe?&quot;,&quot;text&quot;:&quot;Subscribe&quot;,&quot;language&quot;:&quot;en&quot;}" data-component-name="SubscribeWidgetToDOM"><div class="subscription-widget show-subscribe"><div class="preamble"><p class="cta-caption">Thanks for reading toString()! Subscribe for free to receive new posts and support my work.</p></div><form class="subscription-widget-subscribe"><input type="email" class="email-input" name="email" placeholder="Type your email&#8230;" tabindex="-1"><input type="submit" class="button primary" value="Subscribe"><div class="fake-input-wrapper"><div class="fake-input"></div><div class="fake-button"></div></div></form></div></div><h3>Inspiration</h3><p><a class="footnote-anchor" data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-1" href="#footnote-1" target="_self">1</a>John Carmack, an influential tech visionary (I'm a huge fan of him), recently inspired me with a tweet. He proposed a space-based internet<a class="footnote-anchor" data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-2" href="#footnote-2" target="_self">2</a> that could withstand catastrophic events, serve humanity's expansion into space, and function autonomously. His idea of off-grid servers, smart routing, and durable GEO satellites serves as the foundation for this post.</p><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdbcfcdd2-66a6-4122-8929-910a0d879219_597x815.png" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdbcfcdd2-66a6-4122-8929-910a0d879219_597x815.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdbcfcdd2-66a6-4122-8929-910a0d879219_597x815.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdbcfcdd2-66a6-4122-8929-910a0d879219_597x815.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdbcfcdd2-66a6-4122-8929-910a0d879219_597x815.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdbcfcdd2-66a6-4122-8929-910a0d879219_597x815.png" width="597" height="815" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/dbcfcdd2-66a6-4122-8929-910a0d879219_597x815.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:815,&quot;width&quot;:597,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:155946,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdbcfcdd2-66a6-4122-8929-910a0d879219_597x815.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdbcfcdd2-66a6-4122-8929-910a0d879219_597x815.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdbcfcdd2-66a6-4122-8929-910a0d879219_597x815.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdbcfcdd2-66a6-4122-8929-910a0d879219_597x815.png 1456w" sizes="100vw" fetchpriority="high"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a></figure></div><h3>The Apocalyptic Scenario: Earth's Doomsday</h3><p>In a nightmarish turn of events, the world's worst fears are realized: a nuclear apocalypse devastate Earth. Major cities are obliterated within minutes, taking down with them the bulk of data centres that once hosted all the humankind information&#8212;medical records, technological blueprints, historical documents, and more. A lot of satellites that orbited Earth are either knocked out of the sky by nuclear shockwaves or disabled by the electromagnetic pulses that followed the blasts.</p><p>Sarah, a scientist, is among the lucky few who managed to reach a subterranean shelter before the disaster. Her shelter, designed to sustain a community of 50 people, is stocked with essential supplies. However, the shelter's residents are not just battling for physical survival; they're struggling to preserve knowledge and maintain a semblance of societal structure. Sarah knows of a website hosted on an Orbiting Data Center (ODC) that contains critical information&#8212;how to purify water using makeshift materials, techniques for subsistence farming in contaminated soil, medical first aid procedures, and communication protocols for survivors.</p><p>Access to this server isn't a mere convenience; it's a lifeline. The information it holds could mean the difference between a short, brutish existence and the hope for rebuilding. The shelter's isolated server can only connect to the outside world, or what's left of it, via a rudimentary satellite link. Can any existing or theoretical network architecture enable Sarah to access this vital information? How would each architecture behave in this dire situation?</p><p></p><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4153195-1b10-46e3-b6cd-8c5ef78e9a35_1024x1024.png" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4153195-1b10-46e3-b6cd-8c5ef78e9a35_1024x1024.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4153195-1b10-46e3-b6cd-8c5ef78e9a35_1024x1024.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4153195-1b10-46e3-b6cd-8c5ef78e9a35_1024x1024.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4153195-1b10-46e3-b6cd-8c5ef78e9a35_1024x1024.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4153195-1b10-46e3-b6cd-8c5ef78e9a35_1024x1024.png" width="1024" height="1024" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/d4153195-1b10-46e3-b6cd-8c5ef78e9a35_1024x1024.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1024,&quot;width&quot;:1024,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1477549,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4153195-1b10-46e3-b6cd-8c5ef78e9a35_1024x1024.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4153195-1b10-46e3-b6cd-8c5ef78e9a35_1024x1024.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4153195-1b10-46e3-b6cd-8c5ef78e9a35_1024x1024.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4153195-1b10-46e3-b6cd-8c5ef78e9a35_1024x1024.png 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a></figure></div><p></p><h3>Architectural Models for a Cosmic Internet</h3><p></p><h4><strong>Earth-Centric Model</strong></h4><p></p><h5>System Architecture</h5><p>In the Earth-Centric model, Earth's surface hosts the primary data centres, network operation centres, and ground stations that control satellites in both Low Earth Orbit (LEO) and Geostationary Earth Orbit (GEO). In addition, there are backup data centres and relay stations established on the Moon and Mars. These celestial bases are connected to Earth via <a class="footnote-anchor" data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-3" href="#footnote-3" target="_self">3</a> links and are generally used for research and redundancy.</p><h5><strong>System Components Involved</strong>:</h5><ul><li><p><strong>Earth-Based Data Centres</strong>: Store the majority of the data and handle most of the computational load.</p></li><li><p><strong>Ground Stations</strong>: Control the satellites, handle Earth-to-space communications.<a class="footnote-anchor" data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-4" href="#footnote-4" target="_self">4</a></p></li><li><p><strong>LEO Satellites</strong>: Provide fast, low-latency internet services.<a class="footnote-anchor" data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-5" href="#footnote-5" target="_self">5</a></p></li><li><p><strong>GEO Satellites</strong>: Offer wider coverage but with higher latency.<a class="footnote-anchor" data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-6" href="#footnote-6" target="_self">6</a></p></li><li><p><strong>Moon and Mars Bases</strong>: Serve as backup data storage and have their own ground stations to control any orbiting satellites around these celestial bodies.</p></li></ul><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb4cf5a4f-dac2-4b9d-b50c-23897d78c9b4_4200x3450.png" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb4cf5a4f-dac2-4b9d-b50c-23897d78c9b4_4200x3450.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb4cf5a4f-dac2-4b9d-b50c-23897d78c9b4_4200x3450.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb4cf5a4f-dac2-4b9d-b50c-23897d78c9b4_4200x3450.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb4cf5a4f-dac2-4b9d-b50c-23897d78c9b4_4200x3450.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb4cf5a4f-dac2-4b9d-b50c-23897d78c9b4_4200x3450.png" width="1456" height="1196" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/b4cf5a4f-dac2-4b9d-b50c-23897d78c9b4_4200x3450.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1196,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:281662,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb4cf5a4f-dac2-4b9d-b50c-23897d78c9b4_4200x3450.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb4cf5a4f-dac2-4b9d-b50c-23897d78c9b4_4200x3450.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb4cf5a4f-dac2-4b9d-b50c-23897d78c9b4_4200x3450.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb4cf5a4f-dac2-4b9d-b50c-23897d78c9b4_4200x3450.png 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a></figure></div><p></p><h5><strong>Post-Apocalypse Impact</strong>:</h5><ul><li><p><strong>Earth-Based Data Centres</strong>: Destroyed, resulting in loss of primary data storage and computational resources.</p></li><li><p><strong>Ground Stations</strong>: Incapacitated, leading to loss of control over satellites.</p></li><li><p><strong>LEO Satellites</strong>: Likely knocked out by nuclear shockwaves or rendered useless by electromagnetic pulses (EMPs).</p></li><li><p><strong>GEO Satellites</strong>: Some might survive, but would be uncontrollable due to the loss of ground stations.</p></li><li><p><strong>Moon and Mars Bases</strong>: Operational, but with limited data and no capability to control or receive data from Earth-orbiting satellites.</p></li></ul><p>In this grim scenario, Sarah's chances of accessing the critical website would depend on whether the data she needs had been backed up to the Moon or Mars bases. Even if it had been, the communication link would be tenuous at best, given that the shelter's server relies on a rudimentary satellite link that, in all likelihood, is no longer functional due to the loss of Earth's ground stations.</p><p>This scenario highlights the Earth-Centric model's vulnerability to catastrophic Earth-bound events and underscores the need for a more resilient architecture.</p><p></p><h4><strong>Hybrid Model</strong></h4><p></p><h5>System Architecture</h5><p>The Hybrid Model combines elements of both the Earth-Centric and Distributed Models. Earth serves as the primary hub but is supplemented by a network of Interplanetary Routing Nodes (IRNs) and Orbiting Data Centres (ODCs). These assets are not just backups; they actively participate in data storage and routing, functioning in tandem with Earth-based systems.</p><h5><strong>Components Involved</strong>:</h5><ul><li><p><strong>Earth-Based Data Centres and Ground Stations</strong>: Similar to the Earth-Centric model, these handle the majority of data storage and satellite control.</p></li><li><p><strong>Interplanetary Routing Nodes (IRNs)</strong>: Positioned at various points in space, these are smart routers equipped with machine learning algorithms for efficient data routing.<a class="footnote-anchor" data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-7" href="#footnote-7" target="_self">7</a></p></li><li><p><strong>Orbiting Data Centres (ODCs)</strong>: These are essentially data centres in space, orbiting Earth, Moon, or Mars. They store data and can perform computational tasks.</p></li><li><p><strong>Celestial Bases on Moon and Mars</strong>: These have their own IRNs and small-scale ODCs and serve as a bridge for interplanetary communication.</p></li><li><p><strong>LEO and GEO Satellites</strong>: Serve dual purposes&#8212;Earth-based internet coverage and interplanetary data relay.</p></li></ul><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d08cc78-be91-4946-974a-e86bb77c8534_716x624.png" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d08cc78-be91-4946-974a-e86bb77c8534_716x624.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d08cc78-be91-4946-974a-e86bb77c8534_716x624.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d08cc78-be91-4946-974a-e86bb77c8534_716x624.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d08cc78-be91-4946-974a-e86bb77c8534_716x624.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d08cc78-be91-4946-974a-e86bb77c8534_716x624.png" width="716" height="624" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/4d08cc78-be91-4946-974a-e86bb77c8534_716x624.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:624,&quot;width&quot;:716,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:232299,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d08cc78-be91-4946-974a-e86bb77c8534_716x624.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d08cc78-be91-4946-974a-e86bb77c8534_716x624.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d08cc78-be91-4946-974a-e86bb77c8534_716x624.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d08cc78-be91-4946-974a-e86bb77c8534_716x624.png 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a></figure></div><p><a class="footnote-anchor" data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-8" href="#footnote-8" target="_self">8</a></p><h5><strong>Post-Apocalypse Impact</strong>:</h5><ul><li><p><strong>Earth-Based Data Centres and Ground Stations</strong>: Destroyed or disabled, leading to a complete loss of control over Earth-orbiting satellites.</p></li><li><p><strong>Interplanetary Routing Nodes (IRNs)</strong>: Still operational and capable of autonomous function due to their machine learning capabilities.</p></li><li><p><strong>Orbiting Data Centres (ODCs)</strong>: Partially operational; those orbiting Moon and Mars would continue to function, but Earth-orbiting ODCs may be incapacitated.</p></li><li><p><strong>Celestial Bases on Moon and Mars</strong>: Fully operational and capable of both storing and routing data.</p></li><li><p><strong>LEO and GEO Satellites</strong>: LEO satellites would likely be destroyed, but some GEO satellites could survive, albeit without Earth-based control.</p></li></ul><p>In this scenario, Sarah's chances of accessing the vital information are moderately better compared to the Earth-Centric model. The IRNs would detect the loss of Earth-based nodes and reroute her data request autonomously to the nearest functional ODC, likely one orbiting the Moon or Mars. However, latency and data integrity could be issues, given the unprecedented network load and the loss of Earth's primary data centres.</p><p>This highlights the Hybrid Model's adaptability and resilience but also brings attention to its complexity and potential points of failure.</p><p></p><h4><strong>Distributed Model with No Central Hub</strong></h4><p></p><h5>System Architecture</h5><p>In this model, there are no central hubs like Earth; instead, we rely on a mesh of Interplanetary Routing Nodes (IRNs) and Orbiting Data Centres (ODCs) distributed across various celestial bodies like the Moon, Mars, and potentially even farther locations like Europa, one of Jupiter's moons.</p><h5><strong>Components:</strong></h5><ul><li><p><strong>Interplanetary Routing Nodes (IRNs)</strong>: Smart routers equipped with machine learning algorithms to make real-time routing decisions based on network health, data request types, and other factors. Similar concepts exist in Earth-based Content Delivery Networks.</p></li><li><p><strong>Orbiting Data Centers (ODCs)</strong>: These are self-sustaining data centers orbiting celestial bodies, equipped with solar panels for energy and advanced cooling systems to mitigate overheating.</p></li><li><p><strong>Local Gateways</strong>: These are Earth-based servers that initially handle user requests and interface with the cosmic network. Post-apocalypse, similar structures would exist in any surviving colonies on the Moon or Mars.</p></li></ul><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4f4f951d-ea2c-44db-b8db-c64c2a7676f9_719x539.png" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4f4f951d-ea2c-44db-b8db-c64c2a7676f9_719x539.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4f4f951d-ea2c-44db-b8db-c64c2a7676f9_719x539.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4f4f951d-ea2c-44db-b8db-c64c2a7676f9_719x539.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4f4f951d-ea2c-44db-b8db-c64c2a7676f9_719x539.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4f4f951d-ea2c-44db-b8db-c64c2a7676f9_719x539.png" width="719" height="539" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/4f4f951d-ea2c-44db-b8db-c64c2a7676f9_719x539.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:539,&quot;width&quot;:719,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:88907,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4f4f951d-ea2c-44db-b8db-c64c2a7676f9_719x539.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4f4f951d-ea2c-44db-b8db-c64c2a7676f9_719x539.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4f4f951d-ea2c-44db-b8db-c64c2a7676f9_719x539.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4f4f951d-ea2c-44db-b8db-c64c2a7676f9_719x539.png 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a></figure></div><p><a class="footnote-anchor" data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-9" href="#footnote-9" target="_self">9</a></p><h5>Network and Packet Flow Examples</h5><ol><li><p><strong>Earth</strong>: Sarah inputs a URL to access vital survival information. The local Gateway forwards this to the nearest IRN.</p></li><li><p><strong>Moon</strong>: A Moon colonist inputs a similar request. The IRN directly connected to the Moon colony routes the request to the closest ODC.</p></li><li><p><strong>Mars</strong>: A Martian inputs a URL. The Martian local Gateway sends the request to its closest IRN, which then forwards it to an ODC orbiting Mars.</p></li></ol><h5>Power Source Criticality and Lifespan</h5><ul><li><p><strong>IRNs</strong>: Powered by advanced solar panels and small nuclear reactors, these could last up to 25 years without maintenance.</p></li><li><p><strong>ODCs</strong>: These could last up to 30 years, thanks to their more substantial power sources, including larger solar arrays and nuclear reactors.</p></li></ul><p>The primary risk for IRNs and ODCs would be mechanical failures and radiation damage, exacerbated by the lack of maintenance post-apocalypse.</p><p></p><h4>Post-Apocalypse Impact:</h4><p>In the wake of Earth's destruction, the Distributed Model with No Central Hub stands as a beacon of resilience. Here's how:</p><ul><li><p><strong>Local Gateways</strong>: Any local Gateway that survived the apocalypse would become a vital link for survivors like Sarah to access the cosmic network. These could be in subterranean shelters or fortified structures.</p></li><li><p><strong>IRNs &amp; ODCs Unaffected</strong>: Since IRNs and ODCs are distributed across celestial bodies and orbits, they are insulated from Earth-based catastrophes. Their machine learning algorithms would quickly adapt to the loss of Earth-based data centers, rerouting requests to the next optimal ODC.</p></li><li><p><strong>Data Integrity</strong>: The distributed nature of ODCs ensures that data, including vital survival information, remains intact and accessible even if Earth-based data centers are destroyed.</p></li><li><p><strong>Communication</strong>: Surviving human colonies on the Moon or Mars would be able to maintain communication with each other, thanks to the network's distributed architecture.</p></li><li><p><strong>Energy Sustainability</strong>: The ODCs and IRNs are designed for long-term sustainability with minimal maintenance. Even after a catastrophic event, these centers could continue to function for decades, powered by their renewable energy sources.</p></li><li><p><strong>Information Retrieval</strong>: For Sarah and others in post-apocalyptic Earth, accessing information on how to cope with radiation, find clean water, or communicate with other survivors would still be possible.</p></li></ul><p>In the aftermath of Earth's nuclear apocalypse, the Distributed Model with No Central Hub proves to be a robust system for ensuring the continuity of information and communication.</p><ul><li><p><strong>Sarah's Quest for Information</strong>: Sarah, surviving in a subterranean shelter on Earth, needs vital information on radiation treatment. She uses a terminal connected to a local Gateway to input her request.</p></li><li><p><strong>Local Gateway Role</strong>: The surviving local Gateway in Sarah's shelter becomes her first touchpoint to the cosmic network. It forwards her request to the nearest available IRN, which could be orbiting the Moon or Mars.</p></li><li><p><strong>IRN Adaptability</strong>: Recognizing the catastrophic loss of Earth-based resources, the IRN's machine learning algorithms reroute Sarah's request to an ODC that has the requisite data. This could be an ODC orbiting Mars, which had mirrored crucial medical data from Earth.</p></li><li><p><strong>Data Retrieval</strong>: Sarah receives the radiation treatment data she was seeking, thanks to the network's ability to reroute and fulfill her request despite Earth's compromised state.</p></li><li><p><strong>Sustained Communication</strong>: Beyond just Sarah, the surviving members of human society on Earth, Moon, or Mars colonies could still access vital information and communicate with each other, thanks to this model.</p></li></ul><p>In essence, the Distributed Model with No Central Hub ensures that not all is lost for Sarah and others like her. Despite the unimaginable scale of destruction, the network's decentralized nature and adaptive routing capabilities offer a glimmer of hope and a means of survival.</p><h3><strong>Available and Future Technologies</strong></h3><p>To bring the concept of a cosmic internet to life, we'll need a mix of existing technologies and forward-thinking innovations. Below is a table detailing some of the pivotal technologies that could serve as the backbone for this ambitious venture:</p><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb86d631b-adb3-4e0f-9bf0-6d546dc78f6b_889x305.png" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb86d631b-adb3-4e0f-9bf0-6d546dc78f6b_889x305.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb86d631b-adb3-4e0f-9bf0-6d546dc78f6b_889x305.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb86d631b-adb3-4e0f-9bf0-6d546dc78f6b_889x305.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb86d631b-adb3-4e0f-9bf0-6d546dc78f6b_889x305.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb86d631b-adb3-4e0f-9bf0-6d546dc78f6b_889x305.png" width="889" height="305" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/b86d631b-adb3-4e0f-9bf0-6d546dc78f6b_889x305.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:305,&quot;width&quot;:889,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:105109,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb86d631b-adb3-4e0f-9bf0-6d546dc78f6b_889x305.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb86d631b-adb3-4e0f-9bf0-6d546dc78f6b_889x305.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb86d631b-adb3-4e0f-9bf0-6d546dc78f6b_889x305.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb86d631b-adb3-4e0f-9bf0-6d546dc78f6b_889x305.png 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a></figure></div><p>Existing technologies like high-frequency communication links and machine learning algorithms for routing lay a solid groundwork but need to be tailored for the unique challenges of space. Meanwhile, emerging technologies like small-scale nuclear reactors and quantum communication are still in the experimental or developmental stages but hold significant promise for future applications.</p><p class="button-wrapper" data-attrs="{&quot;url&quot;:&quot;https://www.tostring.ai/p/designing-an-apocalypse-resilient?utm_source=substack&utm_medium=email&utm_content=share&action=share&token=eyJ1c2VyX2lkIjoyMTE1MDMzMywicG9zdF9pZCI6MTM3MjEzNzgxLCJpYXQiOjE3MzgxNjE5MjIsImV4cCI6MTc0MDc1MzkyMiwiaXNzIjoicHViLTgzMTY2NiIsInN1YiI6InBvc3QtcmVhY3Rpb24ifQ.JtiTpNxOCrCifysMoUoEcctqDUJbofixZ3w-4G1ymlk&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a class="button primary" href="https://www.tostring.ai/p/designing-an-apocalypse-resilient?utm_source=substack&utm_medium=email&utm_content=share&action=share&token=eyJ1c2VyX2lkIjoyMTE1MDMzMywicG9zdF9pZCI6MTM3MjEzNzgxLCJpYXQiOjE3MzgxNjE5MjIsImV4cCI6MTc0MDc1MzkyMiwiaXNzIjoicHViLTgzMTY2NiIsInN1YiI6InBvc3QtcmVhY3Rpb24ifQ.JtiTpNxOCrCifysMoUoEcctqDUJbofixZ3w-4G1ymlk"><span>Share</span></a></p><h4>Conclusion </h4><p>The concept of a cosmic internet will become increasingly relevant as we set our sights beyond Earth, envisioning a future where humanity is an interplanetary species. This post has tried to provide a high-level overview of different architectural models that could support such an expansive network. While each has its own set of challenges and benefits, the Distributed Model with No Central Hub offers a compelling blend of resiliency and adaptability, particularly relevant as demonstrated through Sarah's use-case scenario.</p><p>In future posts, I'll go deeper into the technological intricacies of these architectures. From exploring the potential of machine learning in data routing to evaluating the long-term sustainability of power sources in space, there's much more to uncover. I&#8217;ll also look into new protocols that could better serve a cosmic network, addressing the unique challenges it presents.</p><p>If you have thoughts on the architecture, protocols, or any other aspect of a cosmic internet, please feel free to contribute.</p><p class="button-wrapper" data-attrs="{&quot;url&quot;:&quot;https://www.tostring.ai/p/designing-an-apocalypse-resilient/comments&quot;,&quot;text&quot;:&quot;Leave a comment&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a class="button primary" href="https://www.tostring.ai/p/designing-an-apocalypse-resilient/comments"><span>Leave a comment</span></a></p><div><hr></div><h6>This post was inspired by John Carmack's insights on the limitations and potential of space-based internet systems. The technical details and hypothetical scenarios are extensions of his initial thoughts, designed to explore the possibilities and challenges of such a network. Additionally, some phrase reformulations and grammar checks were performed with the assistance of ChatGPT-4 by OpenAI.</h6><div class="footnote" data-component-name="FootnoteToDOM"><a id="footnote-1" href="#footnote-anchor-1" class="footnote-number" contenteditable="false" target="_self">1</a><div class="footnote-content"><p>https://en.wikipedia.org/wiki/John_Carmack</p></div></div><div class="footnote" data-component-name="FootnoteToDOM"><a id="footnote-2" href="#footnote-anchor-2" class="footnote-number" contenteditable="false" target="_self">2</a><div class="footnote-content"><p>https://www.nasa.gov/smallsat-institute/sst-soa/communications</p></div></div><div class="footnote" data-component-name="FootnoteToDOM"><a id="footnote-3" href="#footnote-anchor-3" class="footnote-number" contenteditable="false" target="_self">3</a><div class="footnote-content"><p>https://ntrs.nasa.gov/api/citations/20160009224/downloads/20160009224.pdf</p></div></div><div class="footnote" data-component-name="FootnoteToDOM"><a id="footnote-4" href="#footnote-anchor-4" class="footnote-number" contenteditable="false" target="_self">4</a><div class="footnote-content"><p>https://en.wikipedia.org/wiki/Ground_segment</p></div></div><div class="footnote" data-component-name="FootnoteToDOM"><a id="footnote-5" href="#footnote-anchor-5" class="footnote-number" contenteditable="false" target="_self">5</a><div class="footnote-content"><p>https://en.wikipedia.org/wiki/Low_Earth_orbit</p></div></div><div class="footnote" data-component-name="FootnoteToDOM"><a id="footnote-6" href="#footnote-anchor-6" class="footnote-number" contenteditable="false" target="_self">6</a><div class="footnote-content"><p>https://en.wikipedia.org/wiki/Geostationary_orbit</p></div></div><div class="footnote" data-component-name="FootnoteToDOM"><a id="footnote-7" href="#footnote-anchor-7" class="footnote-number" contenteditable="false" target="_self">7</a><div class="footnote-content"><p>https://en.wikipedia.org/wiki/Interplanetary_Internet</p></div></div><div class="footnote" data-component-name="FootnoteToDOM"><a id="footnote-8" href="#footnote-anchor-8" class="footnote-number" contenteditable="false" target="_self">8</a><div class="footnote-content"><p>https://www.semanticscholar.org/paper/Communication-Technologies-and-Architectures-for-Mukherjee-Ramamurthy/321fd43e650b3547bcdec5a6718de12365016a57</p></div></div><div class="footnote" data-component-name="FootnoteToDOM"><a id="footnote-9" href="#footnote-anchor-9" class="footnote-number" contenteditable="false" target="_self">9</a><div class="footnote-content"><p>https://www.researchgate.net/figure/Interplanetary-Internet-Network-Concept-Credits-NASA_fig7_346016205</p><p></p></div></div> ]]>
</content:encoded>
</item>
</channel>
</rss>